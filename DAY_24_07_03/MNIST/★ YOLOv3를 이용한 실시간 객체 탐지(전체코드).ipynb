{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64759373",
   "metadata": {},
   "source": [
    "# YOLOv3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361c5d7b",
   "metadata": {},
   "source": [
    "## YOLOv3의 합성곱과 Residual(yolo.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20444768",
   "metadata": {},
   "source": [
    "### 라이브러리 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6a5c4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b53f4",
   "metadata": {},
   "source": [
    "### 합성곱함수"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155b347a",
   "metadata": {},
   "source": [
    "#### BatchNormalization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66820a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNormalization(layers.BatchNormalization):\n",
    "    # \"동결 상태(Frozen state)\"와 \"추론 모드(Inference mode)\"는 별개의 개념입니다. \n",
    "    # 'layer.trainable=False' 이면 레이어를 동결시킵니다. 이것은 훈련하는 동안 내부 상태 즉, 가중치가 바뀌지 않습니다.\n",
    "    # 그런데 layer.trainable=False이면 추론 모드로 실행됩니다. \n",
    "    # 레이어는 추론모드에서 현재 배치의 평균 및 분산을 사용하는 대신 현재 배치를 정규화하기 위해 이동 평균과 이동 분산을 사용합니다.\n",
    "    def call(self, x, training=False):\n",
    "        if not training:\n",
    "            training = tf.constant(False)\n",
    "        training = tf.logical_and(training, self.trainable)\n",
    "        return super().call(x, training)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67eff2b2",
   "metadata": {},
   "source": [
    "#### convolutional()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "11eb8453",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional(input_layer, filters, kernel_size,\n",
    "                  downsample=False, activate=True, bn=True):\n",
    "    if downsample:\n",
    "        input_layer = layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n",
    "        padding = 'valid'\n",
    "        strides = 2\n",
    "    else:\n",
    "        strides = 1\n",
    "        padding = 'same'\n",
    "\n",
    "    kernel_init = tf.random_normal_initializer(stddev=0.01)\n",
    "    conv = layers.Conv2D(filters=filters, \n",
    "                         kernel_size=kernel_size,\n",
    "                         strides=strides, padding=padding, \n",
    "                         use_bias=not bn,\n",
    "                         kernel_initializer=kernel_init,\n",
    "                         kernel_regularizer=l2(0.0005)\n",
    "                        )(input_layer)\n",
    "    if bn:\n",
    "        conv = BatchNormalization()(conv)\n",
    "    if activate:\n",
    "        conv = layers.LeakyReLU(alpha=0.1)(conv)\n",
    "\n",
    "    return conv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a162e72",
   "metadata": {},
   "source": [
    "### 레지듀얼 블록"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b504eeee",
   "metadata": {},
   "source": [
    "#### residual_block()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "236046cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def residual_block(input_layer, filter_num1, filter_num2):\n",
    "    short_cut = input_layer\n",
    "    conv = convolutional(input_layer, filters=filter_num1, kernel_size=(1,1))\n",
    "    conv = convolutional(conv       , filters=filter_num2, kernel_size=(3,3))\n",
    "    residual_output = short_cut + conv\n",
    "    return residual_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14da4f8",
   "metadata": {},
   "source": [
    "## 다크넷 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e441c85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def darknet53(input_data):\n",
    "    input_data = convolutional(input_data, 32, (3,3))\n",
    "    input_data = convolutional(input_data, 64, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(1):\n",
    "        input_data = residual_block(input_data,  32, 64)\n",
    "\n",
    "    input_data = convolutional(input_data, 128, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(2):\n",
    "        input_data = residual_block(input_data, 64, 128)\n",
    "\n",
    "    input_data = convolutional(input_data, 256, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(8):\n",
    "        input_data = residual_block(input_data, 128, 256)\n",
    "\n",
    "    route_1 = input_data\n",
    "    input_data = convolutional(input_data, 512, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(8):\n",
    "        input_data = residual_block(input_data, 256, 512)\n",
    "\n",
    "    route_2 = input_data\n",
    "    input_data = convolutional(input_data, 1024, (3,3), downsample=True)\n",
    "\n",
    "    for i in range(4):\n",
    "        input_data = residual_block(input_data, 512, 1024)\n",
    "\n",
    "    return route_1, route_2, input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e59faf35",
   "metadata": {},
   "source": [
    "## upsample() - 업샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c848bc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upsample(input_layer):\n",
    "    width, height = input_layer.shape[1], input_layer.shape[2]\n",
    "    output_layer = tf.image.resize(input_layer, (width*2, height*2), \n",
    "                                   method='nearest')\n",
    "    return output_layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f165733",
   "metadata": {},
   "source": [
    "## YOLOv3 함수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39b47029",
   "metadata": {},
   "outputs": [],
   "source": [
    "def YOLOv3(input_layer, num_class):\n",
    "    # Darknet-53을 실행하고 그 결과를 받음\n",
    "    route_1, route_2, conv = darknet53(input_layer)\n",
    "    \n",
    "    conv = convolutional(conv, 512, (1,1))\n",
    "    conv = convolutional(conv, 1024, (3,3))\n",
    "    conv = convolutional(conv, 512, (1,1))\n",
    "    conv = convolutional(conv, 1024, (3,3))\n",
    "    conv = convolutional(conv, 512, (1,1))\n",
    "    conv_lobj_branch = convolutional(conv, 1024, (3,3))\n",
    "    \n",
    "    # conv_lbbox는 큰 객체를 예측하기 위해 사용, Shape = [None, 13, 13, 255] \n",
    "    conv_lbbox = convolutional(conv_lobj_branch, \n",
    "                               3*(num_class+5), (1,1),\n",
    "                               activate=False, bn=False)\n",
    "    \n",
    "    conv = convolutional(conv, 256, (1,1))\n",
    "    # 최근방법(nearest)을 이용하여 업샘플링\n",
    "    # 이렇게 하면 업샘플링시 학습이 필요 없으므로 인공신경망 파라미터를 줄인다.\n",
    "    conv = upsample(conv)\n",
    "\n",
    "    conv = tf.concat([conv, route_2], axis=-1)\n",
    "    conv = convolutional(conv, 256, (1,1))\n",
    "    conv = convolutional(conv, 512, (3,3))\n",
    "    conv = convolutional(conv, 256, (1,1))\n",
    "    conv = convolutional(conv, 512, (3,3))\n",
    "    conv = convolutional(conv, 256, (1,1))\n",
    "    conv_mobj_branch = convolutional(conv, 512, (3,3))\n",
    "\n",
    "    # conv_mbbox는 중간 크기 객체를 예측하기 위해 사용, shape = [None, 26, 26, 255]\n",
    "    conv_mbbox = convolutional(conv_mobj_branch, \n",
    "                               3*(num_class+5), (1,1),\n",
    "                               activate=False, bn=False)\n",
    "\n",
    "    conv = convolutional(conv, 128, (1,1))\n",
    "    conv = upsample(conv)\n",
    "\n",
    "    conv = tf.concat([conv, route_1], axis=-1)\n",
    "    conv = convolutional(conv, 128, (1,1))\n",
    "    conv = convolutional(conv, 256, (3,3))\n",
    "    conv = convolutional(conv, 128, (1,1))\n",
    "    conv = convolutional(conv, 256, (3,3))\n",
    "    conv = convolutional(conv, 128, (1,1))\n",
    "    conv_sobj_branch = convolutional(conv, 256, (3,3))\n",
    "    \n",
    "    # conv_sbbox는 작은 객체를 예측하기 위해 사용, shape = [None, 52, 52, 255]\n",
    "    conv_sbbox = convolutional(conv_sobj_branch, \n",
    "                               3*(num_class+5), (1,1),\n",
    "                               activate=False, bn=False)\n",
    "        \n",
    "    return [conv_sbbox, conv_mbbox, conv_lbbox]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "121ccef6",
   "metadata": {},
   "source": [
    "## 합성곱 신경망의 출력을 디코딩 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efab343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "YOLO_STRIDES  = [8, 16, 32]\n",
    "YOLO_ANCHORS  = [[[10,  13], [16,   30], [33,   23]],\n",
    "                 [[30,  61], [62,   45], [59,  119]],\n",
    "                 [[116, 90], [156, 198], [373, 326]]]\n",
    "STRIDES       = np.array(YOLO_STRIDES)\n",
    "ANCHORS       = (np.array(YOLO_ANCHORS).T/STRIDES).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d8e3488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode(conv_output, num_class, i=0):\n",
    "    conv_shape       = tf.shape(conv_output)\n",
    "    batch_size       = conv_shape[0]\n",
    "    output_size      = conv_shape[1]\n",
    "\n",
    "    conv_output = tf.reshape(conv_output, \n",
    "                             (batch_size, output_size, output_size, \n",
    "                              3, num_class+5))\n",
    "\n",
    "    conv_raw_dxdy = conv_output[:, :, :, :, 0:2] # 상자의 x, y위치\n",
    "    conv_raw_dwdh = conv_output[:, :, :, :, 2:4] # 상자의 가로, 세로 크기\n",
    "    conv_raw_conf = conv_output[:, :, :, :, 4:5] # 상자의 신뢰도(confidence)\n",
    "    conv_raw_prob = conv_output[:, :, :, :, 5: ] # 클래스별 확률\n",
    "\n",
    "    # next need Draw the grid. Where output_size is equal to 13, 26 or 52  \n",
    "    y = tf.range(output_size, dtype=tf.int32)\n",
    "    y = tf.expand_dims(y, -1)\n",
    "    y = tf.tile(y, [1, output_size])\n",
    "    x = tf.range(output_size, dtype=tf.int32)\n",
    "    x = tf.expand_dims(x, 0)\n",
    "    x = tf.tile(x, [output_size, 1])\n",
    "\n",
    "    xy_grid = tf.concat([x[:, :, tf.newaxis], y[:, :, tf.newaxis]], axis=-1)\n",
    "    xy_grid = tf.tile(xy_grid[tf.newaxis, :, :, tf.newaxis, :], \n",
    "                      [batch_size, 1, 1, 3, 1])\n",
    "    xy_grid = tf.cast(xy_grid, tf.float32)\n",
    "\n",
    "    # 상자의 중심점을 계산\n",
    "    pred_xy = (tf.sigmoid(conv_raw_dxdy) + xy_grid) * STRIDES[i]\n",
    "    # 상자의 너비와 높이를 계산\n",
    "    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i]) * STRIDES[i]\n",
    "\n",
    "    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n",
    "    pred_conf = tf.sigmoid(conv_raw_conf) # 상자의 신뢰도 계산\n",
    "    pred_prob = tf.sigmoid(conv_raw_prob) # 클래스별 확률 계산\n",
    "\n",
    "    return tf.concat([pred_xywh, pred_conf, pred_prob], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59f568",
   "metadata": {},
   "source": [
    "## YOLOv3 모델 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a7f1cb98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Create_YOLOv3(num_class, input_shape=(416,416,3), train_mode=False):\n",
    "    input_layer  = layers.Input(input_shape)\n",
    "    conv_tensors = YOLOv3(input_layer, num_class)\n",
    "    output_tensors = []\n",
    "    for i, conv_tensor in enumerate(conv_tensors):\n",
    "        pred_tensor = decode(conv_tensor, num_class, i)\n",
    "        if train_mode: output_tensors.append(conv_tensor)\n",
    "        output_tensors.append(pred_tensor)\n",
    "\n",
    "    model = tf.keras.Model(input_layer, output_tensors)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b42f66d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASS = 10\n",
    "yolo = Create_YOLOv3(train_mode=True, num_class=NUM_CLASS)\n",
    "# yolo.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61fcb80a",
   "metadata": {},
   "source": [
    "# 모델 만들고 학습시키기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8450609b",
   "metadata": {},
   "source": [
    "## 이미지 전처리하기(image_process.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e0b0b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "# 이미지를 정사각형 크기로 변환, \n",
    "# 채워지는 화소 기본값은 value속성의 값으로 설정함\n",
    "def resize_to_square(image, target_size, gt_boxes=None, value=128.0):\n",
    "    ih, iw = target_size, target_size\n",
    "    h, w, _ = image.shape\n",
    "\n",
    "    scale = min(iw / w, ih / h)\n",
    "    nw, nh = int(scale * w), int(scale * h)\n",
    "    image_resized = cv2.resize(image, (nw, nh))\n",
    "\n",
    "    image_padded = np.full(shape=[ih, iw, 3], fill_value=value)\n",
    "    dw, dh = (iw - nw) // 2, (ih - nh) // 2\n",
    "    image_padded[dh:nh + dh, dw:nw + dw, :] = image_resized\n",
    "    image_padded = image_padded / 255.\n",
    "\n",
    "    if gt_boxes is None:\n",
    "        return image_padded\n",
    "    else:\n",
    "        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n",
    "        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n",
    "        return image_padded, gt_boxes\n",
    "    \n",
    "\n",
    "def random_horizontal_flip(image, bboxes, p=0.5):\n",
    "    if random.random() < p:\n",
    "        _, w, _ = image.shape\n",
    "        image = image[:, ::-1, :]\n",
    "        bboxes[:, [0, 2]] = w - bboxes[:, [2, 0]]\n",
    "\n",
    "    return image, bboxes\n",
    "\n",
    "# 자르기 \n",
    "def random_crop(image, bboxes, p=0.5):\n",
    "    if random.random() < p:\n",
    "        h, w, _ = image.shape\n",
    "        max_bbox = np.concatenate( \n",
    "            [np.min(bboxes[:, 0:2], axis=0), \n",
    "             np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "        max_l_trans = max_bbox[0]\n",
    "        max_u_trans = max_bbox[1]\n",
    "        max_r_trans = w - max_bbox[2]\n",
    "        max_d_trans = h - max_bbox[3]\n",
    "\n",
    "        crop_xmin = max(0, int(max_bbox[0] - random.uniform(0, max_l_trans)))\n",
    "        crop_ymin = max(0, int(max_bbox[1] - random.uniform(0, max_u_trans)))\n",
    "        crop_xmax = max(w, int(max_bbox[2] + random.uniform(0, max_r_trans)))\n",
    "        crop_ymax = max(h, int(max_bbox[3] + random.uniform(0, max_d_trans)))\n",
    "\n",
    "        image = image[crop_ymin:crop_ymax, crop_xmin:crop_xmax]\n",
    "\n",
    "        bboxes[:, [0, 2]] = bboxes[:, [0, 2]] - crop_xmin\n",
    "        bboxes[:, [1, 3]] = bboxes[:, [1, 3]] - crop_ymin\n",
    "  \n",
    "    return image, bboxes\n",
    "\n",
    "  \n",
    "# 이동 \n",
    "def random_translate(image, bboxes, p=0.5):\n",
    "    if random.random() < p:\n",
    "        h, w, _ = image.shape\n",
    "        max_bbox = np.concatenate( \n",
    "            [np.min(bboxes[:, 0:2], axis=0),\n",
    "             np.max(bboxes[:, 2:4], axis=0)], axis=-1)\n",
    "\n",
    "        max_l_trans = max_bbox[0]\n",
    "        max_u_trans = max_bbox[1]\n",
    "        max_r_trans = w - max_bbox[2]\n",
    "        max_d_trans = h - max_bbox[3]\n",
    "\n",
    "        tx = random.uniform(-(max_l_trans-1), (max_r_trans-1))\n",
    "        ty = random.uniform(-(max_u_trans-1), (max_d_trans-1))\n",
    "\n",
    "        M = np.array([[1, 0, tx], [0, 1, ty]])\n",
    "        image = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "        bboxes[:, [0, 2]] = bboxes[:, [0, 2]] + tx\n",
    "        bboxes[:, [1, 3]] = bboxes[:, [1, 3]] + ty\n",
    "\n",
    "    return image, bboxes\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d2db6",
   "metadata": {},
   "source": [
    "## IoU 계산하기(bbox_iou.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "651b1e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def bbox_iou(boxes1, boxes2):\n",
    "    boxes1_area = boxes1[..., 2] * boxes1[..., 3]\n",
    "    boxes2_area = boxes2[..., 2] * boxes2[..., 3]\n",
    "\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5, \n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5, \n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    return 1.0 * inter_area / union_area\n",
    " \n",
    "# GIoU 계산하는 함수 \n",
    "def bbox_giou(boxes1, boxes2):\n",
    "    boxes1 = tf.concat([boxes1[..., :2] - boxes1[..., 2:] * 0.5,\n",
    "                        boxes1[..., :2] + boxes1[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "    boxes2 = tf.concat([boxes2[..., :2] - boxes2[..., 2:] * 0.5,\n",
    "                        boxes2[..., :2] + boxes2[..., 2:] * 0.5],\n",
    "                       axis=-1)\n",
    "\n",
    "    boxes1 = tf.concat([tf.minimum(boxes1[...,:2], boxes1[...,2:]),\n",
    "                        tf.maximum(boxes1[...,:2], boxes1[...,2:])], \n",
    "                       axis=-1)\n",
    "    boxes2 = tf.concat([tf.minimum(boxes2[...,:2], boxes2[...,2:]),\n",
    "                        tf.maximum(boxes2[...,:2], boxes2[...,2:])],\n",
    "                       axis=-1)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up = tf.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = tf.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = tf.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "  \n",
    "    # 두 경계 상자의 IoU를 계산 \n",
    "    iou = inter_area / union_area\n",
    "\n",
    "    # 왼쪽 위와 오른쪽 아래를 포함하는 가장 작은 사각형 계산 \n",
    "    enclose_left_up = tf.minimum(boxes1[..., :2], boxes2[..., :2])\n",
    "    enclose_right_down = tf.maximum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "    enclose = tf.maximum(enclose_right_down - enclose_left_up, 0.0)\n",
    "  \n",
    "    # 가장 작은 C 상자의 면적 계산 \n",
    "    enclose_area = enclose[..., 0] * enclose[..., 1]\n",
    "  \n",
    "    # GIoU 공식으로 GIoU 계산 \n",
    "    giou = iou - 1.0 * (enclose_area - union_area) / enclose_area\n",
    "\n",
    "    return giou\n",
    " \n",
    "# CIoU 계산하는 함수 \n",
    "def bbox_ciou(boxes1, boxes2):\n",
    "    boxes1_coor = tf.concat([boxes1[...,:2] - boxes1[...,2:] * 0.5, \n",
    "                             boxes1[...,:2] + boxes1[...,2:] * 0.5], \n",
    "                            axis=-1)\n",
    "    boxes2_coor = tf.concat([boxes2[...,:2] - boxes2[...,2:] * 0.5, \n",
    "                             boxes2[...,:2] + boxes2[...,2:] * 0.5], \n",
    "                            axis=-1)\n",
    "\n",
    "    left = tf.maximum(boxes1_coor[..., 0], boxes2_coor[..., 0])\n",
    "    up = tf.maximum(boxes1_coor[..., 1], boxes2_coor[..., 1])\n",
    "    right = tf.maximum(boxes1_coor[..., 2], boxes2_coor[..., 2])\n",
    "    down = tf.maximum(boxes1_coor[..., 3], boxes2_coor[..., 3])\n",
    "\n",
    "    c = (right - left) * (right - left) + (up - down) * (up - down)\n",
    "    iou = bbox_iou(boxes1, boxes2)\n",
    "\n",
    "    u = (boxes1[..., 0] - boxes2[..., 0]) * (boxes1[..., 0] - boxes2[..., 0]) + (boxes1[..., 1] - boxes2[..., 1]) * (boxes1[..., 1] - boxes2[..., 1])\n",
    "    d = u / c\n",
    "\n",
    "    ar_gt = boxes2[..., 2] / boxes2[..., 3]\n",
    "    ar_pred = boxes1[..., 2] / boxes1[..., 3]\n",
    "\n",
    "    ar_loss = 4 / (np.pi * np.pi) * (tf.atan(ar_gt) - tf.atan(ar_pred)) * (tf.atan(ar_gt) - tf.atan(ar_pred))\n",
    "    alpha = ar_loss / (1 - iou + ar_loss + 0.000001)\n",
    "    ciou_term = d + alpha * ar_loss\n",
    " \n",
    "    return iou - ciou_term"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e0a2372",
   "metadata": {},
   "source": [
    "## 스트라이드와 앵커박스(config.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc780c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "YOLO_STRIDES  = [8, 16, 32]\n",
    "YOLO_ANCHORS  = [[[10,  13], [16,   30], [33,   23]],\n",
    "                 [[30,  61], [62,   45], [59,  119]],\n",
    "                 [[116, 90], [156, 198], [373, 326]]]\n",
    "\n",
    "STRIDES       = np.array(YOLO_STRIDES)\n",
    "ANCHORS       = (np.array(YOLO_ANCHORS).T/STRIDES).T\n",
    "\n",
    "NUM_CLASS     = 10 # COCO 데이터이면 80, MNIST 데이터이면 10 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f884d2",
   "metadata": {},
   "source": [
    "## 데이터 생성기(data.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "11797be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "from config import *\n",
    "from image_process import *\n",
    "from bbox_iou import *\n",
    "\n",
    "\n",
    "# 파일에서 클래스 라벨을 읽어 딕셔너리로 만들어 반환\n",
    "def read_class_names(class_label_path):\n",
    "    names = {}\n",
    "    with open(class_label_path, 'r') as data:\n",
    "        for ID, name in enumerate(data):\n",
    "            names[ID] = name.strip('\\n')\n",
    "    return names\n",
    "\n",
    "\n",
    "class DataGenerator(object):\n",
    "    def __init__(self,\n",
    "                 data_path,\n",
    "                 annot_path,\n",
    "                 class_label_path,\n",
    "                 load_images_to_ram=True,\n",
    "                 data_aug=True,\n",
    "                 input_size=416,\n",
    "                 anchor_per_scale=3,\n",
    "                 max_bbox_per_scale=100, \n",
    "                 batch_size=4,\n",
    "                 strides=STRIDES, \n",
    "                 anchors=ANCHORS):\n",
    "        self.input_size = input_size\n",
    "        self.annot_path = annot_path\n",
    "        self.batch_size = batch_size\n",
    "        self.data_aug = False\n",
    "        self.strides = strides\n",
    "        self.classes = read_class_names(class_label_path)\n",
    "        self.num_classes = len(self.classes)\n",
    "        self.anchors = anchors\n",
    "        self.anchor_per_scale = anchor_per_scale\n",
    "        self.max_bbox_per_scale = max_bbox_per_scale\n",
    "        self.load_images_to_ram = load_images_to_ram\n",
    "        self.annotations = self.load_annotations(annot_path)\n",
    "        self.num_samples = len(self.annotations)\n",
    "        self.num_batchs = int(np.ceil(self.num_samples / self.batch_size)) \n",
    "        self.batch_count = 0 \n",
    "        self.output_sizes = input_size // strides\n",
    "\n",
    "    # 아노테이션 경로에서 데이터파일을 읽어옴 \n",
    "    def load_annotations(self, annot_path):\n",
    "        # C:\\mnist_test\\000009.jpg \n",
    "        # 156,153,178,175,9 278,294,300,316,0 \n",
    "        annotations = []\n",
    "\n",
    "        with open(self.annot_path, 'r') as f:\n",
    "            # 파일에서 데이터를 불러와 라인별로 자름 \n",
    "            data = f.read().splitlines()\n",
    "            # 공백으로 잘라 맨 앞의 파일경로제외하고  \n",
    "            # 길이가0이 아닌 행들을 리스트로 만들어 놓음 \n",
    "            # 파일명만 있는 행 제거 \n",
    "            # (객체가 없는 이미지의 어노테이션 데이터임) \n",
    "            lines = [line.strip() for line in data if len(line.strip().split()[1:]) != 0]\n",
    "        # 랜덤하게 섞음 \n",
    "        np.random.shuffle(lines)\n",
    "\n",
    "        for line in lines:\n",
    "            # 공백으로 나눔 \n",
    "            # 예: line=['C:\\mnist_test\\000009.jpg', \n",
    "            # 156,153,178,175,9', '278,294,300,316,0'] \n",
    "            annotation = line.split()\n",
    "            image_path, index = \"\", 1\n",
    "            for i, one_line in enumerate(annotation):\n",
    "                if not one_line.replace(\",\",\"\").isnumeric():\n",
    "                    if image_path != \"\": \n",
    "                        image_path += \" \"\n",
    "                    image_path += one_line\n",
    "                else:\n",
    "                    index = i\n",
    "                    break\n",
    "\n",
    "            # 어노테이션 이미지파일이 없으면 예외 발생시킴 \n",
    "            if not os.path.exists(image_path):\n",
    "                raise KeyError(f\"{image_path} 파일이 없음\")\n",
    "\n",
    "            # 램 사용하면 이미지를 메모리에 저장 후 사용 \n",
    "            # 램 사용하지 않으면 \n",
    "            #    __next__에서 parse_annotation을 실행, \n",
    "            #    parse_annotation에서 이미지가 로드됨 \n",
    "            if self.load_images_to_ram:\n",
    "                image = cv2.imread(image_path)\n",
    "            else:\n",
    "                image = '' \n",
    "\n",
    "            # [['C:\\mnist_test\\000009.jpg', \n",
    "            # [156,153,178,175,9', '278,294,300,316,0'], ''], ... ] \n",
    "            annotations.append([image_path, annotation[index:], image])\n",
    "\n",
    "        return annotations\n",
    "\n",
    "    # 아노테이션 데이터 파싱 \n",
    "    def parse_annotation(self, annotation, mAP='False'):\n",
    "        if self.load_images_to_ram:\n",
    "            image_path = annotation[0]\n",
    "            image = annotation[2]\n",
    "        else:\n",
    "            image_path = annotation[0]\n",
    "            image = cv2.imread(image_path) # 이미지를 불러옴 \n",
    "\n",
    "        #  [[156,153,178,175,9], [278,294,300,316,0]] \n",
    "        bboxes = np.array([list(map(int, box.split(','))) for box in annotation[1]])\n",
    "\n",
    "        # 이미지 증강 - 숫자, 문자는 좌/우 반전이 필요 없음 \n",
    "        # 이미지를 변환하면 경계 상자도 같이 바꿔줘야 함 \n",
    "        if self.data_aug:\n",
    "            # 좌/우 반전(생략) \n",
    "#             image, bboxes = random_horizontal_flip(np.copy(image), np.copy(bboxes)) \n",
    "            # 자르기 \n",
    "            image, bboxes = random_crop(np.copy(image),\n",
    "                                        np.copy(bboxes))  \n",
    "            # 이동 \n",
    "            image, bboxes = random_translate(np.copy(image),\n",
    "                                             np.copy(bboxes))\n",
    "\n",
    "        # mAP=True이면 image, bbox를 반환\n",
    "        if mAP==True:\n",
    "            return image, bboxes\n",
    "        \n",
    "        image, bboxes = resize_to_square(np.copy(image), self.input_size, np.copy(bboxes))\n",
    "\n",
    "        return image, bboxes\n",
    " \n",
    "    # 상자 전처리 \n",
    "    def preprocess_true_boxes(self, bboxes):\n",
    "        # 스트라이드의 수 만큼 출력 레벨이 만들어짐 \n",
    "        OUTPUT_LEVELS = len(self.strides)\n",
    "\n",
    "        # output_size = 416/[8, 16, 32] = [52, 26, 13] -> N\n",
    "        # anchor_per_scale = 3, num_classes = 10(MNIST일 경우)\n",
    "        # 출력 레벨 수 만큼 (N,N,3,15) 모양의 라벨 배열 초기화\n",
    "        label = [np.zeros((self.output_sizes[i],\n",
    "                           self.output_sizes[i],\n",
    "                           self.anchor_per_scale,\n",
    "                           5 + self.num_classes))\n",
    "                 for i in range(OUTPUT_LEVELS)]\n",
    "        # max_bbox_per_scale = 100 \n",
    "        # 출력 레벨 수 만큼 (100,4) 모양 경계상자 배열 초기화 \n",
    "        bboxes_xywh = [np.zeros((self.max_bbox_per_scale, 4))\n",
    "                       for _ in range(OUTPUT_LEVELS)]\n",
    "        # 출력 레벨 수 만큼 상자 수 배열 초기화 \n",
    "        bbox_count = np.zeros((OUTPUT_LEVELS,))\n",
    "\n",
    "        # 모든 상자 수 만큼 실행 \n",
    "        for bbox in bboxes:\n",
    "            # 상자 좌표 \n",
    "            bbox_coor = bbox[:4]\n",
    "            # 상자 클래스 라벨 \n",
    "            bbox_class_ind = bbox[4]\n",
    "            # 상자의 클래스 라벨 원-핫 인코딩\n",
    "            onehot = np.zeros(self.num_classes, dtype=np.float64) \n",
    "            onehot[bbox_class_ind] = 1.0\n",
    "\n",
    "            # 원-핫 라벨 평활화(Label Smoothing) \n",
    "            # 레이블 정규화라고 부르기도 함 \n",
    "            # 손실함수가 cross entropy이고,\n",
    "            # 활성화 함수를 softmax를 사용할 때 적용 \n",
    "            # 가장 큰 벡터가 나머지 벡터보다 커지는 것을 억제 \n",
    "            # 공식: y_ls = (1-alpha)*y_onehot + alpha/K \n",
    "            K = self.num_classes\n",
    "            alpha = 0.01 \n",
    "            smooth_onehot = (1-alpha)*onehot + alpha/K \n",
    "\n",
    "            # 상자 좌표를 상자 x,y,w,h로 변환 후 표준화 \n",
    "            bbox_xywh = np.concatenate(\n",
    "                [(bbox_coor[2:] + bbox_coor[:2]) * 0.5,\n",
    "                 bbox_coor[2:] - bbox_coor[:2]], axis=-1)\n",
    "            bbox_xywh_scaled = 1.0 * bbox_xywh[np.newaxis, :] / self.strides[:, np.newaxis] \n",
    "\n",
    "            iou = []\n",
    "            exist_positive = False \n",
    "            for i in range(OUTPUT_LEVELS):  # range(3): \n",
    "                # 앵커박스 \n",
    "                anchors_xywh = np.zeros((self.anchor_per_scale, 4))\n",
    "                anchors_xywh[:, 0:2] = np.floor(\n",
    "                    bbox_xywh_scaled[i, 0:2]).astype(np.int32)+0.5\n",
    "                anchors_xywh[:, 2:4] = self.anchors[i]\n",
    "\n",
    "                # 실제 박스와 앵커박스 IoU계산 \n",
    "                iou_scale = bbox_iou(\n",
    "                    bbox_xywh_scaled[i][np.newaxis, :],\n",
    "                    anchors_xywh)\n",
    "                iou.append(iou_scale)\n",
    "\n",
    "                # IoU가 0.3 이상인 박스만 처리함 \n",
    "                iou_mask = iou_scale > 0.3 \n",
    "                if np.any(iou_mask):\n",
    "                    xi, yi = np.floor(\n",
    "                        bbox_xywh_scaled[i, 0:2]).astype(np.int32) \n",
    "\n",
    "                    label[i][yi, xi, iou_mask, :] = 0 \n",
    "                    label[i][yi, xi, iou_mask, 0:4] = bbox_xywh\n",
    "                    label[i][yi, xi, iou_mask, 4:5] = 1.0 \n",
    "                    label[i][yi, xi, iou_mask, 5:] = smooth_onehot\n",
    "\n",
    "                    bbox_ind = int(                        bbox_count[i]%self.max_bbox_per_scale)\n",
    "                    bboxes_xywh[i][bbox_ind, :4] = bbox_xywh\n",
    "                    bbox_count[i] += 1 \n",
    "                    exist_positive = True \n",
    "  \n",
    "            if not exist_positive:\n",
    "                bst_anc_idx = np.argmax(np.array(iou).reshape(-1),\n",
    "                                        axis=-1)\n",
    "                best_detect = int(bst_anc_idx / self.anchor_per_scale)\n",
    "                best_anchor = int(bst_anc_idx % self.anchor_per_scale)\n",
    "                xi, yi = np.floor(\n",
    "                    bbox_xywh_scaled[best_detect,\n",
    "                                     0:2]).astype(np.int32)\n",
    "\n",
    "                label[best_detect][yi, xi, best_anchor, :] = 0 \n",
    "                label[best_detect][yi, xi,\n",
    "                                   best_anchor, 0:4] = bbox_xywh \n",
    "                label[best_detect][yi, xi,\n",
    "                                   best_anchor, 4:5] = 1.0 \n",
    "                label[best_detect][yi, xi,\n",
    "                                   best_anchor, 5:] = smooth_onehot \n",
    "\n",
    "                bbox_ind = int(bbox_count[best_detect] % self.max_bbox_per_scale)\n",
    "                bboxes_xywh[best_detect][bbox_ind, :4] = bbox_xywh \n",
    "                bbox_count[best_detect] += 1 \n",
    "\n",
    "        label_sbbox, label_mbbox, label_lbbox = label\n",
    "        sbboxes, mbboxes, lbboxes = bboxes_xywh\n",
    "        output_boxes = label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes\n",
    "        return output_boxes \n",
    "\n",
    "    def __len__(self):\n",
    "        return self.num_batchs\n",
    "  \n",
    "    def __iter__(self):\n",
    "        return self \n",
    " \n",
    "    # 배치 크기만큼 이미지와 라벨 박스를 반환 \n",
    "    def __next__(self):\n",
    "        with tf.device('/cpu:0'):\n",
    "            # 배치 이미지를 갖는 배열 \n",
    "            batch_image = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.input_size,\n",
    "                 self.input_size,\n",
    "                 3), dtype=np.float32)\n",
    " \n",
    "            # 배치 라벨(small, middle, large) 경계 상자 \n",
    "            batch_label_sbbox = np.zeros(\n",
    "                (self.batch_size,\n",
    "                 self.output_sizes[0],\n",
    "                 self.output_sizes[0],\n",
    "                 self.anchor_per_scale,\n",
    "                 5 + self.num_classes), dtype=np.float32)\n",
    "            batch_label_mbbox = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.output_sizes[1],\n",
    "                 self.output_sizes[1],\n",
    "                 self.anchor_per_scale,\n",
    "                 5 + self.num_classes), dtype=np.float32)\n",
    "            batch_label_lbbox = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.output_sizes[2], \n",
    "                 self.output_sizes[2], \n",
    "                 self.anchor_per_scale,\n",
    "                 5 + self.num_classes), dtype=np.float32)\n",
    " \n",
    "            # 배치 크기만큼 경계 상자를 저장할 변수 \n",
    "            batch_sbboxes = np.zeros(\n",
    "                (self.batch_size,\n",
    "                 self.max_bbox_per_scale, 4),\n",
    "                dtype=np.float32)\n",
    "            batch_mbboxes = np.zeros(\n",
    "                (self.batch_size, \n",
    "                 self.max_bbox_per_scale, 4),\n",
    "                dtype=np.float32)\n",
    "            batch_lbboxes = np.zeros( \n",
    "                (self.batch_size,\n",
    "                 self.max_bbox_per_scale, 4),\n",
    "                dtype=np.float32)\n",
    "\n",
    "            exceptions = False \n",
    "            num = 0 \n",
    "            if self.batch_count < self.num_batchs:\n",
    "                # 배치 크기만큼 실행   \n",
    "                while num < self.batch_size:  \n",
    "                    index = self.batch_count * self.batch_size + num \n",
    "                    if index >= self.num_samples: \n",
    "                        index -= self.num_samples\n",
    "                    annotation = self.annotations[index]\n",
    "                    image, bboxes = self.parse_annotation( annotation) \n",
    "                    try:\n",
    "                        label_sbbox, label_mbbox, label_lbbox, sbboxes, mbboxes, lbboxes = self.preprocess_true_boxes(bboxes) \n",
    "                    except IndexError:\n",
    "                        exceptions = True \n",
    "                        print(\"IndexError,\", annotation[0])\n",
    "\n",
    "                    batch_image[num,:,:,:] = image \n",
    "                    batch_label_mbbox[num,:,:,:,:] = label_mbbox \n",
    "                    batch_label_lbbox[num,:,:,:,:] = label_lbbox \n",
    "                    batch_mbboxes[num,:,:] = mbboxes \n",
    "                    batch_lbboxes[num,:,:] = lbboxes \n",
    "                    batch_label_sbbox[num,:,:,:,:] = label_sbbox \n",
    "                    batch_sbboxes[num,:,:] = sbboxes \n",
    "                    num += 1 \n",
    "\n",
    "                if exceptions:\n",
    "                    print('\\n')\n",
    "                    raise Exception(\"데이터셋에 문제가 있습니다.\")\n",
    "\n",
    "                self.batch_count += 1 \n",
    "                batch_sm_target = batch_label_sbbox, batch_sbboxes \n",
    "                batch_md_target = batch_label_mbbox, batch_mbboxes \n",
    "                batch_lg_target = batch_label_lbbox, batch_lbboxes \n",
    "\n",
    "                target=(batch_sm_target,batch_md_target,batch_lg_target) \n",
    "                return batch_image, target\n",
    "            else:\n",
    "                self.batch_count = 0\n",
    "                np.random.shuffle(self.annotations)\n",
    "                raise StopIteration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdcb424",
   "metadata": {},
   "source": [
    "## GPU 사용 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "93069a48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs []\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(f'GPUs {gpus}')\n",
    "\n",
    "if len(gpus) > 0:\n",
    "    try: \n",
    "        tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "    except RuntimeError: \n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed7c1fb",
   "metadata": {},
   "source": [
    "## 상수 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d9092b6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOGDIR = \"logs\" # 학습로그를 저장할 디렉토리\n",
    "\n",
    "WARMUP_EPOCHS = 2\n",
    "EPOCHS = 100\n",
    "\n",
    "SAVE_BEST_ONLY        = True              # val loss가 가장 좋은 모델을 저장, True 권장\n",
    "SAVE_CHECKPOINT       = False             # True이면 학습 시 모든 유효한 모델을 저장함, False 권장\n",
    "CHECKPOINTS_FOLDER    = \"checkpoints\"     # 모델이 저장될 디렉토리\n",
    "MODEL_NAME            = \"mnist_custom\"    # 저장될 모델의 이름\n",
    "SCORE_THRESHOLD       = 0.3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38437b9",
   "metadata": {},
   "source": [
    "## 학습 로그 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c6e7fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "\n",
    "LOGDIR = \"logs\" # 학습 로그를 저장할 디렉토리 \n",
    "\n",
    "if os.path.exists(LOGDIR): \n",
    "    shutil.rmtree(LOGDIR) # 로그 디렉토리가 있으면 삭제 \n",
    "\n",
    "writer = tf.summary.create_file_writer(LOGDIR)\n",
    "validate_writer = tf.summary.create_file_writer(LOGDIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c145aee",
   "metadata": {},
   "source": [
    "## compute_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "02bd2bf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(pred, conv, label, bboxes, \n",
    "                 i=0, iou_loss_thresh=0.45):\n",
    "    conv_shape  = tf.shape(conv)\n",
    "    batch_size  = conv_shape[0]\n",
    "    output_size = conv_shape[1]\n",
    "    input_size  = STRIDES[i] * output_size\n",
    "    conv = tf.reshape(conv,\n",
    "                      (batch_size, output_size, output_size,\n",
    "                       3, 5 + NUM_CLASS))\n",
    "\n",
    "    conv_raw_conf = conv[:, :, :, :, 4:5]\n",
    "    conv_raw_prob = conv[:, :, :, :, 5:]\n",
    "\n",
    "    pred_xywh     = pred[:, :, :, :, 0:4]\n",
    "    pred_conf     = pred[:, :, :, :, 4:5]\n",
    "\n",
    "    label_xywh    = label[:, :, :, :, 0:4]\n",
    "    respond_bbox  = label[:, :, :, :, 4:5]\n",
    "    label_prob    = label[:, :, :, :, 5:]\n",
    "\n",
    "    giou = tf.expand_dims(bbox_giou(pred_xywh, label_xywh), \n",
    "                          axis=-1)\n",
    "    input_size = tf.cast(input_size, tf.float32)    \n",
    "\n",
    "    bbox_loss_scale = 2.0 - 1.0 * label_xywh[:, :, :, :, 2:3] * label_xywh[:, :, :, :, 3:4] / (input_size ** 2)\n",
    "    giou_loss = respond_bbox * bbox_loss_scale * (1 - giou)\n",
    "\n",
    "    # bbox_iou \n",
    "    iou = bbox_iou(pred_xywh[:, :, :, :, np.newaxis, :],\n",
    "                   bboxes[:, np.newaxis, np.newaxis, np.newaxis, :, :]) \n",
    "\n",
    "    # 실제 상자에서 가장 큰 예측값을 갖는 상자로 IoU 값 찾기 \n",
    "    max_iou = tf.expand_dims(tf.reduce_max(iou, axis=-1),\n",
    "                             axis=-1)\n",
    "\n",
    "    # 가장 큰 iou가 임계값보다 작으면 예측 상자에 개체가 포함되지 않은 것으로 간주되고 배경 상자로 설정 \n",
    "    respond_bgd = (1.0 - respond_bbox) * tf.cast( max_iou < iou_loss_thresh, tf.float32 )\n",
    "\n",
    "    conf_focal = tf.pow(respond_bbox - pred_conf, 2)\n",
    "\n",
    "    # confidence의 손실 계산  \n",
    "    # 그리드에 객체가 포함된 경우 1, 그렇지 않을경우 0  \n",
    "    conf_loss = conf_focal * (\n",
    "        respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=respond_bbox, logits=conv_raw_conf)\n",
    "        + \n",
    "        respond_bgd * tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "            labels=respond_bbox, logits=conv_raw_conf) \n",
    "    )\n",
    "\n",
    "    prob_loss = respond_bbox * tf.nn.sigmoid_cross_entropy_with_logits(\n",
    "        labels=label_prob, logits=conv_raw_prob)\n",
    "\n",
    "    giou_loss = tf.reduce_mean(tf.reduce_sum(giou_loss, axis=[1,2,3,4])) \n",
    "    conf_loss = tf.reduce_mean(tf.reduce_sum(conf_loss, axis=[1,2,3,4])) \n",
    "    prob_loss = tf.reduce_mean(tf.reduce_sum(prob_loss, axis=[1,2,3,4])) \n",
    "\n",
    "    return giou_loss, conf_loss, prob_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14709249",
   "metadata": {},
   "source": [
    "## 학습 단계 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e18d7b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_step(model, image_data, target, lr_init=1e-4, lr_end=1e-6):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = model(image_data, training=True)\n",
    "        giou_loss = conf_loss = prob_loss = 0\n",
    "\n",
    "        # 손실값 계산 \n",
    "        grid = 3\n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "        gradients = tape.gradient(total_loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "        # 학습률 업데이트 \n",
    "        # 워밍업 참고: https://arxiv.org/abs/1812.01187\n",
    "        global_steps.assign_add(1)\n",
    "        if global_steps < warmup_steps:\n",
    "            lr = global_steps / warmup_steps * lr_init\n",
    "        else:\n",
    "            lr = lr_end + 0.5 * (lr_init - lr_end) * ((1 + tf.cos((global_steps - warmup_steps) / (total_steps - warmup_steps) * np.pi)))\n",
    "        optimizer.lr.assign(lr.numpy())\n",
    "\n",
    "        # Loss를 로그에 저장 \n",
    "        with writer.as_default():\n",
    "            tf.summary.scalar(\"lr\", optimizer.lr,\n",
    "                              step=global_steps)\n",
    "            tf.summary.scalar(\"loss/total_loss\", total_loss,\n",
    "                              step=global_steps)\n",
    "            tf.summary.scalar(\"loss/giou_loss\", giou_loss,\n",
    "                              step=global_steps)\n",
    "            tf.summary.scalar(\"loss/conf_loss\", conf_loss,\n",
    "                              step=global_steps)\n",
    "            tf.summary.scalar(\"loss/prob_loss\", prob_loss,\n",
    "                              step=global_steps)\n",
    "        writer.flush()\n",
    "\n",
    "    return global_steps.numpy(), optimizer.lr.numpy(), giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d945f35",
   "metadata": {},
   "source": [
    "## 검증 단계 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0ef05b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_step(model, image_data, target):\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred_result = model(image_data, training=False)\n",
    "        giou_loss = conf_loss = prob_loss = 0 \n",
    "\n",
    "        grid = 3 \n",
    "        for i in range(grid):\n",
    "            conv, pred = pred_result[i*2], pred_result[i*2+1]\n",
    "            loss_items = compute_loss(pred, conv, *target[i], i)\n",
    "            giou_loss += loss_items[0]\n",
    "            conf_loss += loss_items[1]\n",
    "            prob_loss += loss_items[2]\n",
    "\n",
    "        total_loss = giou_loss + conf_loss + prob_loss\n",
    "\n",
    "    return giou_loss.numpy(), conf_loss.numpy(), prob_loss.numpy(), total_loss.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43104949",
   "metadata": {},
   "source": [
    "# 모듈 불러와 학습 모델 만들기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43a40aa3",
   "metadata": {},
   "source": [
    "## 데이터 생성기 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "cdcd721c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from config import *\n",
    "from data import DataGenerator \n",
    "\n",
    "trainset = DataGenerator(data_path=TRAIN_DATA_PATH,\n",
    "                         annot_path=TRAIN_ANNOT_PATH,\n",
    "                         class_label_path=CLASS_LABEL_PATH)\n",
    "testset = DataGenerator(data_path=TEST_DATA_PATH, \n",
    "                        annot_path=TEST_ANNOT_PATH,\n",
    "                        class_label_path=CLASS_LABEL_PATH)\n",
    "steps_per_epoch = len(trainset)\n",
    "global_steps = tf.Variable(1, trainable=False, dtype=tf.int64) \n",
    "warmup_steps = WARMUP_EPOCHS * steps_per_epoch\n",
    "total_steps = EPOCHS * steps_per_epoch\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d36b06a2",
   "metadata": {},
   "source": [
    "## 학습시키기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c1a1ab4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs []\n",
      "epoch: 0 step:    2/192, lr:0.000001, giou_loss:  58.72, conf_loss:1762.82, prob_loss: 104.26, total_loss:1925.80\n",
      "epoch: 0 step:    3/192, lr:0.000001, giou_loss:  55.77, conf_loss:1693.96, prob_loss:  98.69, total_loss:1848.42\n",
      "epoch: 0 step:    4/192, lr:0.000001, giou_loss:  45.37, conf_loss:1717.13, prob_loss:  82.81, total_loss:1845.31\n",
      "epoch: 0 step:    5/192, lr:0.000001, giou_loss:  56.32, conf_loss:1702.26, prob_loss:  96.26, total_loss:1854.84\n",
      "epoch: 0 step:    6/192, lr:0.000002, giou_loss:  56.71, conf_loss:1690.89, prob_loss:  94.37, total_loss:1841.97\n",
      "epoch: 0 step:    7/192, lr:0.000002, giou_loss:  33.52, conf_loss:1690.48, prob_loss:  62.78, total_loss:1786.78\n",
      "epoch: 0 step:    8/192, lr:0.000002, giou_loss:  28.90, conf_loss:1689.69, prob_loss:  49.68, total_loss:1768.27\n",
      "epoch: 0 step:    9/192, lr:0.000002, giou_loss:  50.35, conf_loss:1694.33, prob_loss:  88.90, total_loss:1833.57\n",
      "epoch: 0 step:   10/192, lr:0.000003, giou_loss:  48.80, conf_loss:1666.26, prob_loss:  88.74, total_loss:1803.80\n",
      "epoch: 0 step:   11/192, lr:0.000003, giou_loss:  35.97, conf_loss:1674.71, prob_loss:  55.26, total_loss:1765.93\n",
      "epoch: 0 step:   12/192, lr:0.000003, giou_loss:  50.60, conf_loss:1648.50, prob_loss:  87.51, total_loss:1786.61\n",
      "epoch: 0 step:   13/192, lr:0.000003, giou_loss:  50.71, conf_loss:1659.79, prob_loss:  88.41, total_loss:1798.91\n",
      "epoch: 0 step:   14/192, lr:0.000004, giou_loss:  46.60, conf_loss:1654.02, prob_loss:  74.22, total_loss:1774.84\n",
      "epoch: 0 step:   15/192, lr:0.000004, giou_loss:  56.49, conf_loss:1653.09, prob_loss:  90.08, total_loss:1799.67\n",
      "epoch: 0 step:   16/192, lr:0.000004, giou_loss:  54.49, conf_loss:1607.17, prob_loss:  96.23, total_loss:1757.89\n",
      "epoch: 0 step:   17/192, lr:0.000004, giou_loss:  42.20, conf_loss:1609.38, prob_loss:  71.87, total_loss:1723.44\n",
      "epoch: 0 step:   18/192, lr:0.000005, giou_loss:  37.26, conf_loss:1574.08, prob_loss:  67.29, total_loss:1678.63\n",
      "epoch: 0 step:   19/192, lr:0.000005, giou_loss:  55.10, conf_loss:1567.84, prob_loss:  97.41, total_loss:1720.34\n",
      "epoch: 0 step:   20/192, lr:0.000005, giou_loss:  66.64, conf_loss:1553.05, prob_loss: 118.72, total_loss:1738.41\n",
      "epoch: 0 step:   21/192, lr:0.000005, giou_loss:  42.51, conf_loss:1539.98, prob_loss:  75.73, total_loss:1658.22\n",
      "epoch: 0 step:   22/192, lr:0.000006, giou_loss:  48.33, conf_loss:1524.23, prob_loss:  92.17, total_loss:1664.73\n",
      "epoch: 0 step:   23/192, lr:0.000006, giou_loss:  59.08, conf_loss:1519.32, prob_loss:  99.17, total_loss:1677.57\n",
      "epoch: 0 step:   24/192, lr:0.000006, giou_loss:  57.75, conf_loss:1493.35, prob_loss: 100.93, total_loss:1652.03\n",
      "epoch: 0 step:   25/192, lr:0.000007, giou_loss:  45.43, conf_loss:1495.40, prob_loss:  82.33, total_loss:1623.17\n",
      "epoch: 0 step:   26/192, lr:0.000007, giou_loss:  50.58, conf_loss:1469.71, prob_loss:  89.11, total_loss:1609.40\n",
      "epoch: 0 step:   27/192, lr:0.000007, giou_loss:  46.68, conf_loss:1450.31, prob_loss:  79.02, total_loss:1576.01\n",
      "epoch: 0 step:   28/192, lr:0.000007, giou_loss:  54.88, conf_loss:1425.44, prob_loss:  94.49, total_loss:1574.81\n",
      "epoch: 0 step:   29/192, lr:0.000008, giou_loss:  33.89, conf_loss:1429.27, prob_loss:  63.85, total_loss:1527.00\n",
      "epoch: 0 step:   30/192, lr:0.000008, giou_loss:  48.73, conf_loss:1425.12, prob_loss:  91.66, total_loss:1565.50\n",
      "epoch: 0 step:   31/192, lr:0.000008, giou_loss:  45.05, conf_loss:1409.55, prob_loss:  81.80, total_loss:1536.40\n",
      "epoch: 0 step:   32/192, lr:0.000008, giou_loss:  36.70, conf_loss:1392.57, prob_loss:  68.88, total_loss:1498.15\n",
      "epoch: 0 step:   33/192, lr:0.000009, giou_loss:  30.47, conf_loss:1389.83, prob_loss:  56.88, total_loss:1477.18\n",
      "epoch: 0 step:   34/192, lr:0.000009, giou_loss:  38.10, conf_loss:1368.27, prob_loss:  74.96, total_loss:1481.33\n",
      "epoch: 0 step:   35/192, lr:0.000009, giou_loss:  26.72, conf_loss:1359.44, prob_loss:  53.88, total_loss:1440.05\n",
      "epoch: 0 step:   36/192, lr:0.000009, giou_loss:  41.37, conf_loss:1353.27, prob_loss:  78.76, total_loss:1473.40\n",
      "epoch: 0 step:   37/192, lr:0.000010, giou_loss:  38.22, conf_loss:1342.98, prob_loss:  72.64, total_loss:1453.84\n",
      "epoch: 0 step:   38/192, lr:0.000010, giou_loss:  50.82, conf_loss:1331.03, prob_loss:  89.02, total_loss:1470.87\n",
      "epoch: 0 step:   39/192, lr:0.000010, giou_loss:  34.90, conf_loss:1324.39, prob_loss:  69.14, total_loss:1428.43\n",
      "epoch: 0 step:   40/192, lr:0.000010, giou_loss:  39.87, conf_loss:1309.41, prob_loss:  71.58, total_loss:1420.87\n",
      "epoch: 0 step:   41/192, lr:0.000011, giou_loss:  31.80, conf_loss:1303.89, prob_loss:  56.42, total_loss:1392.11\n",
      "epoch: 0 step:   42/192, lr:0.000011, giou_loss:  28.80, conf_loss:1297.37, prob_loss:  55.02, total_loss:1381.18\n",
      "epoch: 0 step:   43/192, lr:0.000011, giou_loss:  26.84, conf_loss:1284.89, prob_loss:  52.88, total_loss:1364.60\n",
      "epoch: 0 step:   44/192, lr:0.000011, giou_loss:  35.53, conf_loss:1272.30, prob_loss:  65.43, total_loss:1373.25\n",
      "epoch: 0 step:   45/192, lr:0.000012, giou_loss:  44.93, conf_loss:1262.28, prob_loss:  85.93, total_loss:1393.14\n",
      "epoch: 0 step:   46/192, lr:0.000012, giou_loss:  39.01, conf_loss:1240.04, prob_loss:  74.19, total_loss:1353.24\n",
      "epoch: 0 step:   47/192, lr:0.000012, giou_loss:  51.15, conf_loss:1246.57, prob_loss:  96.14, total_loss:1393.86\n",
      "epoch: 0 step:   48/192, lr:0.000012, giou_loss:  33.29, conf_loss:1228.25, prob_loss:  62.77, total_loss:1324.31\n",
      "epoch: 0 step:   49/192, lr:0.000013, giou_loss:  39.17, conf_loss:1230.70, prob_loss:  74.50, total_loss:1344.37\n",
      "epoch: 0 step:   50/192, lr:0.000013, giou_loss:  31.38, conf_loss:1212.57, prob_loss:  55.01, total_loss:1298.97\n",
      "epoch: 0 step:   51/192, lr:0.000013, giou_loss:  28.71, conf_loss:1208.13, prob_loss:  54.33, total_loss:1291.17\n",
      "epoch: 0 step:   52/192, lr:0.000014, giou_loss:  45.79, conf_loss:1201.86, prob_loss:  86.34, total_loss:1333.99\n",
      "epoch: 0 step:   53/192, lr:0.000014, giou_loss:  34.32, conf_loss:1189.83, prob_loss:  63.71, total_loss:1287.86\n",
      "epoch: 0 step:   54/192, lr:0.000014, giou_loss:  43.10, conf_loss:1199.29, prob_loss:  76.48, total_loss:1318.87\n",
      "epoch: 0 step:   55/192, lr:0.000014, giou_loss:  46.20, conf_loss:1164.87, prob_loss:  82.66, total_loss:1293.74\n",
      "epoch: 0 step:   56/192, lr:0.000015, giou_loss:  52.11, conf_loss:1166.92, prob_loss:  94.67, total_loss:1313.69\n",
      "epoch: 0 step:   57/192, lr:0.000015, giou_loss:  44.84, conf_loss:1151.75, prob_loss:  82.21, total_loss:1278.80\n",
      "epoch: 0 step:   58/192, lr:0.000015, giou_loss:  43.95, conf_loss:1159.88, prob_loss:  87.08, total_loss:1290.91\n",
      "epoch: 0 step:   59/192, lr:0.000015, giou_loss:  32.60, conf_loss:1128.85, prob_loss:  62.51, total_loss:1223.96\n",
      "epoch: 0 step:   60/192, lr:0.000016, giou_loss:  51.20, conf_loss:1134.33, prob_loss:  97.44, total_loss:1282.98\n",
      "epoch: 0 step:   61/192, lr:0.000016, giou_loss:  53.66, conf_loss:1119.06, prob_loss:  98.06, total_loss:1270.77\n",
      "epoch: 0 step:   62/192, lr:0.000016, giou_loss:  34.32, conf_loss:1106.89, prob_loss:  64.74, total_loss:1205.96\n",
      "epoch: 0 step:   63/192, lr:0.000016, giou_loss:  33.93, conf_loss:1109.89, prob_loss:  65.93, total_loss:1209.75\n",
      "epoch: 0 step:   64/192, lr:0.000017, giou_loss:  35.04, conf_loss:1091.87, prob_loss:  72.40, total_loss:1199.31\n",
      "epoch: 0 step:   65/192, lr:0.000017, giou_loss:  37.65, conf_loss:1082.51, prob_loss:  66.95, total_loss:1187.11\n",
      "epoch: 0 step:   66/192, lr:0.000017, giou_loss:  32.14, conf_loss:1051.36, prob_loss:  60.02, total_loss:1143.53\n",
      "epoch: 0 step:   67/192, lr:0.000017, giou_loss:  32.49, conf_loss:1067.66, prob_loss:  57.10, total_loss:1157.25\n",
      "epoch: 0 step:   68/192, lr:0.000018, giou_loss:  34.75, conf_loss:1045.08, prob_loss:  64.86, total_loss:1144.69\n",
      "epoch: 0 step:   69/192, lr:0.000018, giou_loss:  33.04, conf_loss:1052.45, prob_loss:  66.32, total_loss:1151.81\n",
      "epoch: 0 step:   70/192, lr:0.000018, giou_loss:  46.26, conf_loss:1036.32, prob_loss:  82.86, total_loss:1165.45\n",
      "epoch: 0 step:   71/192, lr:0.000018, giou_loss:  42.48, conf_loss:1029.60, prob_loss:  79.47, total_loss:1151.55\n",
      "epoch: 0 step:   72/192, lr:0.000019, giou_loss:  28.82, conf_loss:1009.11, prob_loss:  56.63, total_loss:1094.56\n",
      "epoch: 0 step:   73/192, lr:0.000019, giou_loss:  42.79, conf_loss:1021.48, prob_loss:  80.38, total_loss:1144.65\n",
      "epoch: 0 step:   74/192, lr:0.000019, giou_loss:  32.10, conf_loss:1028.76, prob_loss:  56.15, total_loss:1117.01\n",
      "epoch: 0 step:   75/192, lr:0.000020, giou_loss:  31.56, conf_loss: 983.44, prob_loss:  59.86, total_loss:1074.86\n",
      "epoch: 0 step:   76/192, lr:0.000020, giou_loss:  40.74, conf_loss: 991.28, prob_loss:  76.19, total_loss:1108.21\n",
      "epoch: 0 step:   77/192, lr:0.000020, giou_loss:  37.88, conf_loss: 997.98, prob_loss:  70.65, total_loss:1106.50\n",
      "epoch: 0 step:   78/192, lr:0.000020, giou_loss:  27.53, conf_loss: 970.96, prob_loss:  51.47, total_loss:1049.96\n",
      "epoch: 0 step:   79/192, lr:0.000021, giou_loss:  27.77, conf_loss: 963.96, prob_loss:  53.85, total_loss:1045.59\n",
      "epoch: 0 step:   80/192, lr:0.000021, giou_loss:  36.95, conf_loss: 947.24, prob_loss:  66.66, total_loss:1050.85\n",
      "epoch: 0 step:   81/192, lr:0.000021, giou_loss:  43.42, conf_loss: 963.36, prob_loss:  79.10, total_loss:1085.89\n",
      "epoch: 0 step:   82/192, lr:0.000021, giou_loss:  31.55, conf_loss: 948.03, prob_loss:  54.98, total_loss:1034.56\n",
      "epoch: 0 step:   83/192, lr:0.000022, giou_loss:  39.41, conf_loss: 971.07, prob_loss:  71.09, total_loss:1081.57\n",
      "epoch: 0 step:   84/192, lr:0.000022, giou_loss:  44.74, conf_loss: 940.39, prob_loss:  79.75, total_loss:1064.88\n",
      "epoch: 0 step:   85/192, lr:0.000022, giou_loss:  39.30, conf_loss: 916.59, prob_loss:  69.58, total_loss:1025.47\n",
      "epoch: 0 step:   86/192, lr:0.000022, giou_loss:  31.27, conf_loss: 916.75, prob_loss:  57.95, total_loss:1005.96\n",
      "epoch: 0 step:   87/192, lr:0.000023, giou_loss:  29.15, conf_loss: 898.06, prob_loss:  53.48, total_loss: 980.70\n",
      "epoch: 0 step:   88/192, lr:0.000023, giou_loss:  18.67, conf_loss: 930.09, prob_loss:  32.54, total_loss: 981.30\n",
      "epoch: 0 step:   89/192, lr:0.000023, giou_loss:  28.47, conf_loss: 905.62, prob_loss:  49.70, total_loss: 983.80\n",
      "epoch: 0 step:   90/192, lr:0.000023, giou_loss:  26.48, conf_loss: 889.98, prob_loss:  48.84, total_loss: 965.29\n",
      "epoch: 0 step:   91/192, lr:0.000024, giou_loss:  30.93, conf_loss: 927.22, prob_loss:  53.46, total_loss:1011.61\n",
      "epoch: 0 step:   92/192, lr:0.000024, giou_loss:  28.87, conf_loss: 874.32, prob_loss:  49.47, total_loss: 952.66\n",
      "epoch: 0 step:   93/192, lr:0.000024, giou_loss:  37.88, conf_loss: 889.15, prob_loss:  64.57, total_loss: 991.60\n",
      "epoch: 0 step:   94/192, lr:0.000024, giou_loss:  28.34, conf_loss: 863.92, prob_loss:  51.13, total_loss: 943.40\n",
      "epoch: 0 step:   95/192, lr:0.000025, giou_loss:  38.59, conf_loss: 906.90, prob_loss:  64.59, total_loss:1010.07\n",
      "epoch: 0 step:   96/192, lr:0.000025, giou_loss:  27.32, conf_loss: 870.31, prob_loss:  47.21, total_loss: 944.85\n",
      "epoch: 0 step:   97/192, lr:0.000025, giou_loss:  23.80, conf_loss: 844.42, prob_loss:  38.88, total_loss: 907.11\n",
      "epoch: 0 step:   98/192, lr:0.000026, giou_loss:  31.03, conf_loss: 869.55, prob_loss:  52.41, total_loss: 952.99\n",
      "epoch: 0 step:   99/192, lr:0.000026, giou_loss:  30.68, conf_loss: 839.21, prob_loss:  52.81, total_loss: 922.69\n",
      "epoch: 0 step:  100/192, lr:0.000026, giou_loss:  27.40, conf_loss: 831.13, prob_loss:  49.91, total_loss: 908.44\n",
      "epoch: 0 step:  101/192, lr:0.000026, giou_loss:  32.91, conf_loss: 825.46, prob_loss:  59.19, total_loss: 917.55\n",
      "epoch: 0 step:  102/192, lr:0.000027, giou_loss:  28.47, conf_loss: 862.27, prob_loss:  48.28, total_loss: 939.02\n",
      "epoch: 0 step:  103/192, lr:0.000027, giou_loss:  21.70, conf_loss: 841.28, prob_loss:  37.26, total_loss: 900.24\n",
      "epoch: 0 step:  104/192, lr:0.000027, giou_loss:  33.58, conf_loss: 836.22, prob_loss:  57.34, total_loss: 927.13\n",
      "epoch: 0 step:  105/192, lr:0.000027, giou_loss:  22.29, conf_loss: 811.25, prob_loss:  37.25, total_loss: 870.80\n",
      "epoch: 0 step:  106/192, lr:0.000028, giou_loss:  37.56, conf_loss: 851.75, prob_loss:  59.88, total_loss: 949.19\n",
      "epoch: 0 step:  107/192, lr:0.000028, giou_loss:  30.90, conf_loss: 801.17, prob_loss:  56.82, total_loss: 888.90\n",
      "epoch: 0 step:  108/192, lr:0.000028, giou_loss:  37.40, conf_loss: 787.77, prob_loss:  62.22, total_loss: 887.39\n",
      "epoch: 0 step:  109/192, lr:0.000028, giou_loss:  31.03, conf_loss: 792.20, prob_loss:  50.85, total_loss: 874.08\n",
      "epoch: 0 step:  110/192, lr:0.000029, giou_loss:  33.51, conf_loss: 809.38, prob_loss:  52.58, total_loss: 895.47\n",
      "epoch: 0 step:  111/192, lr:0.000029, giou_loss:  21.56, conf_loss: 808.26, prob_loss:  35.01, total_loss: 864.84\n",
      "epoch: 0 step:  112/192, lr:0.000029, giou_loss:  24.01, conf_loss: 767.68, prob_loss:  38.05, total_loss: 829.73\n",
      "epoch: 0 step:  113/192, lr:0.000029, giou_loss:  32.36, conf_loss: 766.15, prob_loss:  55.90, total_loss: 854.42\n",
      "epoch: 0 step:  114/192, lr:0.000030, giou_loss:  19.74, conf_loss: 774.86, prob_loss:  31.95, total_loss: 826.55\n",
      "epoch: 0 step:  115/192, lr:0.000030, giou_loss:  35.90, conf_loss: 771.53, prob_loss:  56.70, total_loss: 864.13\n",
      "epoch: 0 step:  116/192, lr:0.000030, giou_loss:  25.52, conf_loss: 755.57, prob_loss:  41.98, total_loss: 823.08\n",
      "epoch: 0 step:  117/192, lr:0.000030, giou_loss:  38.47, conf_loss: 753.89, prob_loss:  65.33, total_loss: 857.69\n",
      "epoch: 0 step:  118/192, lr:0.000031, giou_loss:  26.45, conf_loss: 762.65, prob_loss:  47.33, total_loss: 836.43\n",
      "epoch: 0 step:  119/192, lr:0.000031, giou_loss:  35.51, conf_loss: 751.87, prob_loss:  53.15, total_loss: 840.54\n",
      "epoch: 0 step:  120/192, lr:0.000031, giou_loss:  36.36, conf_loss: 746.23, prob_loss:  56.61, total_loss: 839.20\n",
      "epoch: 0 step:  121/192, lr:0.000032, giou_loss:  27.91, conf_loss: 762.63, prob_loss:  43.45, total_loss: 833.99\n",
      "epoch: 0 step:  122/192, lr:0.000032, giou_loss:  21.45, conf_loss: 725.30, prob_loss:  32.63, total_loss: 779.37\n",
      "epoch: 0 step:  123/192, lr:0.000032, giou_loss:  35.23, conf_loss: 733.52, prob_loss:  47.56, total_loss: 816.31\n",
      "epoch: 0 step:  124/192, lr:0.000032, giou_loss:  36.87, conf_loss: 726.49, prob_loss:  56.50, total_loss: 819.87\n",
      "epoch: 0 step:  125/192, lr:0.000033, giou_loss:  34.04, conf_loss: 742.89, prob_loss:  52.48, total_loss: 829.40\n",
      "epoch: 0 step:  126/192, lr:0.000033, giou_loss:  25.10, conf_loss: 734.09, prob_loss:  35.13, total_loss: 794.32\n",
      "epoch: 0 step:  127/192, lr:0.000033, giou_loss:  38.54, conf_loss: 714.76, prob_loss:  59.71, total_loss: 813.02\n",
      "epoch: 0 step:  128/192, lr:0.000033, giou_loss:  40.30, conf_loss: 705.25, prob_loss:  56.47, total_loss: 802.02\n",
      "epoch: 0 step:  129/192, lr:0.000034, giou_loss:  26.38, conf_loss: 711.43, prob_loss:  39.99, total_loss: 777.80\n",
      "epoch: 0 step:  130/192, lr:0.000034, giou_loss:  34.68, conf_loss: 709.89, prob_loss:  46.69, total_loss: 791.27\n",
      "epoch: 0 step:  131/192, lr:0.000034, giou_loss:  36.18, conf_loss: 709.45, prob_loss:  53.09, total_loss: 798.73\n",
      "epoch: 0 step:  132/192, lr:0.000034, giou_loss:  27.48, conf_loss: 711.18, prob_loss:  41.66, total_loss: 780.32\n",
      "epoch: 0 step:  133/192, lr:0.000035, giou_loss:  32.46, conf_loss: 701.60, prob_loss:  46.06, total_loss: 780.12\n",
      "epoch: 0 step:  134/192, lr:0.000035, giou_loss:  33.49, conf_loss: 687.38, prob_loss:  47.26, total_loss: 768.13\n",
      "epoch: 0 step:  135/192, lr:0.000035, giou_loss:  27.45, conf_loss: 681.78, prob_loss:  41.41, total_loss: 750.63\n",
      "epoch: 0 step:  136/192, lr:0.000035, giou_loss:  25.69, conf_loss: 674.55, prob_loss:  34.06, total_loss: 734.30\n",
      "epoch: 0 step:  137/192, lr:0.000036, giou_loss:  25.59, conf_loss: 679.24, prob_loss:  37.74, total_loss: 742.57\n",
      "epoch: 0 step:  138/192, lr:0.000036, giou_loss:  38.77, conf_loss: 689.11, prob_loss:  50.30, total_loss: 778.18\n",
      "epoch: 0 step:  139/192, lr:0.000036, giou_loss:  33.84, conf_loss: 666.03, prob_loss:  50.14, total_loss: 750.01\n",
      "epoch: 0 step:  140/192, lr:0.000036, giou_loss:  30.62, conf_loss: 653.40, prob_loss:  35.58, total_loss: 719.61\n",
      "epoch: 0 step:  141/192, lr:0.000037, giou_loss:  44.28, conf_loss: 673.48, prob_loss:  54.82, total_loss: 772.58\n",
      "epoch: 0 step:  142/192, lr:0.000037, giou_loss:  34.62, conf_loss: 645.48, prob_loss:  45.50, total_loss: 725.60\n",
      "epoch: 0 step:  143/192, lr:0.000037, giou_loss:  39.32, conf_loss: 662.89, prob_loss:  48.61, total_loss: 750.82\n",
      "epoch: 0 step:  144/192, lr:0.000038, giou_loss:  46.46, conf_loss: 657.01, prob_loss:  59.45, total_loss: 762.92\n",
      "epoch: 0 step:  145/192, lr:0.000038, giou_loss:  19.29, conf_loss: 648.72, prob_loss:  27.08, total_loss: 695.08\n",
      "epoch: 0 step:  146/192, lr:0.000038, giou_loss:  27.29, conf_loss: 643.42, prob_loss:  34.79, total_loss: 705.50\n",
      "epoch: 0 step:  147/192, lr:0.000038, giou_loss:  33.25, conf_loss: 640.38, prob_loss:  41.72, total_loss: 715.35\n",
      "epoch: 0 step:  148/192, lr:0.000039, giou_loss:  37.14, conf_loss: 642.71, prob_loss:  46.39, total_loss: 726.24\n",
      "epoch: 0 step:  149/192, lr:0.000039, giou_loss:  39.92, conf_loss: 642.45, prob_loss:  49.68, total_loss: 732.05\n",
      "epoch: 0 step:  150/192, lr:0.000039, giou_loss:  30.23, conf_loss: 616.94, prob_loss:  34.77, total_loss: 681.94\n",
      "epoch: 0 step:  151/192, lr:0.000039, giou_loss:  24.85, conf_loss: 625.37, prob_loss:  30.30, total_loss: 680.52\n",
      "epoch: 0 step:  152/192, lr:0.000040, giou_loss:  29.82, conf_loss: 624.73, prob_loss:  34.22, total_loss: 688.78\n",
      "epoch: 0 step:  153/192, lr:0.000040, giou_loss:  37.95, conf_loss: 628.40, prob_loss:  43.08, total_loss: 709.43\n",
      "epoch: 0 step:  154/192, lr:0.000040, giou_loss:  20.99, conf_loss: 610.25, prob_loss:  26.08, total_loss: 657.32\n",
      "epoch: 0 step:  155/192, lr:0.000040, giou_loss:  27.41, conf_loss: 600.95, prob_loss:  30.00, total_loss: 658.36\n",
      "epoch: 0 step:  156/192, lr:0.000041, giou_loss:  45.65, conf_loss: 602.03, prob_loss:  55.35, total_loss: 703.02\n",
      "epoch: 0 step:  157/192, lr:0.000041, giou_loss:  38.73, conf_loss: 602.31, prob_loss:  43.41, total_loss: 684.45\n",
      "epoch: 0 step:  158/192, lr:0.000041, giou_loss:  29.85, conf_loss: 603.52, prob_loss:  33.43, total_loss: 666.79\n",
      "epoch: 0 step:  159/192, lr:0.000041, giou_loss:  25.45, conf_loss: 583.85, prob_loss:  29.14, total_loss: 638.44\n",
      "epoch: 0 step:  160/192, lr:0.000042, giou_loss:  36.90, conf_loss: 595.26, prob_loss:  41.09, total_loss: 673.26\n",
      "epoch: 0 step:  161/192, lr:0.000042, giou_loss:  21.69, conf_loss: 599.63, prob_loss:  25.24, total_loss: 646.56\n",
      "epoch: 0 step:  162/192, lr:0.000042, giou_loss:  52.24, conf_loss: 591.42, prob_loss:  59.72, total_loss: 703.38\n",
      "epoch: 0 step:  163/192, lr:0.000042, giou_loss:  37.58, conf_loss: 582.54, prob_loss:  44.79, total_loss: 664.91\n",
      "epoch: 0 step:  164/192, lr:0.000043, giou_loss:  31.82, conf_loss: 568.07, prob_loss:  35.53, total_loss: 635.41\n",
      "epoch: 0 step:  165/192, lr:0.000043, giou_loss:  31.54, conf_loss: 573.44, prob_loss:  32.64, total_loss: 637.62\n",
      "epoch: 0 step:  166/192, lr:0.000043, giou_loss:  37.52, conf_loss: 576.40, prob_loss:  43.08, total_loss: 657.00\n",
      "epoch: 0 step:  167/192, lr:0.000043, giou_loss:  38.10, conf_loss: 575.42, prob_loss:  43.74, total_loss: 657.25\n",
      "epoch: 0 step:  168/192, lr:0.000044, giou_loss:  21.51, conf_loss: 566.30, prob_loss:  26.35, total_loss: 614.16\n",
      "epoch: 0 step:  169/192, lr:0.000044, giou_loss:  20.71, conf_loss: 551.21, prob_loss:  21.28, total_loss: 593.20\n",
      "epoch: 0 step:  170/192, lr:0.000044, giou_loss:  38.99, conf_loss: 555.74, prob_loss:  37.19, total_loss: 631.92\n",
      "epoch: 0 step:  171/192, lr:0.000045, giou_loss:  29.02, conf_loss: 552.78, prob_loss:  30.78, total_loss: 612.58\n",
      "epoch: 0 step:  172/192, lr:0.000045, giou_loss:  42.02, conf_loss: 559.53, prob_loss:  38.16, total_loss: 639.72\n",
      "epoch: 0 step:  173/192, lr:0.000045, giou_loss:  27.62, conf_loss: 545.93, prob_loss:  28.40, total_loss: 601.95\n",
      "epoch: 0 step:  174/192, lr:0.000045, giou_loss:  25.79, conf_loss: 552.71, prob_loss:  29.39, total_loss: 607.89\n",
      "epoch: 0 step:  175/192, lr:0.000046, giou_loss:  36.34, conf_loss: 546.79, prob_loss:  34.83, total_loss: 617.97\n",
      "epoch: 0 step:  176/192, lr:0.000046, giou_loss:  22.02, conf_loss: 531.07, prob_loss:  21.94, total_loss: 575.03\n",
      "epoch: 0 step:  177/192, lr:0.000046, giou_loss:  21.80, conf_loss: 520.05, prob_loss:  22.61, total_loss: 564.47\n",
      "epoch: 0 step:  178/192, lr:0.000046, giou_loss:  27.41, conf_loss: 529.03, prob_loss:  24.34, total_loss: 580.78\n",
      "epoch: 0 step:  179/192, lr:0.000047, giou_loss:  30.00, conf_loss: 520.13, prob_loss:  30.70, total_loss: 580.83\n",
      "epoch: 0 step:  180/192, lr:0.000047, giou_loss:  41.10, conf_loss: 531.96, prob_loss:  46.64, total_loss: 619.70\n",
      "epoch: 0 step:  181/192, lr:0.000047, giou_loss:  32.62, conf_loss: 516.18, prob_loss:  26.11, total_loss: 574.91\n",
      "epoch: 0 step:  182/192, lr:0.000047, giou_loss:  28.38, conf_loss: 507.85, prob_loss:  27.59, total_loss: 563.82\n",
      "epoch: 0 step:  183/192, lr:0.000048, giou_loss:  30.33, conf_loss: 505.60, prob_loss:  25.79, total_loss: 561.73\n",
      "epoch: 0 step:  184/192, lr:0.000048, giou_loss:  30.47, conf_loss: 498.77, prob_loss:  28.26, total_loss: 557.50\n",
      "epoch: 0 step:  185/192, lr:0.000048, giou_loss:  25.04, conf_loss: 495.83, prob_loss:  23.58, total_loss: 544.45\n",
      "epoch: 0 step:  186/192, lr:0.000048, giou_loss:  27.31, conf_loss: 494.32, prob_loss:  22.05, total_loss: 543.67\n",
      "epoch: 0 step:  187/192, lr:0.000049, giou_loss:  24.63, conf_loss: 489.65, prob_loss:  21.15, total_loss: 535.43\n",
      "epoch: 0 step:  188/192, lr:0.000049, giou_loss:  29.80, conf_loss: 482.03, prob_loss:  26.24, total_loss: 538.07\n",
      "epoch: 0 step:  189/192, lr:0.000049, giou_loss:  35.44, conf_loss: 485.58, prob_loss:  29.78, total_loss: 550.80\n",
      "epoch: 0 step:  190/192, lr:0.000049, giou_loss:  27.71, conf_loss: 481.17, prob_loss:  27.58, total_loss: 536.47\n",
      "epoch: 0 step:  191/192, lr:0.000050, giou_loss:  30.80, conf_loss: 478.55, prob_loss:  29.04, total_loss: 538.38\n",
      "epoch: 0 step:    0/192, lr:0.000050, giou_loss:  28.20, conf_loss: 470.25, prob_loss:  20.56, total_loss: 519.02\n",
      "epoch: 0 step:    1/192, lr:0.000050, giou_loss:  27.95, conf_loss: 466.17, prob_loss:  20.54, total_loss: 514.67\n",
      "epoch: 1 step:    2/192, lr:0.000051, giou_loss:  28.34, conf_loss: 464.43, prob_loss:  23.88, total_loss: 516.65\n",
      "epoch: 1 step:    3/192, lr:0.000051, giou_loss:  26.11, conf_loss: 462.75, prob_loss:  24.99, total_loss: 513.85\n",
      "epoch: 1 step:    4/192, lr:0.000051, giou_loss:  39.49, conf_loss: 470.45, prob_loss:  37.58, total_loss: 547.52\n",
      "epoch: 1 step:    5/192, lr:0.000051, giou_loss:  20.31, conf_loss: 457.41, prob_loss:  16.37, total_loss: 494.08\n",
      "epoch: 1 step:    6/192, lr:0.000052, giou_loss:  34.18, conf_loss: 460.55, prob_loss:  31.24, total_loss: 525.98\n",
      "epoch: 1 step:    7/192, lr:0.000052, giou_loss:  30.55, conf_loss: 450.77, prob_loss:  22.90, total_loss: 504.23\n",
      "epoch: 1 step:    8/192, lr:0.000052, giou_loss:  27.77, conf_loss: 444.64, prob_loss:  20.30, total_loss: 492.71\n",
      "epoch: 1 step:    9/192, lr:0.000052, giou_loss:  29.34, conf_loss: 442.36, prob_loss:  26.15, total_loss: 497.85\n",
      "epoch: 1 step:   10/192, lr:0.000053, giou_loss:  38.72, conf_loss: 446.99, prob_loss:  32.50, total_loss: 518.21\n",
      "epoch: 1 step:   11/192, lr:0.000053, giou_loss:  37.35, conf_loss: 447.46, prob_loss:  37.13, total_loss: 521.94\n",
      "epoch: 1 step:   12/192, lr:0.000053, giou_loss:  33.31, conf_loss: 438.66, prob_loss:  26.59, total_loss: 498.56\n",
      "epoch: 1 step:   13/192, lr:0.000053, giou_loss:  21.38, conf_loss: 425.38, prob_loss:  14.95, total_loss: 461.71\n",
      "epoch: 1 step:   14/192, lr:0.000054, giou_loss:  28.85, conf_loss: 430.66, prob_loss:  25.29, total_loss: 484.79\n",
      "epoch: 1 step:   15/192, lr:0.000054, giou_loss:  27.66, conf_loss: 428.64, prob_loss:  20.92, total_loss: 477.21\n",
      "epoch: 1 step:   16/192, lr:0.000054, giou_loss:  27.23, conf_loss: 424.30, prob_loss:  19.42, total_loss: 470.96\n",
      "epoch: 1 step:   17/192, lr:0.000054, giou_loss:  33.92, conf_loss: 414.08, prob_loss:  26.30, total_loss: 474.30\n",
      "epoch: 1 step:   18/192, lr:0.000055, giou_loss:  18.81, conf_loss: 415.30, prob_loss:  12.08, total_loss: 446.19\n",
      "epoch: 1 step:   19/192, lr:0.000055, giou_loss:  34.91, conf_loss: 414.94, prob_loss:  20.34, total_loss: 470.19\n",
      "epoch: 1 step:   20/192, lr:0.000055, giou_loss:  30.45, conf_loss: 421.59, prob_loss:  26.56, total_loss: 478.60\n",
      "epoch: 1 step:   21/192, lr:0.000055, giou_loss:  27.60, conf_loss: 402.76, prob_loss:  14.92, total_loss: 445.28\n",
      "epoch: 1 step:   22/192, lr:0.000056, giou_loss:  23.78, conf_loss: 400.48, prob_loss:  15.99, total_loss: 440.25\n",
      "epoch: 1 step:   23/192, lr:0.000056, giou_loss:  40.92, conf_loss: 411.39, prob_loss:  31.84, total_loss: 484.15\n",
      "epoch: 1 step:   24/192, lr:0.000056, giou_loss:  29.36, conf_loss: 402.24, prob_loss:  25.49, total_loss: 457.09\n",
      "epoch: 1 step:   25/192, lr:0.000057, giou_loss:  30.66, conf_loss: 394.48, prob_loss:  19.17, total_loss: 444.31\n",
      "epoch: 1 step:   26/192, lr:0.000057, giou_loss:  28.02, conf_loss: 391.22, prob_loss:  17.91, total_loss: 437.15\n",
      "epoch: 1 step:   27/192, lr:0.000057, giou_loss:  28.40, conf_loss: 389.55, prob_loss:  20.32, total_loss: 438.27\n",
      "epoch: 1 step:   28/192, lr:0.000057, giou_loss:  42.60, conf_loss: 394.48, prob_loss:  29.03, total_loss: 466.11\n",
      "epoch: 1 step:   29/192, lr:0.000058, giou_loss:  29.94, conf_loss: 385.68, prob_loss:  23.05, total_loss: 438.67\n",
      "epoch: 1 step:   30/192, lr:0.000058, giou_loss:  32.59, conf_loss: 385.27, prob_loss:  23.57, total_loss: 441.43\n",
      "epoch: 1 step:   31/192, lr:0.000058, giou_loss:  50.48, conf_loss: 390.18, prob_loss:  40.93, total_loss: 481.59\n",
      "epoch: 1 step:   32/192, lr:0.000058, giou_loss:  19.93, conf_loss: 372.44, prob_loss:  10.92, total_loss: 403.29\n",
      "epoch: 1 step:   33/192, lr:0.000059, giou_loss:  43.67, conf_loss: 395.46, prob_loss:  37.29, total_loss: 476.42\n",
      "epoch: 1 step:   34/192, lr:0.000059, giou_loss:  25.44, conf_loss: 371.28, prob_loss:  14.48, total_loss: 411.21\n",
      "epoch: 1 step:   35/192, lr:0.000059, giou_loss:  26.69, conf_loss: 368.05, prob_loss:  15.38, total_loss: 410.11\n",
      "epoch: 1 step:   36/192, lr:0.000059, giou_loss:  15.50, conf_loss: 371.71, prob_loss:   9.53, total_loss: 396.74\n",
      "epoch: 1 step:   37/192, lr:0.000060, giou_loss:  38.93, conf_loss: 365.13, prob_loss:  24.89, total_loss: 428.94\n",
      "epoch: 1 step:   38/192, lr:0.000060, giou_loss:  30.80, conf_loss: 368.41, prob_loss:  17.26, total_loss: 416.46\n",
      "epoch: 1 step:   39/192, lr:0.000060, giou_loss:  25.70, conf_loss: 364.78, prob_loss:  15.57, total_loss: 406.05\n",
      "epoch: 1 step:   40/192, lr:0.000060, giou_loss:  26.28, conf_loss: 355.50, prob_loss:  12.14, total_loss: 393.91\n",
      "epoch: 1 step:   41/192, lr:0.000061, giou_loss:  17.15, conf_loss: 350.24, prob_loss:   9.57, total_loss: 376.97\n",
      "epoch: 1 step:   42/192, lr:0.000061, giou_loss:  21.02, conf_loss: 348.69, prob_loss:  12.98, total_loss: 382.68\n",
      "epoch: 1 step:   43/192, lr:0.000061, giou_loss:  23.00, conf_loss: 345.89, prob_loss:  12.32, total_loss: 381.21\n",
      "epoch: 1 step:   44/192, lr:0.000061, giou_loss:  21.30, conf_loss: 345.84, prob_loss:  16.11, total_loss: 383.24\n",
      "epoch: 1 step:   45/192, lr:0.000062, giou_loss:  23.29, conf_loss: 341.90, prob_loss:   9.88, total_loss: 375.07\n",
      "epoch: 1 step:   46/192, lr:0.000062, giou_loss:  26.08, conf_loss: 341.53, prob_loss:  18.54, total_loss: 386.15\n",
      "epoch: 1 step:   47/192, lr:0.000062, giou_loss:  25.82, conf_loss: 342.65, prob_loss:  11.02, total_loss: 379.50\n",
      "epoch: 1 step:   48/192, lr:0.000063, giou_loss:  24.75, conf_loss: 333.81, prob_loss:  14.74, total_loss: 373.30\n",
      "epoch: 1 step:   49/192, lr:0.000063, giou_loss:  21.60, conf_loss: 331.58, prob_loss:  18.30, total_loss: 371.49\n",
      "epoch: 1 step:   50/192, lr:0.000063, giou_loss:  26.68, conf_loss: 324.97, prob_loss:  16.37, total_loss: 368.03\n",
      "epoch: 1 step:   51/192, lr:0.000063, giou_loss:  32.10, conf_loss: 335.70, prob_loss:  20.73, total_loss: 388.53\n",
      "epoch: 1 step:   52/192, lr:0.000064, giou_loss:  36.36, conf_loss: 337.56, prob_loss:  28.67, total_loss: 402.59\n",
      "epoch: 1 step:   53/192, lr:0.000064, giou_loss:  25.94, conf_loss: 334.01, prob_loss:  17.10, total_loss: 377.06\n",
      "epoch: 1 step:   54/192, lr:0.000064, giou_loss:  30.47, conf_loss: 321.21, prob_loss:  17.25, total_loss: 368.93\n",
      "epoch: 1 step:   55/192, lr:0.000064, giou_loss:  24.71, conf_loss: 326.26, prob_loss:  17.50, total_loss: 368.47\n",
      "epoch: 1 step:   56/192, lr:0.000065, giou_loss:  35.35, conf_loss: 325.26, prob_loss:  23.89, total_loss: 384.51\n",
      "epoch: 1 step:   57/192, lr:0.000065, giou_loss:  23.48, conf_loss: 311.11, prob_loss:  16.51, total_loss: 351.09\n",
      "epoch: 1 step:   58/192, lr:0.000065, giou_loss:  29.17, conf_loss: 312.39, prob_loss:  15.86, total_loss: 357.41\n",
      "epoch: 1 step:   59/192, lr:0.000065, giou_loss:  19.99, conf_loss: 308.07, prob_loss:  13.18, total_loss: 341.24\n",
      "epoch: 1 step:   60/192, lr:0.000066, giou_loss:  26.24, conf_loss: 303.60, prob_loss:  20.37, total_loss: 350.21\n",
      "epoch: 1 step:   61/192, lr:0.000066, giou_loss:  28.79, conf_loss: 306.73, prob_loss:  18.06, total_loss: 353.58\n",
      "epoch: 1 step:   62/192, lr:0.000066, giou_loss:  19.62, conf_loss: 301.30, prob_loss:  10.84, total_loss: 331.76\n",
      "epoch: 1 step:   63/192, lr:0.000066, giou_loss:  33.45, conf_loss: 304.41, prob_loss:  18.86, total_loss: 356.72\n",
      "epoch: 1 step:   64/192, lr:0.000067, giou_loss:  35.70, conf_loss: 307.54, prob_loss:  26.97, total_loss: 370.21\n",
      "epoch: 1 step:   65/192, lr:0.000067, giou_loss:  25.07, conf_loss: 296.80, prob_loss:  18.63, total_loss: 340.50\n",
      "epoch: 1 step:   66/192, lr:0.000067, giou_loss:  25.98, conf_loss: 288.59, prob_loss:  16.96, total_loss: 331.53\n",
      "epoch: 1 step:   67/192, lr:0.000067, giou_loss:  32.61, conf_loss: 289.93, prob_loss:  19.60, total_loss: 342.15\n",
      "epoch: 1 step:   68/192, lr:0.000068, giou_loss:  20.39, conf_loss: 288.23, prob_loss:   8.96, total_loss: 317.58\n",
      "epoch: 1 step:   69/192, lr:0.000068, giou_loss:  28.96, conf_loss: 289.42, prob_loss:  18.06, total_loss: 336.44\n",
      "epoch: 1 step:   70/192, lr:0.000068, giou_loss:  27.49, conf_loss: 290.28, prob_loss:  16.11, total_loss: 333.88\n",
      "epoch: 1 step:   71/192, lr:0.000068, giou_loss:  13.12, conf_loss: 287.73, prob_loss:   7.03, total_loss: 307.88\n",
      "epoch: 1 step:   72/192, lr:0.000069, giou_loss:  28.31, conf_loss: 280.66, prob_loss:  14.80, total_loss: 323.77\n",
      "epoch: 1 step:   73/192, lr:0.000069, giou_loss:  16.36, conf_loss: 275.63, prob_loss:   7.22, total_loss: 299.20\n",
      "epoch: 1 step:   74/192, lr:0.000069, giou_loss:  22.20, conf_loss: 282.24, prob_loss:  18.17, total_loss: 322.61\n",
      "epoch: 1 step:   75/192, lr:0.000070, giou_loss:  29.72, conf_loss: 274.98, prob_loss:  18.68, total_loss: 323.37\n",
      "epoch: 1 step:   76/192, lr:0.000070, giou_loss:  33.00, conf_loss: 279.77, prob_loss:  21.46, total_loss: 334.23\n",
      "epoch: 1 step:   77/192, lr:0.000070, giou_loss:  28.23, conf_loss: 270.79, prob_loss:  15.58, total_loss: 314.60\n",
      "epoch: 1 step:   78/192, lr:0.000070, giou_loss:  20.65, conf_loss: 276.35, prob_loss:  12.34, total_loss: 309.33\n",
      "epoch: 1 step:   79/192, lr:0.000071, giou_loss:  27.74, conf_loss: 267.84, prob_loss:  16.36, total_loss: 311.95\n",
      "epoch: 1 step:   80/192, lr:0.000071, giou_loss:  31.66, conf_loss: 269.90, prob_loss:  19.71, total_loss: 321.27\n",
      "epoch: 1 step:   81/192, lr:0.000071, giou_loss:  20.40, conf_loss: 264.39, prob_loss:  12.95, total_loss: 297.73\n",
      "epoch: 1 step:   82/192, lr:0.000071, giou_loss:  11.76, conf_loss: 261.64, prob_loss:   9.73, total_loss: 283.12\n",
      "epoch: 1 step:   83/192, lr:0.000072, giou_loss:  20.70, conf_loss: 253.92, prob_loss:   9.16, total_loss: 283.78\n",
      "epoch: 1 step:   84/192, lr:0.000072, giou_loss:  24.85, conf_loss: 265.74, prob_loss:  11.32, total_loss: 301.90\n",
      "epoch: 1 step:   85/192, lr:0.000072, giou_loss:  20.65, conf_loss: 254.38, prob_loss:   9.11, total_loss: 284.14\n",
      "epoch: 1 step:   86/192, lr:0.000072, giou_loss:  28.50, conf_loss: 254.73, prob_loss:  13.89, total_loss: 297.12\n",
      "epoch: 1 step:   87/192, lr:0.000073, giou_loss:  30.51, conf_loss: 252.48, prob_loss:  14.76, total_loss: 297.74\n",
      "epoch: 1 step:   88/192, lr:0.000073, giou_loss:  30.90, conf_loss: 253.19, prob_loss:  18.30, total_loss: 302.38\n",
      "epoch: 1 step:   89/192, lr:0.000073, giou_loss:  20.82, conf_loss: 247.75, prob_loss:  10.81, total_loss: 279.37\n",
      "epoch: 1 step:   90/192, lr:0.000073, giou_loss:  29.88, conf_loss: 249.53, prob_loss:  17.70, total_loss: 297.12\n",
      "epoch: 1 step:   91/192, lr:0.000074, giou_loss:  27.72, conf_loss: 251.07, prob_loss:  17.27, total_loss: 296.05\n",
      "epoch: 1 step:   92/192, lr:0.000074, giou_loss:  29.71, conf_loss: 241.80, prob_loss:  15.75, total_loss: 287.26\n",
      "epoch: 1 step:   93/192, lr:0.000074, giou_loss:  27.22, conf_loss: 238.17, prob_loss:  12.82, total_loss: 278.21\n",
      "epoch: 1 step:   94/192, lr:0.000074, giou_loss:  33.60, conf_loss: 247.92, prob_loss:  15.35, total_loss: 296.87\n",
      "epoch: 1 step:   95/192, lr:0.000075, giou_loss:  33.68, conf_loss: 241.77, prob_loss:  21.79, total_loss: 297.23\n",
      "epoch: 1 step:   96/192, lr:0.000075, giou_loss:  32.82, conf_loss: 239.28, prob_loss:  17.24, total_loss: 289.34\n",
      "epoch: 1 step:   97/192, lr:0.000075, giou_loss:  45.46, conf_loss: 243.67, prob_loss:  24.76, total_loss: 313.89\n",
      "epoch: 1 step:   98/192, lr:0.000076, giou_loss:  21.69, conf_loss: 240.05, prob_loss:  14.50, total_loss: 276.24\n",
      "epoch: 1 step:   99/192, lr:0.000076, giou_loss:  27.00, conf_loss: 230.11, prob_loss:  13.75, total_loss: 270.86\n",
      "epoch: 1 step:  100/192, lr:0.000076, giou_loss:  33.95, conf_loss: 234.39, prob_loss:  21.79, total_loss: 290.12\n",
      "epoch: 1 step:  101/192, lr:0.000076, giou_loss:  14.20, conf_loss: 231.61, prob_loss:   8.53, total_loss: 254.34\n",
      "epoch: 1 step:  102/192, lr:0.000077, giou_loss:  30.43, conf_loss: 233.51, prob_loss:  20.82, total_loss: 284.76\n",
      "epoch: 1 step:  103/192, lr:0.000077, giou_loss:  27.05, conf_loss: 227.13, prob_loss:  11.24, total_loss: 265.42\n",
      "epoch: 1 step:  104/192, lr:0.000077, giou_loss:  27.14, conf_loss: 219.90, prob_loss:  17.52, total_loss: 264.57\n",
      "epoch: 1 step:  105/192, lr:0.000077, giou_loss:  23.89, conf_loss: 223.27, prob_loss:  10.89, total_loss: 258.06\n",
      "epoch: 1 step:  106/192, lr:0.000078, giou_loss:  20.38, conf_loss: 220.97, prob_loss:  10.78, total_loss: 252.12\n",
      "epoch: 1 step:  107/192, lr:0.000078, giou_loss:  24.92, conf_loss: 225.94, prob_loss:  18.60, total_loss: 269.46\n",
      "epoch: 1 step:  108/192, lr:0.000078, giou_loss:  22.85, conf_loss: 214.11, prob_loss:   8.48, total_loss: 245.44\n",
      "epoch: 1 step:  109/192, lr:0.000078, giou_loss:  22.63, conf_loss: 214.51, prob_loss:  11.02, total_loss: 248.17\n",
      "epoch: 1 step:  110/192, lr:0.000079, giou_loss:  12.10, conf_loss: 208.44, prob_loss:   7.37, total_loss: 227.91\n",
      "epoch: 1 step:  111/192, lr:0.000079, giou_loss:  25.11, conf_loss: 217.01, prob_loss:  14.90, total_loss: 257.03\n",
      "epoch: 1 step:  112/192, lr:0.000079, giou_loss:  32.31, conf_loss: 220.04, prob_loss:  20.48, total_loss: 272.83\n",
      "epoch: 1 step:  113/192, lr:0.000079, giou_loss:  17.41, conf_loss: 205.29, prob_loss:   8.31, total_loss: 231.01\n",
      "epoch: 1 step:  114/192, lr:0.000080, giou_loss:  22.89, conf_loss: 206.63, prob_loss:  14.59, total_loss: 244.11\n",
      "epoch: 1 step:  115/192, lr:0.000080, giou_loss:  19.57, conf_loss: 202.31, prob_loss:   9.56, total_loss: 231.44\n",
      "epoch: 1 step:  116/192, lr:0.000080, giou_loss:  22.19, conf_loss: 203.83, prob_loss:  10.41, total_loss: 236.43\n",
      "epoch: 1 step:  117/192, lr:0.000080, giou_loss:  16.89, conf_loss: 201.83, prob_loss:   9.25, total_loss: 227.98\n",
      "epoch: 1 step:  118/192, lr:0.000081, giou_loss:  26.56, conf_loss: 206.28, prob_loss:  18.39, total_loss: 251.22\n",
      "epoch: 1 step:  119/192, lr:0.000081, giou_loss:  28.35, conf_loss: 203.47, prob_loss:  16.22, total_loss: 248.03\n",
      "epoch: 1 step:  120/192, lr:0.000081, giou_loss:  22.85, conf_loss: 195.86, prob_loss:   9.15, total_loss: 227.87\n",
      "epoch: 1 step:  121/192, lr:0.000082, giou_loss:  26.06, conf_loss: 197.19, prob_loss:  12.05, total_loss: 235.30\n",
      "epoch: 1 step:  122/192, lr:0.000082, giou_loss:  19.53, conf_loss: 189.86, prob_loss:   5.19, total_loss: 214.58\n",
      "epoch: 1 step:  123/192, lr:0.000082, giou_loss:  18.02, conf_loss: 190.25, prob_loss:   6.29, total_loss: 214.57\n",
      "epoch: 1 step:  124/192, lr:0.000082, giou_loss:  30.18, conf_loss: 193.62, prob_loss:  16.01, total_loss: 239.80\n",
      "epoch: 1 step:  125/192, lr:0.000083, giou_loss:  30.70, conf_loss: 199.58, prob_loss:  14.15, total_loss: 244.44\n",
      "epoch: 1 step:  126/192, lr:0.000083, giou_loss:  33.97, conf_loss: 196.98, prob_loss:  21.50, total_loss: 252.45\n",
      "epoch: 1 step:  127/192, lr:0.000083, giou_loss:  28.03, conf_loss: 194.25, prob_loss:  14.33, total_loss: 236.61\n",
      "epoch: 1 step:  128/192, lr:0.000083, giou_loss:  28.91, conf_loss: 192.84, prob_loss:  13.91, total_loss: 235.66\n",
      "epoch: 1 step:  129/192, lr:0.000084, giou_loss:  27.81, conf_loss: 190.49, prob_loss:  11.79, total_loss: 230.10\n",
      "epoch: 1 step:  130/192, lr:0.000084, giou_loss:  40.65, conf_loss: 197.81, prob_loss:  19.44, total_loss: 257.91\n",
      "epoch: 1 step:  131/192, lr:0.000084, giou_loss:  26.34, conf_loss: 191.46, prob_loss:  12.68, total_loss: 230.48\n",
      "epoch: 1 step:  132/192, lr:0.000084, giou_loss:  31.64, conf_loss: 193.42, prob_loss:  14.88, total_loss: 239.94\n",
      "epoch: 1 step:  133/192, lr:0.000085, giou_loss:  30.79, conf_loss: 185.70, prob_loss:  10.31, total_loss: 226.81\n",
      "epoch: 1 step:  134/192, lr:0.000085, giou_loss:  20.39, conf_loss: 191.47, prob_loss:  10.94, total_loss: 222.80\n",
      "epoch: 1 step:  135/192, lr:0.000085, giou_loss:  22.38, conf_loss: 178.19, prob_loss:   8.43, total_loss: 209.00\n",
      "epoch: 1 step:  136/192, lr:0.000085, giou_loss:  33.62, conf_loss: 182.92, prob_loss:  14.75, total_loss: 231.29\n",
      "epoch: 1 step:  137/192, lr:0.000086, giou_loss:  23.55, conf_loss: 180.80, prob_loss:   9.97, total_loss: 214.32\n",
      "epoch: 1 step:  138/192, lr:0.000086, giou_loss:  24.04, conf_loss: 181.16, prob_loss:  12.91, total_loss: 218.11\n",
      "epoch: 1 step:  139/192, lr:0.000086, giou_loss:  31.31, conf_loss: 180.23, prob_loss:  13.02, total_loss: 224.56\n",
      "epoch: 1 step:  140/192, lr:0.000086, giou_loss:  33.35, conf_loss: 183.17, prob_loss:  20.80, total_loss: 237.33\n",
      "epoch: 1 step:  141/192, lr:0.000087, giou_loss:  22.74, conf_loss: 175.92, prob_loss:   9.71, total_loss: 208.37\n",
      "epoch: 1 step:  142/192, lr:0.000087, giou_loss:  27.87, conf_loss: 171.13, prob_loss:  10.55, total_loss: 209.55\n",
      "epoch: 1 step:  143/192, lr:0.000087, giou_loss:  25.27, conf_loss: 176.25, prob_loss:  11.85, total_loss: 213.37\n",
      "epoch: 1 step:  144/192, lr:0.000087, giou_loss:  18.79, conf_loss: 174.07, prob_loss:  11.11, total_loss: 203.97\n",
      "epoch: 1 step:  145/192, lr:0.000088, giou_loss:  47.80, conf_loss: 190.22, prob_loss:  23.49, total_loss: 261.51\n",
      "epoch: 1 step:  146/192, lr:0.000088, giou_loss:  28.22, conf_loss: 171.53, prob_loss:  12.95, total_loss: 212.70\n",
      "epoch: 1 step:  147/192, lr:0.000088, giou_loss:  33.32, conf_loss: 169.30, prob_loss:  12.49, total_loss: 215.11\n",
      "epoch: 1 step:  148/192, lr:0.000089, giou_loss:  24.70, conf_loss: 165.97, prob_loss:   8.63, total_loss: 199.30\n",
      "epoch: 1 step:  149/192, lr:0.000089, giou_loss:  30.92, conf_loss: 160.99, prob_loss:  13.12, total_loss: 205.04\n",
      "epoch: 1 step:  150/192, lr:0.000089, giou_loss:  18.45, conf_loss: 162.13, prob_loss:   7.03, total_loss: 187.61\n",
      "epoch: 1 step:  151/192, lr:0.000089, giou_loss:  20.10, conf_loss: 169.05, prob_loss:  10.36, total_loss: 199.51\n",
      "epoch: 1 step:  152/192, lr:0.000090, giou_loss:  22.08, conf_loss: 168.14, prob_loss:  11.86, total_loss: 202.07\n",
      "epoch: 1 step:  153/192, lr:0.000090, giou_loss:  26.84, conf_loss: 168.23, prob_loss:  12.58, total_loss: 207.66\n",
      "epoch: 1 step:  154/192, lr:0.000090, giou_loss:  27.14, conf_loss: 161.63, prob_loss:   9.84, total_loss: 198.61\n",
      "epoch: 1 step:  155/192, lr:0.000090, giou_loss:  21.88, conf_loss: 160.10, prob_loss:   9.73, total_loss: 191.71\n",
      "epoch: 1 step:  156/192, lr:0.000091, giou_loss:  10.19, conf_loss: 159.02, prob_loss:   6.57, total_loss: 175.78\n",
      "epoch: 1 step:  157/192, lr:0.000091, giou_loss:  14.20, conf_loss: 156.78, prob_loss:   6.58, total_loss: 177.56\n",
      "epoch: 1 step:  158/192, lr:0.000091, giou_loss:  18.15, conf_loss: 152.69, prob_loss:   5.16, total_loss: 176.00\n",
      "epoch: 1 step:  159/192, lr:0.000091, giou_loss:  16.58, conf_loss: 150.44, prob_loss:   5.55, total_loss: 172.57\n",
      "epoch: 1 step:  160/192, lr:0.000092, giou_loss:  29.19, conf_loss: 166.23, prob_loss:  13.68, total_loss: 209.10\n",
      "epoch: 1 step:  161/192, lr:0.000092, giou_loss:  18.41, conf_loss: 156.03, prob_loss:   9.33, total_loss: 183.76\n",
      "epoch: 1 step:  162/192, lr:0.000092, giou_loss:  13.93, conf_loss: 142.22, prob_loss:   3.36, total_loss: 159.51\n",
      "epoch: 1 step:  163/192, lr:0.000092, giou_loss:  31.04, conf_loss: 157.70, prob_loss:  13.91, total_loss: 202.64\n",
      "epoch: 1 step:  164/192, lr:0.000093, giou_loss:  25.06, conf_loss: 152.83, prob_loss:   8.73, total_loss: 186.62\n",
      "epoch: 1 step:  165/192, lr:0.000093, giou_loss:  20.44, conf_loss: 146.18, prob_loss:   6.19, total_loss: 172.81\n",
      "epoch: 1 step:  166/192, lr:0.000093, giou_loss:  22.38, conf_loss: 146.83, prob_loss:   6.93, total_loss: 176.13\n",
      "epoch: 1 step:  167/192, lr:0.000093, giou_loss:  17.97, conf_loss: 145.26, prob_loss:   6.32, total_loss: 169.55\n",
      "epoch: 1 step:  168/192, lr:0.000094, giou_loss:  33.04, conf_loss: 153.33, prob_loss:  14.29, total_loss: 200.65\n",
      "epoch: 1 step:  169/192, lr:0.000094, giou_loss:  30.02, conf_loss: 150.36, prob_loss:  10.44, total_loss: 190.81\n",
      "epoch: 1 step:  170/192, lr:0.000094, giou_loss:  22.35, conf_loss: 139.75, prob_loss:   7.76, total_loss: 169.86\n",
      "epoch: 1 step:  171/192, lr:0.000095, giou_loss:  26.83, conf_loss: 145.47, prob_loss:  10.51, total_loss: 182.81\n",
      "epoch: 1 step:  172/192, lr:0.000095, giou_loss:  30.48, conf_loss: 149.02, prob_loss:  12.75, total_loss: 192.26\n",
      "epoch: 1 step:  173/192, lr:0.000095, giou_loss:  32.54, conf_loss: 148.15, prob_loss:  14.62, total_loss: 195.31\n",
      "epoch: 1 step:  174/192, lr:0.000095, giou_loss:  26.89, conf_loss: 138.10, prob_loss:  10.25, total_loss: 175.24\n",
      "epoch: 1 step:  175/192, lr:0.000096, giou_loss:  28.15, conf_loss: 141.11, prob_loss:  13.88, total_loss: 183.14\n",
      "epoch: 1 step:  176/192, lr:0.000096, giou_loss:  27.18, conf_loss: 146.00, prob_loss:  11.86, total_loss: 185.04\n",
      "epoch: 1 step:  177/192, lr:0.000096, giou_loss:  27.84, conf_loss: 137.15, prob_loss:  12.71, total_loss: 177.70\n",
      "epoch: 1 step:  178/192, lr:0.000096, giou_loss:  22.95, conf_loss: 138.18, prob_loss:  13.41, total_loss: 174.54\n",
      "epoch: 1 step:  179/192, lr:0.000097, giou_loss:  21.75, conf_loss: 139.26, prob_loss:  12.08, total_loss: 173.09\n",
      "epoch: 1 step:  180/192, lr:0.000097, giou_loss:  20.47, conf_loss: 136.30, prob_loss:   8.21, total_loss: 164.98\n",
      "epoch: 1 step:  181/192, lr:0.000097, giou_loss:  25.11, conf_loss: 137.02, prob_loss:  13.83, total_loss: 175.97\n",
      "epoch: 1 step:  182/192, lr:0.000097, giou_loss:  18.22, conf_loss: 130.52, prob_loss:   4.75, total_loss: 153.49\n",
      "epoch: 1 step:  183/192, lr:0.000098, giou_loss:  21.84, conf_loss: 133.19, prob_loss:   7.70, total_loss: 162.73\n",
      "epoch: 1 step:  184/192, lr:0.000098, giou_loss:  24.66, conf_loss: 134.15, prob_loss:   7.86, total_loss: 166.66\n",
      "epoch: 1 step:  185/192, lr:0.000098, giou_loss:  30.74, conf_loss: 133.61, prob_loss:  10.56, total_loss: 174.91\n",
      "epoch: 1 step:  186/192, lr:0.000098, giou_loss:  25.29, conf_loss: 134.78, prob_loss:  12.68, total_loss: 172.75\n",
      "epoch: 1 step:  187/192, lr:0.000099, giou_loss:  23.93, conf_loss: 131.02, prob_loss:   9.50, total_loss: 164.45\n",
      "epoch: 1 step:  188/192, lr:0.000099, giou_loss:  30.12, conf_loss: 131.57, prob_loss:   9.41, total_loss: 171.10\n",
      "epoch: 1 step:  189/192, lr:0.000099, giou_loss:  27.64, conf_loss: 134.35, prob_loss:  10.33, total_loss: 172.32\n",
      "epoch: 1 step:  190/192, lr:0.000099, giou_loss:  31.46, conf_loss: 135.47, prob_loss:  12.77, total_loss: 179.69\n",
      "epoch: 1 step:  191/192, lr:0.000100, giou_loss:  26.35, conf_loss: 126.80, prob_loss:   9.87, total_loss: 163.02\n",
      "epoch: 1 step:    0/192, lr:0.000100, giou_loss:  19.27, conf_loss: 128.26, prob_loss:   7.67, total_loss: 155.20\n",
      "epoch: 1 step:    1/192, lr:0.000100, giou_loss:  21.24, conf_loss: 123.65, prob_loss:   7.98, total_loss: 152.87\n",
      "epoch: 2 step:    2/192, lr:0.000100, giou_loss:  21.81, conf_loss: 122.52, prob_loss:   8.16, total_loss: 152.49\n",
      "epoch: 2 step:    3/192, lr:0.000100, giou_loss:  21.12, conf_loss: 127.62, prob_loss:   9.44, total_loss: 158.17\n",
      "epoch: 2 step:    4/192, lr:0.000100, giou_loss:  22.99, conf_loss: 125.65, prob_loss:  12.59, total_loss: 161.24\n",
      "epoch: 2 step:    5/192, lr:0.000100, giou_loss:  25.43, conf_loss: 122.35, prob_loss:  11.04, total_loss: 158.82\n",
      "epoch: 2 step:    6/192, lr:0.000100, giou_loss:  31.58, conf_loss: 128.90, prob_loss:  14.01, total_loss: 174.49\n",
      "epoch: 2 step:    7/192, lr:0.000100, giou_loss:  24.34, conf_loss: 121.77, prob_loss:  13.20, total_loss: 159.30\n",
      "epoch: 2 step:    8/192, lr:0.000100, giou_loss:  19.89, conf_loss: 122.61, prob_loss:   8.30, total_loss: 150.80\n",
      "epoch: 2 step:    9/192, lr:0.000100, giou_loss:  25.77, conf_loss: 116.14, prob_loss:  12.70, total_loss: 154.62\n",
      "epoch: 2 step:   10/192, lr:0.000100, giou_loss:  27.31, conf_loss: 122.05, prob_loss:  18.54, total_loss: 167.90\n",
      "epoch: 2 step:   11/192, lr:0.000100, giou_loss:  25.48, conf_loss: 119.31, prob_loss:   8.39, total_loss: 153.18\n",
      "epoch: 2 step:   12/192, lr:0.000100, giou_loss:  25.69, conf_loss: 115.75, prob_loss:  10.30, total_loss: 151.74\n",
      "epoch: 2 step:   13/192, lr:0.000100, giou_loss:  11.58, conf_loss: 120.04, prob_loss:   6.34, total_loss: 137.95\n",
      "epoch: 2 step:   14/192, lr:0.000100, giou_loss:  22.16, conf_loss: 110.73, prob_loss:   8.76, total_loss: 141.65\n",
      "epoch: 2 step:   15/192, lr:0.000100, giou_loss:  18.52, conf_loss: 116.46, prob_loss:   6.30, total_loss: 141.28\n",
      "epoch: 2 step:   16/192, lr:0.000100, giou_loss:  17.85, conf_loss: 114.62, prob_loss:   7.82, total_loss: 140.29\n",
      "epoch: 2 step:   17/192, lr:0.000100, giou_loss:  14.09, conf_loss: 118.08, prob_loss:   7.00, total_loss: 139.16\n",
      "epoch: 2 step:   18/192, lr:0.000100, giou_loss:  42.47, conf_loss: 136.47, prob_loss:  18.26, total_loss: 197.20\n",
      "epoch: 2 step:   19/192, lr:0.000100, giou_loss:  32.91, conf_loss: 132.77, prob_loss:  15.28, total_loss: 180.95\n",
      "epoch: 2 step:   20/192, lr:0.000100, giou_loss:  28.15, conf_loss: 119.85, prob_loss:   8.24, total_loss: 156.24\n",
      "epoch: 2 step:   21/192, lr:0.000100, giou_loss:  25.50, conf_loss: 111.62, prob_loss:   9.94, total_loss: 147.05\n",
      "epoch: 2 step:   22/192, lr:0.000100, giou_loss:  19.48, conf_loss: 106.60, prob_loss:   5.59, total_loss: 131.66\n",
      "epoch: 2 step:   23/192, lr:0.000100, giou_loss:  22.01, conf_loss: 111.01, prob_loss:   8.95, total_loss: 141.97\n",
      "epoch: 2 step:   24/192, lr:0.000100, giou_loss:  30.88, conf_loss: 125.78, prob_loss:  16.05, total_loss: 172.71\n",
      "epoch: 2 step:   25/192, lr:0.000100, giou_loss:  17.15, conf_loss: 104.17, prob_loss:   5.41, total_loss: 126.72\n",
      "epoch: 2 step:   26/192, lr:0.000100, giou_loss:  23.01, conf_loss: 108.36, prob_loss:   8.68, total_loss: 140.05\n",
      "epoch: 2 step:   27/192, lr:0.000100, giou_loss:  27.55, conf_loss: 109.95, prob_loss:  17.26, total_loss: 154.76\n",
      "epoch: 2 step:   28/192, lr:0.000100, giou_loss:  19.41, conf_loss: 105.85, prob_loss:   7.21, total_loss: 132.47\n",
      "epoch: 2 step:   29/192, lr:0.000100, giou_loss:  21.77, conf_loss: 108.72, prob_loss:   7.62, total_loss: 138.11\n",
      "epoch: 2 step:   30/192, lr:0.000100, giou_loss:  22.73, conf_loss: 105.75, prob_loss:   9.26, total_loss: 137.74\n",
      "epoch: 2 step:   31/192, lr:0.000100, giou_loss:  16.95, conf_loss: 106.98, prob_loss:   5.17, total_loss: 129.10\n",
      "epoch: 2 step:   32/192, lr:0.000100, giou_loss:  28.36, conf_loss: 107.35, prob_loss:   9.00, total_loss: 144.71\n",
      "epoch: 2 step:   33/192, lr:0.000100, giou_loss:  26.90, conf_loss: 107.30, prob_loss:   9.93, total_loss: 144.13\n",
      "epoch: 2 step:   34/192, lr:0.000100, giou_loss:  25.14, conf_loss: 108.63, prob_loss:   9.70, total_loss: 143.47\n",
      "epoch: 2 step:   35/192, lr:0.000100, giou_loss:  20.55, conf_loss: 100.76, prob_loss:   7.40, total_loss: 128.72\n",
      "epoch: 2 step:   36/192, lr:0.000100, giou_loss:  20.63, conf_loss: 106.90, prob_loss:   9.09, total_loss: 136.63\n",
      "epoch: 2 step:   37/192, lr:0.000100, giou_loss:  23.60, conf_loss: 109.03, prob_loss:  10.69, total_loss: 143.31\n",
      "epoch: 2 step:   38/192, lr:0.000100, giou_loss:  24.90, conf_loss: 104.07, prob_loss:   8.42, total_loss: 137.39\n",
      "epoch: 2 step:   39/192, lr:0.000100, giou_loss:  24.56, conf_loss: 107.72, prob_loss:   7.95, total_loss: 140.24\n",
      "epoch: 2 step:   40/192, lr:0.000100, giou_loss:  18.06, conf_loss: 103.17, prob_loss:   7.01, total_loss: 128.25\n",
      "epoch: 2 step:   41/192, lr:0.000100, giou_loss:  24.69, conf_loss: 105.21, prob_loss:  11.97, total_loss: 141.86\n",
      "epoch: 2 step:   42/192, lr:0.000100, giou_loss:  15.51, conf_loss: 113.25, prob_loss:   8.60, total_loss: 137.36\n",
      "epoch: 2 step:   43/192, lr:0.000100, giou_loss:  24.06, conf_loss: 104.08, prob_loss:  12.31, total_loss: 140.45\n",
      "epoch: 2 step:   44/192, lr:0.000100, giou_loss:  21.74, conf_loss:  97.54, prob_loss:   5.28, total_loss: 124.56\n",
      "epoch: 2 step:   45/192, lr:0.000100, giou_loss:  21.02, conf_loss:  99.78, prob_loss:   9.83, total_loss: 130.62\n",
      "epoch: 2 step:   46/192, lr:0.000100, giou_loss:  19.15, conf_loss:  98.13, prob_loss:   9.62, total_loss: 126.91\n",
      "epoch: 2 step:   47/192, lr:0.000100, giou_loss:  22.61, conf_loss: 100.24, prob_loss:   8.37, total_loss: 131.22\n",
      "epoch: 2 step:   48/192, lr:0.000100, giou_loss:  19.75, conf_loss:  96.13, prob_loss:   6.19, total_loss: 122.07\n",
      "epoch: 2 step:   49/192, lr:0.000100, giou_loss:  20.46, conf_loss:  97.76, prob_loss:   7.03, total_loss: 125.24\n",
      "epoch: 2 step:   50/192, lr:0.000100, giou_loss:  20.51, conf_loss:  98.75, prob_loss:   9.30, total_loss: 128.56\n",
      "epoch: 2 step:   51/192, lr:0.000100, giou_loss:  22.27, conf_loss: 101.59, prob_loss:  11.31, total_loss: 135.17\n",
      "epoch: 2 step:   52/192, lr:0.000100, giou_loss:  21.17, conf_loss:  97.00, prob_loss:  10.21, total_loss: 128.38\n",
      "epoch: 2 step:   53/192, lr:0.000100, giou_loss:  22.67, conf_loss:  95.73, prob_loss:   7.79, total_loss: 126.18\n",
      "epoch: 2 step:   54/192, lr:0.000100, giou_loss:  27.62, conf_loss:  99.48, prob_loss:  11.99, total_loss: 139.09\n",
      "epoch: 2 step:   55/192, lr:0.000100, giou_loss:  25.29, conf_loss:  94.14, prob_loss:   9.23, total_loss: 128.66\n",
      "epoch: 2 step:   56/192, lr:0.000100, giou_loss:  28.09, conf_loss:  98.73, prob_loss:  11.01, total_loss: 137.83\n",
      "epoch: 2 step:   57/192, lr:0.000100, giou_loss:  26.45, conf_loss:  91.07, prob_loss:  10.71, total_loss: 128.24\n",
      "epoch: 2 step:   58/192, lr:0.000100, giou_loss:  26.66, conf_loss:  95.52, prob_loss:   8.14, total_loss: 130.33\n",
      "epoch: 2 step:   59/192, lr:0.000100, giou_loss:  29.27, conf_loss: 104.39, prob_loss:  12.30, total_loss: 145.95\n",
      "epoch: 2 step:   60/192, lr:0.000100, giou_loss:  19.04, conf_loss:  87.00, prob_loss:   4.82, total_loss: 110.87\n",
      "epoch: 2 step:   61/192, lr:0.000100, giou_loss:  18.49, conf_loss:  90.96, prob_loss:   5.88, total_loss: 115.33\n",
      "epoch: 2 step:   62/192, lr:0.000100, giou_loss:  19.07, conf_loss:  88.44, prob_loss:   8.13, total_loss: 115.63\n",
      "epoch: 2 step:   63/192, lr:0.000100, giou_loss:  12.80, conf_loss:  87.71, prob_loss:   4.18, total_loss: 104.69\n",
      "epoch: 2 step:   64/192, lr:0.000100, giou_loss:  21.95, conf_loss:  93.10, prob_loss:   7.27, total_loss: 122.32\n",
      "epoch: 2 step:   65/192, lr:0.000100, giou_loss:  18.11, conf_loss:  88.49, prob_loss:   7.78, total_loss: 114.37\n",
      "epoch: 2 step:   66/192, lr:0.000100, giou_loss:  22.64, conf_loss:  89.74, prob_loss:   7.19, total_loss: 119.57\n",
      "epoch: 2 step:   67/192, lr:0.000100, giou_loss:  38.78, conf_loss: 107.29, prob_loss:  17.73, total_loss: 163.79\n",
      "epoch: 2 step:   68/192, lr:0.000100, giou_loss:  23.79, conf_loss:  92.26, prob_loss:   9.79, total_loss: 125.84\n",
      "epoch: 2 step:   69/192, lr:0.000100, giou_loss:  25.12, conf_loss:  90.33, prob_loss:  10.92, total_loss: 126.36\n",
      "epoch: 2 step:   70/192, lr:0.000100, giou_loss:  23.53, conf_loss:  87.14, prob_loss:   8.17, total_loss: 118.84\n",
      "epoch: 2 step:   71/192, lr:0.000100, giou_loss:  22.77, conf_loss:  91.28, prob_loss:  11.10, total_loss: 125.15\n",
      "epoch: 2 step:   72/192, lr:0.000100, giou_loss:  15.73, conf_loss:  85.42, prob_loss:   4.60, total_loss: 105.74\n",
      "epoch: 2 step:   73/192, lr:0.000100, giou_loss:  19.20, conf_loss:  94.09, prob_loss:   6.58, total_loss: 119.87\n",
      "epoch: 2 step:   74/192, lr:0.000100, giou_loss:  19.59, conf_loss:  90.19, prob_loss:   7.19, total_loss: 116.97\n",
      "epoch: 2 step:   75/192, lr:0.000100, giou_loss:  20.32, conf_loss:  83.41, prob_loss:   8.54, total_loss: 112.27\n",
      "epoch: 2 step:   76/192, lr:0.000100, giou_loss:  22.68, conf_loss:  91.31, prob_loss:   9.34, total_loss: 123.33\n",
      "epoch: 2 step:   77/192, lr:0.000100, giou_loss:  24.12, conf_loss:  87.45, prob_loss:   8.09, total_loss: 119.66\n",
      "epoch: 2 step:   78/192, lr:0.000100, giou_loss:  26.77, conf_loss:  90.18, prob_loss:  13.56, total_loss: 130.51\n",
      "epoch: 2 step:   79/192, lr:0.000100, giou_loss:  21.20, conf_loss:  89.67, prob_loss:  10.67, total_loss: 121.54\n",
      "epoch: 2 step:   80/192, lr:0.000100, giou_loss:  31.81, conf_loss:  93.60, prob_loss:  16.51, total_loss: 141.92\n",
      "epoch: 2 step:   81/192, lr:0.000100, giou_loss:  20.27, conf_loss:  88.02, prob_loss:   9.61, total_loss: 117.90\n",
      "epoch: 2 step:   82/192, lr:0.000100, giou_loss:  23.45, conf_loss:  83.64, prob_loss:   8.83, total_loss: 115.92\n",
      "epoch: 2 step:   83/192, lr:0.000100, giou_loss:  16.12, conf_loss:  77.80, prob_loss:   4.39, total_loss:  98.30\n",
      "epoch: 2 step:   84/192, lr:0.000100, giou_loss:  27.36, conf_loss:  87.73, prob_loss:   8.55, total_loss: 123.64\n",
      "epoch: 2 step:   85/192, lr:0.000100, giou_loss:  36.40, conf_loss: 101.32, prob_loss:  15.80, total_loss: 153.52\n",
      "epoch: 2 step:   86/192, lr:0.000100, giou_loss:  16.60, conf_loss:  86.40, prob_loss:   6.54, total_loss: 109.54\n",
      "epoch: 2 step:   87/192, lr:0.000100, giou_loss:  16.85, conf_loss:  80.75, prob_loss:   5.07, total_loss: 102.68\n",
      "epoch: 2 step:   88/192, lr:0.000100, giou_loss:  28.96, conf_loss:  85.53, prob_loss:  11.21, total_loss: 125.70\n",
      "epoch: 2 step:   89/192, lr:0.000100, giou_loss:  37.95, conf_loss: 103.54, prob_loss:  17.11, total_loss: 158.60\n",
      "epoch: 2 step:   90/192, lr:0.000100, giou_loss:  20.19, conf_loss:  83.35, prob_loss:   7.53, total_loss: 111.06\n",
      "epoch: 2 step:   91/192, lr:0.000100, giou_loss:  19.80, conf_loss:  86.55, prob_loss:   7.16, total_loss: 113.50\n",
      "epoch: 2 step:   92/192, lr:0.000100, giou_loss:  20.83, conf_loss:  82.99, prob_loss:   8.24, total_loss: 112.05\n",
      "epoch: 2 step:   93/192, lr:0.000100, giou_loss:  20.82, conf_loss:  86.27, prob_loss:   7.23, total_loss: 114.32\n",
      "epoch: 2 step:   94/192, lr:0.000100, giou_loss:  26.86, conf_loss:  87.43, prob_loss:  12.56, total_loss: 126.84\n",
      "epoch: 2 step:   95/192, lr:0.000100, giou_loss:  21.69, conf_loss:  83.39, prob_loss:   8.64, total_loss: 113.72\n",
      "epoch: 2 step:   96/192, lr:0.000100, giou_loss:  18.52, conf_loss:  82.82, prob_loss:   8.24, total_loss: 109.58\n",
      "epoch: 2 step:   97/192, lr:0.000100, giou_loss:  19.09, conf_loss:  82.78, prob_loss:   8.55, total_loss: 110.42\n",
      "epoch: 2 step:   98/192, lr:0.000100, giou_loss:  24.43, conf_loss:  86.25, prob_loss:  15.47, total_loss: 126.15\n",
      "epoch: 2 step:   99/192, lr:0.000100, giou_loss:  30.48, conf_loss:  91.41, prob_loss:  12.20, total_loss: 134.10\n",
      "epoch: 2 step:  100/192, lr:0.000100, giou_loss:  32.65, conf_loss:  86.88, prob_loss:  10.21, total_loss: 129.73\n",
      "epoch: 2 step:  101/192, lr:0.000100, giou_loss:  16.68, conf_loss:  74.63, prob_loss:   8.42, total_loss:  99.74\n",
      "epoch: 2 step:  102/192, lr:0.000100, giou_loss:  29.42, conf_loss:  86.57, prob_loss:  10.49, total_loss: 126.49\n",
      "epoch: 2 step:  103/192, lr:0.000100, giou_loss:  20.79, conf_loss:  74.71, prob_loss:   7.51, total_loss: 103.01\n",
      "epoch: 2 step:  104/192, lr:0.000100, giou_loss:  13.22, conf_loss:  79.29, prob_loss:   6.48, total_loss:  98.99\n",
      "epoch: 2 step:  105/192, lr:0.000100, giou_loss:  18.22, conf_loss:  76.76, prob_loss:   3.91, total_loss:  98.88\n",
      "epoch: 2 step:  106/192, lr:0.000100, giou_loss:  19.59, conf_loss:  72.34, prob_loss:   5.77, total_loss:  97.70\n",
      "epoch: 2 step:  107/192, lr:0.000100, giou_loss:  20.27, conf_loss:  79.26, prob_loss:   6.68, total_loss: 106.21\n",
      "epoch: 2 step:  108/192, lr:0.000100, giou_loss:  25.81, conf_loss:  82.20, prob_loss:   9.22, total_loss: 117.22\n",
      "epoch: 2 step:  109/192, lr:0.000100, giou_loss:  21.34, conf_loss:  81.08, prob_loss:  11.29, total_loss: 113.71\n",
      "epoch: 2 step:  110/192, lr:0.000100, giou_loss:  26.48, conf_loss:  79.49, prob_loss:   7.97, total_loss: 113.94\n",
      "epoch: 2 step:  111/192, lr:0.000100, giou_loss:  20.79, conf_loss:  78.62, prob_loss:   6.94, total_loss: 106.35\n",
      "epoch: 2 step:  112/192, lr:0.000100, giou_loss:  22.90, conf_loss:  80.46, prob_loss:   9.53, total_loss: 112.89\n",
      "epoch: 2 step:  113/192, lr:0.000100, giou_loss:  17.62, conf_loss:  66.74, prob_loss:   3.65, total_loss:  88.01\n",
      "epoch: 2 step:  114/192, lr:0.000100, giou_loss:  17.13, conf_loss:  69.58, prob_loss:   5.72, total_loss:  92.44\n",
      "epoch: 2 step:  115/192, lr:0.000100, giou_loss:  16.82, conf_loss:  71.46, prob_loss:   5.23, total_loss:  93.51\n",
      "epoch: 2 step:  116/192, lr:0.000100, giou_loss:  21.99, conf_loss:  73.55, prob_loss:   5.56, total_loss: 101.11\n",
      "epoch: 2 step:  117/192, lr:0.000100, giou_loss:  20.75, conf_loss:  71.47, prob_loss:   5.88, total_loss:  98.10\n",
      "epoch: 2 step:  118/192, lr:0.000100, giou_loss:  29.47, conf_loss:  83.97, prob_loss:  12.85, total_loss: 126.29\n",
      "epoch: 2 step:  119/192, lr:0.000100, giou_loss:  29.79, conf_loss:  85.99, prob_loss:  13.69, total_loss: 129.46\n",
      "epoch: 2 step:  120/192, lr:0.000100, giou_loss:  19.10, conf_loss:  76.27, prob_loss:   8.43, total_loss: 103.80\n",
      "epoch: 2 step:  121/192, lr:0.000100, giou_loss:  23.52, conf_loss:  69.94, prob_loss:   9.18, total_loss: 102.63\n",
      "epoch: 2 step:  122/192, lr:0.000100, giou_loss:  18.12, conf_loss:  76.39, prob_loss:   8.46, total_loss: 102.98\n",
      "epoch: 2 step:  123/192, lr:0.000100, giou_loss:  21.83, conf_loss:  72.87, prob_loss:   8.83, total_loss: 103.52\n",
      "epoch: 2 step:  124/192, lr:0.000100, giou_loss:  19.43, conf_loss:  83.41, prob_loss:   6.83, total_loss: 109.68\n",
      "epoch: 2 step:  125/192, lr:0.000100, giou_loss:  15.60, conf_loss:  65.26, prob_loss:   3.93, total_loss:  84.79\n",
      "epoch: 2 step:  126/192, lr:0.000100, giou_loss:  26.26, conf_loss:  80.59, prob_loss:  13.32, total_loss: 120.17\n",
      "epoch: 2 step:  127/192, lr:0.000100, giou_loss:  19.20, conf_loss:  73.05, prob_loss:   6.00, total_loss:  98.26\n",
      "epoch: 2 step:  128/192, lr:0.000100, giou_loss:  16.89, conf_loss:  67.62, prob_loss:   4.65, total_loss:  89.16\n",
      "epoch: 2 step:  129/192, lr:0.000100, giou_loss:  34.59, conf_loss:  82.30, prob_loss:  10.30, total_loss: 127.19\n",
      "epoch: 2 step:  130/192, lr:0.000100, giou_loss:  21.81, conf_loss:  72.24, prob_loss:   7.83, total_loss: 101.88\n",
      "epoch: 2 step:  131/192, lr:0.000100, giou_loss:  15.93, conf_loss:  65.44, prob_loss:   5.48, total_loss:  86.85\n",
      "epoch: 2 step:  132/192, lr:0.000100, giou_loss:  21.75, conf_loss:  74.13, prob_loss:   7.96, total_loss: 103.85\n",
      "epoch: 2 step:  133/192, lr:0.000100, giou_loss:  20.49, conf_loss:  70.61, prob_loss:   6.35, total_loss:  97.45\n",
      "epoch: 2 step:  134/192, lr:0.000100, giou_loss:  25.88, conf_loss:  71.03, prob_loss:   9.81, total_loss: 106.72\n",
      "epoch: 2 step:  135/192, lr:0.000100, giou_loss:  22.95, conf_loss:  68.60, prob_loss:   7.34, total_loss:  98.89\n",
      "epoch: 2 step:  136/192, lr:0.000100, giou_loss:  11.46, conf_loss:  73.35, prob_loss:   4.34, total_loss:  89.15\n",
      "epoch: 2 step:  137/192, lr:0.000100, giou_loss:  15.57, conf_loss:  66.03, prob_loss:   4.00, total_loss:  85.61\n",
      "epoch: 2 step:  138/192, lr:0.000100, giou_loss:  32.50, conf_loss:  82.78, prob_loss:  13.04, total_loss: 128.33\n",
      "epoch: 2 step:  139/192, lr:0.000100, giou_loss:  22.62, conf_loss:  69.89, prob_loss:   5.92, total_loss:  98.43\n",
      "epoch: 2 step:  140/192, lr:0.000100, giou_loss:  30.34, conf_loss:  72.97, prob_loss:  11.04, total_loss: 114.35\n",
      "epoch: 2 step:  141/192, lr:0.000100, giou_loss:  30.26, conf_loss:  73.58, prob_loss:  10.22, total_loss: 114.07\n",
      "epoch: 2 step:  142/192, lr:0.000100, giou_loss:  18.48, conf_loss:  70.12, prob_loss:   5.47, total_loss:  94.07\n",
      "epoch: 2 step:  143/192, lr:0.000100, giou_loss:  28.35, conf_loss:  71.09, prob_loss:   7.60, total_loss: 107.05\n",
      "epoch: 2 step:  144/192, lr:0.000100, giou_loss:  23.02, conf_loss:  65.95, prob_loss:   5.99, total_loss:  94.96\n",
      "epoch: 2 step:  145/192, lr:0.000100, giou_loss:  33.71, conf_loss:  85.64, prob_loss:  13.25, total_loss: 132.60\n",
      "epoch: 2 step:  146/192, lr:0.000100, giou_loss:  18.33, conf_loss:  72.79, prob_loss:   5.05, total_loss:  96.16\n",
      "epoch: 2 step:  147/192, lr:0.000100, giou_loss:  28.27, conf_loss:  73.59, prob_loss:   9.52, total_loss: 111.38\n",
      "epoch: 2 step:  148/192, lr:0.000100, giou_loss:  18.46, conf_loss:  65.48, prob_loss:   7.61, total_loss:  91.55\n",
      "epoch: 2 step:  149/192, lr:0.000100, giou_loss:  15.56, conf_loss:  73.58, prob_loss:   5.00, total_loss:  94.14\n",
      "epoch: 2 step:  150/192, lr:0.000100, giou_loss:  11.39, conf_loss:  65.09, prob_loss:   2.56, total_loss:  79.05\n",
      "epoch: 2 step:  151/192, lr:0.000100, giou_loss:  29.96, conf_loss:  74.60, prob_loss:  10.14, total_loss: 114.70\n",
      "epoch: 2 step:  152/192, lr:0.000100, giou_loss:  26.77, conf_loss:  69.02, prob_loss:   8.03, total_loss: 103.81\n",
      "epoch: 2 step:  153/192, lr:0.000100, giou_loss:  16.55, conf_loss:  60.48, prob_loss:   4.67, total_loss:  81.71\n",
      "epoch: 2 step:  154/192, lr:0.000100, giou_loss:  21.95, conf_loss:  68.95, prob_loss:   5.57, total_loss:  96.47\n",
      "epoch: 2 step:  155/192, lr:0.000100, giou_loss:  24.89, conf_loss:  68.60, prob_loss:   8.78, total_loss: 102.27\n",
      "epoch: 2 step:  156/192, lr:0.000100, giou_loss:  27.32, conf_loss:  72.90, prob_loss:   7.18, total_loss: 107.40\n",
      "epoch: 2 step:  157/192, lr:0.000100, giou_loss:  20.44, conf_loss:  67.10, prob_loss:   5.24, total_loss:  92.78\n",
      "epoch: 2 step:  158/192, lr:0.000100, giou_loss:  11.82, conf_loss:  58.96, prob_loss:   3.08, total_loss:  73.86\n",
      "epoch: 2 step:  159/192, lr:0.000100, giou_loss:  21.20, conf_loss:  67.55, prob_loss:   6.86, total_loss:  95.61\n",
      "epoch: 2 step:  160/192, lr:0.000100, giou_loss:  26.60, conf_loss:  70.81, prob_loss:   9.34, total_loss: 106.75\n",
      "epoch: 2 step:  161/192, lr:0.000100, giou_loss:  28.35, conf_loss:  72.47, prob_loss:   9.35, total_loss: 110.17\n",
      "epoch: 2 step:  162/192, lr:0.000100, giou_loss:  27.29, conf_loss:  68.74, prob_loss:   9.54, total_loss: 105.57\n",
      "epoch: 2 step:  163/192, lr:0.000100, giou_loss:  25.07, conf_loss:  69.55, prob_loss:  11.05, total_loss: 105.66\n",
      "epoch: 2 step:  164/192, lr:0.000100, giou_loss:  10.46, conf_loss:  66.63, prob_loss:   3.55, total_loss:  80.65\n",
      "epoch: 2 step:  165/192, lr:0.000100, giou_loss:  20.33, conf_loss:  62.52, prob_loss:   6.08, total_loss:  88.93\n",
      "epoch: 2 step:  166/192, lr:0.000100, giou_loss:  12.17, conf_loss:  68.96, prob_loss:   5.06, total_loss:  86.20\n",
      "epoch: 2 step:  167/192, lr:0.000100, giou_loss:  22.17, conf_loss:  65.53, prob_loss:   7.32, total_loss:  95.02\n",
      "epoch: 2 step:  168/192, lr:0.000100, giou_loss:  12.51, conf_loss:  66.08, prob_loss:   3.60, total_loss:  82.19\n",
      "epoch: 2 step:  169/192, lr:0.000100, giou_loss:  25.22, conf_loss:  69.11, prob_loss:   8.71, total_loss: 103.03\n",
      "epoch: 2 step:  170/192, lr:0.000100, giou_loss:  16.88, conf_loss:  60.38, prob_loss:   6.25, total_loss:  83.51\n",
      "epoch: 2 step:  171/192, lr:0.000100, giou_loss:  11.04, conf_loss:  57.70, prob_loss:   4.46, total_loss:  73.20\n",
      "epoch: 2 step:  172/192, lr:0.000100, giou_loss:  21.62, conf_loss:  64.84, prob_loss:   6.53, total_loss:  92.99\n",
      "epoch: 2 step:  173/192, lr:0.000100, giou_loss:  13.83, conf_loss:  60.00, prob_loss:   3.87, total_loss:  77.69\n",
      "epoch: 2 step:  174/192, lr:0.000100, giou_loss:  19.87, conf_loss:  63.54, prob_loss:   5.55, total_loss:  88.96\n",
      "epoch: 2 step:  175/192, lr:0.000100, giou_loss:  32.44, conf_loss:  74.14, prob_loss:  11.55, total_loss: 118.14\n",
      "epoch: 2 step:  176/192, lr:0.000100, giou_loss:  19.81, conf_loss:  67.57, prob_loss:   7.93, total_loss:  95.31\n",
      "epoch: 2 step:  177/192, lr:0.000100, giou_loss:  14.72, conf_loss:  55.66, prob_loss:   4.51, total_loss:  74.89\n",
      "epoch: 2 step:  178/192, lr:0.000100, giou_loss:  29.03, conf_loss:  68.38, prob_loss:   8.96, total_loss: 106.37\n",
      "epoch: 2 step:  179/192, lr:0.000100, giou_loss:  15.18, conf_loss:  62.00, prob_loss:   4.39, total_loss:  81.57\n",
      "epoch: 2 step:  180/192, lr:0.000100, giou_loss:  12.12, conf_loss:  60.53, prob_loss:   4.37, total_loss:  77.02\n",
      "epoch: 2 step:  181/192, lr:0.000100, giou_loss:  26.39, conf_loss:  64.64, prob_loss:  10.03, total_loss: 101.07\n",
      "epoch: 2 step:  182/192, lr:0.000100, giou_loss:  17.85, conf_loss:  61.42, prob_loss:   4.90, total_loss:  84.16\n",
      "epoch: 2 step:  183/192, lr:0.000100, giou_loss:  23.27, conf_loss:  63.38, prob_loss:   7.70, total_loss:  94.35\n",
      "epoch: 2 step:  184/192, lr:0.000100, giou_loss:  15.52, conf_loss:  54.41, prob_loss:   4.61, total_loss:  74.54\n",
      "epoch: 2 step:  185/192, lr:0.000100, giou_loss:  32.43, conf_loss:  73.84, prob_loss:  11.44, total_loss: 117.71\n",
      "epoch: 2 step:  186/192, lr:0.000100, giou_loss:  19.06, conf_loss:  57.62, prob_loss:   7.36, total_loss:  84.04\n",
      "epoch: 2 step:  187/192, lr:0.000100, giou_loss:  19.57, conf_loss:  60.30, prob_loss:   4.66, total_loss:  84.53\n",
      "epoch: 2 step:  188/192, lr:0.000100, giou_loss:  24.01, conf_loss:  63.41, prob_loss:   7.62, total_loss:  95.04\n",
      "epoch: 2 step:  189/192, lr:0.000100, giou_loss:  21.84, conf_loss:  57.07, prob_loss:   5.66, total_loss:  84.57\n",
      "epoch: 2 step:  190/192, lr:0.000100, giou_loss:  19.91, conf_loss:  57.56, prob_loss:   6.06, total_loss:  83.54\n",
      "epoch: 2 step:  191/192, lr:0.000100, giou_loss:  15.09, conf_loss:  66.51, prob_loss:   4.70, total_loss:  86.30\n",
      "epoch: 2 step:    0/192, lr:0.000100, giou_loss:  14.97, conf_loss:  64.29, prob_loss:   3.96, total_loss:  83.22\n",
      "epoch: 2 step:    1/192, lr:0.000100, giou_loss:  16.06, conf_loss:  60.09, prob_loss:   4.65, total_loss:  80.79\n",
      "epoch: 3 step:    2/192, lr:0.000100, giou_loss:  22.94, conf_loss:  57.86, prob_loss:   7.38, total_loss:  88.17\n",
      "epoch: 3 step:    3/192, lr:0.000100, giou_loss:  26.48, conf_loss:  64.62, prob_loss:   9.35, total_loss: 100.46\n",
      "epoch: 3 step:    4/192, lr:0.000100, giou_loss:  26.84, conf_loss:  65.87, prob_loss:  12.61, total_loss: 105.32\n",
      "epoch: 3 step:    5/192, lr:0.000100, giou_loss:  18.80, conf_loss:  56.76, prob_loss:   5.50, total_loss:  81.06\n",
      "epoch: 3 step:    6/192, lr:0.000100, giou_loss:  33.13, conf_loss:  75.35, prob_loss:  11.54, total_loss: 120.02\n",
      "epoch: 3 step:    7/192, lr:0.000100, giou_loss:  17.16, conf_loss:  57.26, prob_loss:   4.99, total_loss:  79.41\n",
      "epoch: 3 step:    8/192, lr:0.000100, giou_loss:  22.51, conf_loss:  60.78, prob_loss:   7.58, total_loss:  90.87\n",
      "epoch: 3 step:    9/192, lr:0.000100, giou_loss:  17.29, conf_loss:  55.73, prob_loss:   5.08, total_loss:  78.09\n",
      "epoch: 3 step:   10/192, lr:0.000100, giou_loss:  20.45, conf_loss:  67.17, prob_loss:   7.61, total_loss:  95.23\n",
      "epoch: 3 step:   11/192, lr:0.000100, giou_loss:  22.91, conf_loss:  56.97, prob_loss:   9.35, total_loss:  89.22\n",
      "epoch: 3 step:   12/192, lr:0.000100, giou_loss:  14.77, conf_loss:  53.54, prob_loss:   4.46, total_loss:  72.77\n",
      "epoch: 3 step:   13/192, lr:0.000100, giou_loss:  26.09, conf_loss:  71.20, prob_loss:   9.49, total_loss: 106.79\n",
      "epoch: 3 step:   14/192, lr:0.000100, giou_loss:  31.81, conf_loss:  59.92, prob_loss:   9.48, total_loss: 101.21\n",
      "epoch: 3 step:   15/192, lr:0.000100, giou_loss:  23.51, conf_loss:  59.23, prob_loss:   6.94, total_loss:  89.68\n",
      "epoch: 3 step:   16/192, lr:0.000100, giou_loss:  17.62, conf_loss:  49.23, prob_loss:   4.54, total_loss:  71.39\n",
      "epoch: 3 step:   17/192, lr:0.000100, giou_loss:  23.41, conf_loss:  56.16, prob_loss:   6.97, total_loss:  86.53\n",
      "epoch: 3 step:   18/192, lr:0.000100, giou_loss:  16.92, conf_loss:  62.08, prob_loss:   7.74, total_loss:  86.74\n",
      "epoch: 3 step:   19/192, lr:0.000100, giou_loss:  14.85, conf_loss:  55.13, prob_loss:   3.81, total_loss:  73.79\n",
      "epoch: 3 step:   20/192, lr:0.000100, giou_loss:  18.33, conf_loss:  53.45, prob_loss:   4.57, total_loss:  76.35\n",
      "epoch: 3 step:   21/192, lr:0.000100, giou_loss:  27.05, conf_loss:  59.65, prob_loss:   9.28, total_loss:  95.98\n",
      "epoch: 3 step:   22/192, lr:0.000100, giou_loss:  17.61, conf_loss:  53.66, prob_loss:   5.76, total_loss:  77.02\n",
      "epoch: 3 step:   23/192, lr:0.000100, giou_loss:  19.06, conf_loss:  53.35, prob_loss:   5.05, total_loss:  77.46\n",
      "epoch: 3 step:   24/192, lr:0.000100, giou_loss:  24.97, conf_loss:  62.95, prob_loss:   8.35, total_loss:  96.27\n",
      "epoch: 3 step:   25/192, lr:0.000100, giou_loss:  13.55, conf_loss:  49.60, prob_loss:   3.81, total_loss:  66.96\n",
      "epoch: 3 step:   26/192, lr:0.000100, giou_loss:  18.24, conf_loss:  52.76, prob_loss:   6.39, total_loss:  77.39\n",
      "epoch: 3 step:   27/192, lr:0.000100, giou_loss:  19.40, conf_loss:  53.46, prob_loss:   4.83, total_loss:  77.68\n",
      "epoch: 3 step:   28/192, lr:0.000100, giou_loss:  22.21, conf_loss:  56.95, prob_loss:   6.14, total_loss:  85.31\n",
      "epoch: 3 step:   29/192, lr:0.000100, giou_loss:  18.86, conf_loss:  55.34, prob_loss:   6.06, total_loss:  80.27\n",
      "epoch: 3 step:   30/192, lr:0.000100, giou_loss:  24.67, conf_loss:  62.03, prob_loss:   9.84, total_loss:  96.55\n",
      "epoch: 3 step:   31/192, lr:0.000100, giou_loss:  16.99, conf_loss:  51.91, prob_loss:   4.35, total_loss:  73.25\n",
      "epoch: 3 step:   32/192, lr:0.000100, giou_loss:  19.14, conf_loss:  54.57, prob_loss:   6.03, total_loss:  79.74\n",
      "epoch: 3 step:   33/192, lr:0.000100, giou_loss:  24.47, conf_loss:  56.33, prob_loss:   6.45, total_loss:  87.25\n",
      "epoch: 3 step:   34/192, lr:0.000100, giou_loss:  25.75, conf_loss:  55.03, prob_loss:   7.64, total_loss:  88.42\n",
      "epoch: 3 step:   35/192, lr:0.000100, giou_loss:  22.11, conf_loss:  55.34, prob_loss:   7.52, total_loss:  84.98\n",
      "epoch: 3 step:   36/192, lr:0.000100, giou_loss:  14.60, conf_loss:  47.79, prob_loss:   4.52, total_loss:  66.91\n",
      "epoch: 3 step:   37/192, lr:0.000100, giou_loss:  23.85, conf_loss:  56.07, prob_loss:   7.68, total_loss:  87.60\n",
      "epoch: 3 step:   38/192, lr:0.000100, giou_loss:  19.83, conf_loss:  57.66, prob_loss:   5.22, total_loss:  82.72\n",
      "epoch: 3 step:   39/192, lr:0.000100, giou_loss:  15.74, conf_loss:  46.75, prob_loss:   4.27, total_loss:  66.76\n",
      "epoch: 3 step:   40/192, lr:0.000100, giou_loss:  30.42, conf_loss:  63.71, prob_loss:   8.65, total_loss: 102.78\n",
      "epoch: 3 step:   41/192, lr:0.000100, giou_loss:  22.48, conf_loss:  60.62, prob_loss:   6.67, total_loss:  89.77\n",
      "epoch: 3 step:   42/192, lr:0.000100, giou_loss:  18.33, conf_loss:  49.61, prob_loss:   4.70, total_loss:  72.64\n",
      "epoch: 3 step:   43/192, lr:0.000100, giou_loss:  17.80, conf_loss:  55.46, prob_loss:   6.24, total_loss:  79.50\n",
      "epoch: 3 step:   44/192, lr:0.000100, giou_loss:  15.49, conf_loss:  54.68, prob_loss:   4.07, total_loss:  74.23\n",
      "epoch: 3 step:   45/192, lr:0.000100, giou_loss:  13.02, conf_loss:  49.21, prob_loss:   3.27, total_loss:  65.50\n",
      "epoch: 3 step:   46/192, lr:0.000100, giou_loss:  22.96, conf_loss:  51.15, prob_loss:   5.99, total_loss:  80.11\n",
      "epoch: 3 step:   47/192, lr:0.000100, giou_loss:  18.33, conf_loss:  50.03, prob_loss:   4.82, total_loss:  73.18\n",
      "epoch: 3 step:   48/192, lr:0.000100, giou_loss:  15.23, conf_loss:  52.71, prob_loss:   4.57, total_loss:  72.51\n",
      "epoch: 3 step:   49/192, lr:0.000100, giou_loss:  18.54, conf_loss:  47.77, prob_loss:   4.71, total_loss:  71.03\n",
      "epoch: 3 step:   50/192, lr:0.000100, giou_loss:  16.96, conf_loss:  53.63, prob_loss:   3.73, total_loss:  74.32\n",
      "epoch: 3 step:   51/192, lr:0.000100, giou_loss:  17.53, conf_loss:  48.56, prob_loss:   5.82, total_loss:  71.91\n",
      "epoch: 3 step:   52/192, lr:0.000100, giou_loss:  15.36, conf_loss:  48.37, prob_loss:   4.25, total_loss:  67.99\n",
      "epoch: 3 step:   53/192, lr:0.000100, giou_loss:  26.45, conf_loss:  59.78, prob_loss:   8.19, total_loss:  94.42\n",
      "epoch: 3 step:   54/192, lr:0.000100, giou_loss:  21.21, conf_loss:  51.74, prob_loss:   5.58, total_loss:  78.53\n",
      "epoch: 3 step:   55/192, lr:0.000100, giou_loss:  14.87, conf_loss:  55.03, prob_loss:   3.67, total_loss:  73.57\n",
      "epoch: 3 step:   56/192, lr:0.000100, giou_loss:  23.18, conf_loss:  55.56, prob_loss:   6.21, total_loss:  84.95\n",
      "epoch: 3 step:   57/192, lr:0.000100, giou_loss:  15.17, conf_loss:  49.03, prob_loss:   5.00, total_loss:  69.20\n",
      "epoch: 3 step:   58/192, lr:0.000100, giou_loss:  15.10, conf_loss:  58.46, prob_loss:   6.04, total_loss:  79.60\n",
      "epoch: 3 step:   59/192, lr:0.000100, giou_loss:  14.80, conf_loss:  52.91, prob_loss:   3.42, total_loss:  71.12\n",
      "epoch: 3 step:   60/192, lr:0.000100, giou_loss:  29.45, conf_loss:  57.98, prob_loss:   8.82, total_loss:  96.25\n",
      "epoch: 3 step:   61/192, lr:0.000100, giou_loss:  17.52, conf_loss:  53.21, prob_loss:   5.72, total_loss:  76.45\n",
      "epoch: 3 step:   62/192, lr:0.000100, giou_loss:  20.12, conf_loss:  49.79, prob_loss:   5.70, total_loss:  75.61\n",
      "epoch: 3 step:   63/192, lr:0.000100, giou_loss:  16.78, conf_loss:  47.57, prob_loss:   5.41, total_loss:  69.75\n",
      "epoch: 3 step:   64/192, lr:0.000100, giou_loss:  15.46, conf_loss:  47.26, prob_loss:   4.35, total_loss:  67.07\n",
      "epoch: 3 step:   65/192, lr:0.000100, giou_loss:  15.54, conf_loss:  42.74, prob_loss:   4.21, total_loss:  62.49\n",
      "epoch: 3 step:   66/192, lr:0.000100, giou_loss:  17.17, conf_loss:  51.89, prob_loss:   6.50, total_loss:  75.55\n",
      "epoch: 3 step:   67/192, lr:0.000100, giou_loss:  18.80, conf_loss:  44.60, prob_loss:   4.14, total_loss:  67.54\n",
      "epoch: 3 step:   68/192, lr:0.000100, giou_loss:  17.85, conf_loss:  54.81, prob_loss:   6.56, total_loss:  79.23\n",
      "epoch: 3 step:   69/192, lr:0.000100, giou_loss:  16.58, conf_loss:  47.40, prob_loss:   5.91, total_loss:  69.89\n",
      "epoch: 3 step:   70/192, lr:0.000100, giou_loss:  21.93, conf_loss:  47.41, prob_loss:   6.85, total_loss:  76.19\n",
      "epoch: 3 step:   71/192, lr:0.000100, giou_loss:  24.05, conf_loss:  52.39, prob_loss:   6.87, total_loss:  83.31\n",
      "epoch: 3 step:   72/192, lr:0.000100, giou_loss:  24.52, conf_loss:  55.25, prob_loss:   9.07, total_loss:  88.84\n",
      "epoch: 3 step:   73/192, lr:0.000100, giou_loss:  24.48, conf_loss:  54.34, prob_loss:   6.04, total_loss:  84.86\n",
      "epoch: 3 step:   74/192, lr:0.000100, giou_loss:  23.99, conf_loss:  55.83, prob_loss:   7.00, total_loss:  86.81\n",
      "epoch: 3 step:   75/192, lr:0.000100, giou_loss:  12.64, conf_loss:  43.59, prob_loss:   3.07, total_loss:  59.30\n",
      "epoch: 3 step:   76/192, lr:0.000100, giou_loss:  28.18, conf_loss:  55.43, prob_loss:   9.84, total_loss:  93.45\n",
      "epoch: 3 step:   77/192, lr:0.000100, giou_loss:  22.23, conf_loss:  47.79, prob_loss:   6.53, total_loss:  76.55\n",
      "epoch: 3 step:   78/192, lr:0.000100, giou_loss:  26.13, conf_loss:  56.72, prob_loss:   6.74, total_loss:  89.58\n",
      "epoch: 3 step:   79/192, lr:0.000100, giou_loss:  16.07, conf_loss:  42.06, prob_loss:   4.48, total_loss:  62.61\n",
      "epoch: 3 step:   80/192, lr:0.000100, giou_loss:  24.17, conf_loss:  53.07, prob_loss:   7.27, total_loss:  84.52\n",
      "epoch: 3 step:   81/192, lr:0.000100, giou_loss:  17.70, conf_loss:  47.90, prob_loss:   5.58, total_loss:  71.18\n",
      "epoch: 3 step:   82/192, lr:0.000100, giou_loss:  19.44, conf_loss:  47.99, prob_loss:   5.33, total_loss:  72.76\n",
      "epoch: 3 step:   83/192, lr:0.000100, giou_loss:  25.85, conf_loss:  56.06, prob_loss:   9.52, total_loss:  91.43\n",
      "epoch: 3 step:   84/192, lr:0.000100, giou_loss:  17.77, conf_loss:  50.18, prob_loss:   5.16, total_loss:  73.11\n",
      "epoch: 3 step:   85/192, lr:0.000100, giou_loss:  26.06, conf_loss:  53.67, prob_loss:  10.03, total_loss:  89.76\n",
      "epoch: 3 step:   86/192, lr:0.000100, giou_loss:  18.41, conf_loss:  48.72, prob_loss:   5.47, total_loss:  72.60\n",
      "epoch: 3 step:   87/192, lr:0.000100, giou_loss:  16.09, conf_loss:  54.16, prob_loss:   5.51, total_loss:  75.76\n",
      "epoch: 3 step:   88/192, lr:0.000100, giou_loss:  18.09, conf_loss:  43.14, prob_loss:   4.92, total_loss:  66.14\n",
      "epoch: 3 step:   89/192, lr:0.000100, giou_loss:  20.60, conf_loss:  46.28, prob_loss:   5.79, total_loss:  72.67\n",
      "epoch: 3 step:   90/192, lr:0.000100, giou_loss:  27.45, conf_loss:  55.98, prob_loss:   7.57, total_loss:  91.00\n",
      "epoch: 3 step:   91/192, lr:0.000100, giou_loss:  17.49, conf_loss:  44.78, prob_loss:   4.31, total_loss:  66.57\n",
      "epoch: 3 step:   92/192, lr:0.000100, giou_loss:  25.50, conf_loss:  53.35, prob_loss:   8.43, total_loss:  87.28\n",
      "epoch: 3 step:   93/192, lr:0.000100, giou_loss:  23.77, conf_loss:  49.51, prob_loss:   8.55, total_loss:  81.83\n",
      "epoch: 3 step:   94/192, lr:0.000100, giou_loss:  23.26, conf_loss:  44.60, prob_loss:   4.18, total_loss:  72.04\n",
      "epoch: 3 step:   95/192, lr:0.000100, giou_loss:  28.11, conf_loss:  59.78, prob_loss:   8.93, total_loss:  96.82\n",
      "epoch: 3 step:   96/192, lr:0.000100, giou_loss:  27.21, conf_loss:  56.74, prob_loss:   8.67, total_loss:  92.62\n",
      "epoch: 3 step:   97/192, lr:0.000100, giou_loss:  16.49, conf_loss:  45.30, prob_loss:   4.53, total_loss:  66.32\n",
      "epoch: 3 step:   98/192, lr:0.000100, giou_loss:  19.88, conf_loss:  45.02, prob_loss:   6.22, total_loss:  71.11\n",
      "epoch: 3 step:   99/192, lr:0.000100, giou_loss:  16.88, conf_loss:  49.05, prob_loss:   5.22, total_loss:  71.14\n",
      "epoch: 3 step:  100/192, lr:0.000100, giou_loss:  12.24, conf_loss:  41.33, prob_loss:   2.84, total_loss:  56.41\n",
      "epoch: 3 step:  101/192, lr:0.000100, giou_loss:  24.03, conf_loss:  57.22, prob_loss:   7.48, total_loss:  88.73\n",
      "epoch: 3 step:  102/192, lr:0.000100, giou_loss:  19.88, conf_loss:  50.94, prob_loss:   7.52, total_loss:  78.34\n",
      "epoch: 3 step:  103/192, lr:0.000100, giou_loss:  15.64, conf_loss:  41.97, prob_loss:   4.33, total_loss:  61.95\n",
      "epoch: 3 step:  104/192, lr:0.000100, giou_loss:  16.34, conf_loss:  40.99, prob_loss:   4.58, total_loss:  61.91\n",
      "epoch: 3 step:  105/192, lr:0.000100, giou_loss:  14.71, conf_loss:  48.27, prob_loss:   5.44, total_loss:  68.42\n",
      "epoch: 3 step:  106/192, lr:0.000100, giou_loss:  20.87, conf_loss:  46.57, prob_loss:   6.20, total_loss:  73.64\n",
      "epoch: 3 step:  107/192, lr:0.000100, giou_loss:  20.48, conf_loss:  49.90, prob_loss:   6.13, total_loss:  76.51\n",
      "epoch: 3 step:  108/192, lr:0.000100, giou_loss:  17.88, conf_loss:  41.15, prob_loss:   4.77, total_loss:  63.81\n",
      "epoch: 3 step:  109/192, lr:0.000100, giou_loss:  19.40, conf_loss:  50.29, prob_loss:   6.26, total_loss:  75.94\n",
      "epoch: 3 step:  110/192, lr:0.000100, giou_loss:  25.08, conf_loss:  50.90, prob_loss:   7.67, total_loss:  83.65\n",
      "epoch: 3 step:  111/192, lr:0.000100, giou_loss:  23.28, conf_loss:  50.70, prob_loss:   6.12, total_loss:  80.10\n",
      "epoch: 3 step:  112/192, lr:0.000100, giou_loss:  14.45, conf_loss:  45.09, prob_loss:   3.50, total_loss:  63.04\n",
      "epoch: 3 step:  113/192, lr:0.000100, giou_loss:  19.86, conf_loss:  45.98, prob_loss:   5.67, total_loss:  71.50\n",
      "epoch: 3 step:  114/192, lr:0.000100, giou_loss:  16.21, conf_loss:  45.01, prob_loss:   5.04, total_loss:  66.26\n",
      "epoch: 3 step:  115/192, lr:0.000100, giou_loss:  18.37, conf_loss:  48.00, prob_loss:   6.26, total_loss:  72.62\n",
      "epoch: 3 step:  116/192, lr:0.000100, giou_loss:  15.58, conf_loss:  39.04, prob_loss:   4.09, total_loss:  58.71\n",
      "epoch: 3 step:  117/192, lr:0.000100, giou_loss:  20.90, conf_loss:  42.26, prob_loss:   6.35, total_loss:  69.51\n",
      "epoch: 3 step:  118/192, lr:0.000100, giou_loss:  17.63, conf_loss:  50.61, prob_loss:   4.81, total_loss:  73.06\n",
      "epoch: 3 step:  119/192, lr:0.000100, giou_loss:  19.74, conf_loss:  51.37, prob_loss:   5.24, total_loss:  76.35\n",
      "epoch: 3 step:  120/192, lr:0.000100, giou_loss:  23.83, conf_loss:  46.00, prob_loss:   7.46, total_loss:  77.29\n",
      "epoch: 3 step:  121/192, lr:0.000100, giou_loss:  19.86, conf_loss:  44.80, prob_loss:   5.90, total_loss:  70.55\n",
      "epoch: 3 step:  122/192, lr:0.000100, giou_loss:  26.31, conf_loss:  52.14, prob_loss:   7.16, total_loss:  85.61\n",
      "epoch: 3 step:  123/192, lr:0.000100, giou_loss:  27.03, conf_loss:  51.56, prob_loss:   7.35, total_loss:  85.94\n",
      "epoch: 3 step:  124/192, lr:0.000100, giou_loss:  13.76, conf_loss:  45.95, prob_loss:   3.91, total_loss:  63.62\n",
      "epoch: 3 step:  125/192, lr:0.000100, giou_loss:  12.78, conf_loss:  43.07, prob_loss:   4.16, total_loss:  60.00\n",
      "epoch: 3 step:  126/192, lr:0.000100, giou_loss:  13.08, conf_loss:  45.24, prob_loss:   3.84, total_loss:  62.16\n",
      "epoch: 3 step:  127/192, lr:0.000100, giou_loss:  29.25, conf_loss:  53.96, prob_loss:   9.67, total_loss:  92.88\n",
      "epoch: 3 step:  128/192, lr:0.000100, giou_loss:  24.01, conf_loss:  48.93, prob_loss:   6.42, total_loss:  79.37\n",
      "epoch: 3 step:  129/192, lr:0.000100, giou_loss:  22.37, conf_loss:  45.77, prob_loss:   6.37, total_loss:  74.51\n",
      "epoch: 3 step:  130/192, lr:0.000100, giou_loss:  22.78, conf_loss:  48.30, prob_loss:   7.35, total_loss:  78.42\n",
      "epoch: 3 step:  131/192, lr:0.000100, giou_loss:  19.21, conf_loss:  43.64, prob_loss:   5.94, total_loss:  68.79\n",
      "epoch: 3 step:  132/192, lr:0.000100, giou_loss:  24.65, conf_loss:  44.68, prob_loss:   6.66, total_loss:  75.99\n",
      "epoch: 3 step:  133/192, lr:0.000100, giou_loss:  11.93, conf_loss:  47.64, prob_loss:   4.70, total_loss:  64.27\n",
      "epoch: 3 step:  134/192, lr:0.000100, giou_loss:  18.36, conf_loss:  45.65, prob_loss:   6.31, total_loss:  70.32\n",
      "epoch: 3 step:  135/192, lr:0.000100, giou_loss:  20.53, conf_loss:  47.26, prob_loss:   6.75, total_loss:  74.53\n",
      "epoch: 3 step:  136/192, lr:0.000100, giou_loss:  15.35, conf_loss:  41.72, prob_loss:   5.89, total_loss:  62.96\n",
      "epoch: 3 step:  137/192, lr:0.000100, giou_loss:  19.92, conf_loss:  42.25, prob_loss:   6.02, total_loss:  68.18\n",
      "epoch: 3 step:  138/192, lr:0.000100, giou_loss:  26.48, conf_loss:  50.63, prob_loss:   7.38, total_loss:  84.50\n",
      "epoch: 3 step:  139/192, lr:0.000100, giou_loss:  17.50, conf_loss:  40.44, prob_loss:   4.58, total_loss:  62.52\n",
      "epoch: 3 step:  140/192, lr:0.000100, giou_loss:  14.85, conf_loss:  40.03, prob_loss:   4.28, total_loss:  59.16\n",
      "epoch: 3 step:  141/192, lr:0.000100, giou_loss:  25.80, conf_loss:  46.02, prob_loss:   9.43, total_loss:  81.24\n",
      "epoch: 3 step:  142/192, lr:0.000100, giou_loss:  20.03, conf_loss:  40.83, prob_loss:   7.21, total_loss:  68.08\n",
      "epoch: 3 step:  143/192, lr:0.000100, giou_loss:  23.26, conf_loss:  44.43, prob_loss:   8.64, total_loss:  76.34\n",
      "epoch: 3 step:  144/192, lr:0.000100, giou_loss:  18.70, conf_loss:  44.62, prob_loss:   5.68, total_loss:  69.00\n",
      "epoch: 3 step:  145/192, lr:0.000100, giou_loss:  19.28, conf_loss:  46.28, prob_loss:   6.85, total_loss:  72.41\n",
      "epoch: 3 step:  146/192, lr:0.000100, giou_loss:  14.55, conf_loss:  40.19, prob_loss:   4.29, total_loss:  59.03\n",
      "epoch: 3 step:  147/192, lr:0.000100, giou_loss:  15.14, conf_loss:  42.10, prob_loss:   4.61, total_loss:  61.85\n",
      "epoch: 3 step:  148/192, lr:0.000100, giou_loss:  24.60, conf_loss:  53.63, prob_loss:   7.17, total_loss:  85.39\n",
      "epoch: 3 step:  149/192, lr:0.000100, giou_loss:  15.44, conf_loss:  35.75, prob_loss:   5.35, total_loss:  56.53\n",
      "epoch: 3 step:  150/192, lr:0.000100, giou_loss:  19.29, conf_loss:  46.58, prob_loss:   5.31, total_loss:  71.18\n",
      "epoch: 3 step:  151/192, lr:0.000100, giou_loss:  22.51, conf_loss:  43.48, prob_loss:   6.32, total_loss:  72.32\n",
      "epoch: 3 step:  152/192, lr:0.000100, giou_loss:  15.00, conf_loss:  37.61, prob_loss:   4.14, total_loss:  56.75\n",
      "epoch: 3 step:  153/192, lr:0.000100, giou_loss:  21.63, conf_loss:  53.52, prob_loss:   6.00, total_loss:  81.15\n",
      "epoch: 3 step:  154/192, lr:0.000100, giou_loss:  18.45, conf_loss:  42.90, prob_loss:   4.63, total_loss:  65.98\n",
      "epoch: 3 step:  155/192, lr:0.000100, giou_loss:  22.15, conf_loss:  43.45, prob_loss:   5.76, total_loss:  71.37\n",
      "epoch: 3 step:  156/192, lr:0.000100, giou_loss:  19.98, conf_loss:  45.72, prob_loss:   6.13, total_loss:  71.84\n",
      "epoch: 3 step:  157/192, lr:0.000100, giou_loss:  20.48, conf_loss:  43.74, prob_loss:   6.29, total_loss:  70.52\n",
      "epoch: 3 step:  158/192, lr:0.000100, giou_loss:  18.47, conf_loss:  37.53, prob_loss:   4.46, total_loss:  60.46\n",
      "epoch: 3 step:  159/192, lr:0.000100, giou_loss:  15.03, conf_loss:  43.62, prob_loss:   5.02, total_loss:  63.68\n",
      "epoch: 3 step:  160/192, lr:0.000100, giou_loss:  18.69, conf_loss:  44.99, prob_loss:   4.59, total_loss:  68.27\n",
      "epoch: 3 step:  161/192, lr:0.000100, giou_loss:  27.11, conf_loss:  49.38, prob_loss:   9.48, total_loss:  85.97\n",
      "epoch: 3 step:  162/192, lr:0.000100, giou_loss:  15.09, conf_loss:  39.25, prob_loss:   4.31, total_loss:  58.64\n",
      "epoch: 3 step:  163/192, lr:0.000100, giou_loss:  24.25, conf_loss:  46.45, prob_loss:   7.04, total_loss:  77.74\n",
      "epoch: 3 step:  164/192, lr:0.000100, giou_loss:  22.33, conf_loss:  43.49, prob_loss:   6.38, total_loss:  72.20\n",
      "epoch: 3 step:  165/192, lr:0.000100, giou_loss:  15.29, conf_loss:  36.24, prob_loss:   4.09, total_loss:  55.62\n",
      "epoch: 3 step:  166/192, lr:0.000100, giou_loss:  22.37, conf_loss:  39.56, prob_loss:   5.86, total_loss:  67.79\n",
      "epoch: 3 step:  167/192, lr:0.000100, giou_loss:   9.98, conf_loss:  43.19, prob_loss:   2.02, total_loss:  55.19\n",
      "epoch: 3 step:  168/192, lr:0.000100, giou_loss:  19.82, conf_loss:  37.61, prob_loss:   5.98, total_loss:  63.41\n",
      "epoch: 3 step:  169/192, lr:0.000100, giou_loss:  16.96, conf_loss:  41.38, prob_loss:   5.32, total_loss:  63.66\n",
      "epoch: 3 step:  170/192, lr:0.000100, giou_loss:  14.24, conf_loss:  36.24, prob_loss:   3.43, total_loss:  53.91\n",
      "epoch: 3 step:  171/192, lr:0.000100, giou_loss:  21.71, conf_loss:  42.72, prob_loss:   5.94, total_loss:  70.36\n",
      "epoch: 3 step:  172/192, lr:0.000100, giou_loss:  19.02, conf_loss:  49.98, prob_loss:   5.27, total_loss:  74.26\n",
      "epoch: 3 step:  173/192, lr:0.000100, giou_loss:  24.55, conf_loss:  47.18, prob_loss:   6.64, total_loss:  78.37\n",
      "epoch: 3 step:  174/192, lr:0.000100, giou_loss:  14.79, conf_loss:  40.18, prob_loss:   3.72, total_loss:  58.69\n",
      "epoch: 3 step:  175/192, lr:0.000100, giou_loss:  26.94, conf_loss:  52.35, prob_loss:   5.87, total_loss:  85.16\n",
      "epoch: 3 step:  176/192, lr:0.000100, giou_loss:  12.48, conf_loss:  36.20, prob_loss:   4.13, total_loss:  52.80\n",
      "epoch: 3 step:  177/192, lr:0.000100, giou_loss:  15.60, conf_loss:  39.70, prob_loss:   4.14, total_loss:  59.45\n",
      "epoch: 3 step:  178/192, lr:0.000100, giou_loss:  17.13, conf_loss:  42.45, prob_loss:   3.92, total_loss:  63.50\n",
      "epoch: 3 step:  179/192, lr:0.000100, giou_loss:  23.57, conf_loss:  48.48, prob_loss:   6.81, total_loss:  78.87\n",
      "epoch: 3 step:  180/192, lr:0.000100, giou_loss:  19.09, conf_loss:  39.83, prob_loss:   6.28, total_loss:  65.20\n",
      "epoch: 3 step:  181/192, lr:0.000100, giou_loss:  18.34, conf_loss:  39.72, prob_loss:   4.72, total_loss:  62.79\n",
      "epoch: 3 step:  182/192, lr:0.000100, giou_loss:  18.06, conf_loss:  48.06, prob_loss:   3.95, total_loss:  70.07\n",
      "epoch: 3 step:  183/192, lr:0.000100, giou_loss:  18.66, conf_loss:  41.46, prob_loss:   4.73, total_loss:  64.84\n",
      "epoch: 3 step:  184/192, lr:0.000100, giou_loss:  17.07, conf_loss:  36.43, prob_loss:   4.28, total_loss:  57.78\n",
      "epoch: 3 step:  185/192, lr:0.000100, giou_loss:  17.67, conf_loss:  40.65, prob_loss:   4.62, total_loss:  62.94\n",
      "epoch: 3 step:  186/192, lr:0.000100, giou_loss:  29.08, conf_loss:  55.33, prob_loss:   7.25, total_loss:  91.66\n",
      "epoch: 3 step:  187/192, lr:0.000100, giou_loss:  15.47, conf_loss:  35.71, prob_loss:   4.28, total_loss:  55.46\n",
      "epoch: 3 step:  188/192, lr:0.000100, giou_loss:  20.14, conf_loss:  40.72, prob_loss:   5.68, total_loss:  66.54\n",
      "epoch: 3 step:  189/192, lr:0.000100, giou_loss:  19.06, conf_loss:  38.92, prob_loss:   5.58, total_loss:  63.57\n",
      "epoch: 3 step:  190/192, lr:0.000100, giou_loss:  27.21, conf_loss:  43.15, prob_loss:   6.33, total_loss:  76.69\n",
      "epoch: 3 step:  191/192, lr:0.000100, giou_loss:  19.52, conf_loss:  41.27, prob_loss:   6.02, total_loss:  66.81\n",
      "epoch: 3 step:    0/192, lr:0.000100, giou_loss:  13.97, conf_loss:  43.93, prob_loss:   4.31, total_loss:  62.21\n",
      "epoch: 3 step:    1/192, lr:0.000100, giou_loss:  22.88, conf_loss:  40.10, prob_loss:   6.98, total_loss:  69.96\n",
      "epoch: 4 step:    2/192, lr:0.000100, giou_loss:  22.44, conf_loss:  39.58, prob_loss:   5.49, total_loss:  67.51\n",
      "epoch: 4 step:    3/192, lr:0.000100, giou_loss:  16.03, conf_loss:  37.60, prob_loss:   5.13, total_loss:  58.77\n",
      "epoch: 4 step:    4/192, lr:0.000100, giou_loss:  18.37, conf_loss:  39.37, prob_loss:   5.69, total_loss:  63.42\n",
      "epoch: 4 step:    5/192, lr:0.000100, giou_loss:  18.74, conf_loss:  34.46, prob_loss:   4.44, total_loss:  57.63\n",
      "epoch: 4 step:    6/192, lr:0.000100, giou_loss:  24.59, conf_loss:  41.36, prob_loss:   7.57, total_loss:  73.52\n",
      "epoch: 4 step:    7/192, lr:0.000100, giou_loss:  21.91, conf_loss:  38.81, prob_loss:   5.40, total_loss:  66.12\n",
      "epoch: 4 step:    8/192, lr:0.000100, giou_loss:  18.72, conf_loss:  33.85, prob_loss:   4.91, total_loss:  57.48\n",
      "epoch: 4 step:    9/192, lr:0.000100, giou_loss:   5.79, conf_loss:  39.68, prob_loss:   1.59, total_loss:  47.06\n",
      "epoch: 4 step:   10/192, lr:0.000100, giou_loss:  15.40, conf_loss:  33.75, prob_loss:   3.84, total_loss:  52.99\n",
      "epoch: 4 step:   11/192, lr:0.000100, giou_loss:  14.44, conf_loss:  35.43, prob_loss:   3.44, total_loss:  53.32\n",
      "epoch: 4 step:   12/192, lr:0.000100, giou_loss:  32.18, conf_loss:  47.78, prob_loss:  10.88, total_loss:  90.84\n",
      "epoch: 4 step:   13/192, lr:0.000100, giou_loss:  16.33, conf_loss:  38.02, prob_loss:   4.49, total_loss:  58.84\n",
      "epoch: 4 step:   14/192, lr:0.000100, giou_loss:  19.09, conf_loss:  37.57, prob_loss:   4.47, total_loss:  61.13\n",
      "epoch: 4 step:   15/192, lr:0.000100, giou_loss:  22.95, conf_loss:  41.81, prob_loss:   6.40, total_loss:  71.17\n",
      "epoch: 4 step:   16/192, lr:0.000100, giou_loss:  13.90, conf_loss:  35.21, prob_loss:   3.49, total_loss:  52.59\n",
      "epoch: 4 step:   17/192, lr:0.000100, giou_loss:  21.09, conf_loss:  37.11, prob_loss:   4.73, total_loss:  62.94\n",
      "epoch: 4 step:   18/192, lr:0.000100, giou_loss:  16.90, conf_loss:  41.88, prob_loss:   5.32, total_loss:  64.09\n",
      "epoch: 4 step:   19/192, lr:0.000100, giou_loss:  12.35, conf_loss:  29.41, prob_loss:   3.64, total_loss:  45.41\n",
      "epoch: 4 step:   20/192, lr:0.000100, giou_loss:  18.46, conf_loss:  41.39, prob_loss:   4.59, total_loss:  64.44\n",
      "epoch: 4 step:   21/192, lr:0.000100, giou_loss:  23.27, conf_loss:  38.51, prob_loss:   5.58, total_loss:  67.36\n",
      "epoch: 4 step:   22/192, lr:0.000100, giou_loss:  10.43, conf_loss:  37.24, prob_loss:   2.91, total_loss:  50.58\n",
      "epoch: 4 step:   23/192, lr:0.000100, giou_loss:  17.05, conf_loss:  32.25, prob_loss:   4.25, total_loss:  53.55\n",
      "epoch: 4 step:   24/192, lr:0.000100, giou_loss:  19.44, conf_loss:  34.18, prob_loss:   6.37, total_loss:  59.98\n",
      "epoch: 4 step:   25/192, lr:0.000100, giou_loss:  14.89, conf_loss:  33.17, prob_loss:   3.84, total_loss:  51.90\n",
      "epoch: 4 step:   26/192, lr:0.000100, giou_loss:  22.22, conf_loss:  36.51, prob_loss:   7.45, total_loss:  66.18\n",
      "epoch: 4 step:   27/192, lr:0.000100, giou_loss:  20.16, conf_loss:  35.61, prob_loss:   5.98, total_loss:  61.74\n",
      "epoch: 4 step:   28/192, lr:0.000100, giou_loss:  19.71, conf_loss:  35.73, prob_loss:   5.40, total_loss:  60.84\n",
      "epoch: 4 step:   29/192, lr:0.000100, giou_loss:  22.36, conf_loss:  42.84, prob_loss:   5.33, total_loss:  70.53\n",
      "epoch: 4 step:   30/192, lr:0.000100, giou_loss:  14.64, conf_loss:  37.30, prob_loss:   4.36, total_loss:  56.30\n",
      "epoch: 4 step:   31/192, lr:0.000100, giou_loss:  26.12, conf_loss:  38.57, prob_loss:   8.30, total_loss:  72.98\n",
      "epoch: 4 step:   32/192, lr:0.000100, giou_loss:  17.65, conf_loss:  32.85, prob_loss:   4.21, total_loss:  54.72\n",
      "epoch: 4 step:   33/192, lr:0.000100, giou_loss:  18.05, conf_loss:  31.19, prob_loss:   4.28, total_loss:  53.52\n",
      "epoch: 4 step:   34/192, lr:0.000100, giou_loss:  20.09, conf_loss:  35.53, prob_loss:   5.05, total_loss:  60.68\n",
      "epoch: 4 step:   35/192, lr:0.000100, giou_loss:  20.68, conf_loss:  42.78, prob_loss:   7.35, total_loss:  70.81\n",
      "epoch: 4 step:   36/192, lr:0.000100, giou_loss:  14.04, conf_loss:  31.36, prob_loss:   3.72, total_loss:  49.12\n",
      "epoch: 4 step:   37/192, lr:0.000100, giou_loss:  14.06, conf_loss:  32.57, prob_loss:   4.37, total_loss:  51.00\n",
      "epoch: 4 step:   38/192, lr:0.000100, giou_loss:  12.29, conf_loss:  39.77, prob_loss:   3.14, total_loss:  55.20\n",
      "epoch: 4 step:   39/192, lr:0.000100, giou_loss:  20.82, conf_loss:  38.85, prob_loss:   4.47, total_loss:  64.14\n",
      "epoch: 4 step:   40/192, lr:0.000100, giou_loss:  18.96, conf_loss:  33.85, prob_loss:   4.99, total_loss:  57.80\n",
      "epoch: 4 step:   41/192, lr:0.000100, giou_loss:  13.33, conf_loss:  41.24, prob_loss:   3.60, total_loss:  58.17\n",
      "epoch: 4 step:   42/192, lr:0.000100, giou_loss:  18.78, conf_loss:  33.97, prob_loss:   5.78, total_loss:  58.53\n",
      "epoch: 4 step:   43/192, lr:0.000100, giou_loss:  23.23, conf_loss:  42.22, prob_loss:   6.07, total_loss:  71.52\n",
      "epoch: 4 step:   44/192, lr:0.000100, giou_loss:  14.12, conf_loss:  41.05, prob_loss:   3.53, total_loss:  58.70\n",
      "epoch: 4 step:   45/192, lr:0.000100, giou_loss:  18.26, conf_loss:  41.48, prob_loss:   5.33, total_loss:  65.07\n",
      "epoch: 4 step:   46/192, lr:0.000100, giou_loss:  17.70, conf_loss:  33.57, prob_loss:   4.15, total_loss:  55.42\n",
      "epoch: 4 step:   47/192, lr:0.000100, giou_loss:  17.79, conf_loss:  35.21, prob_loss:   4.36, total_loss:  57.36\n",
      "epoch: 4 step:   48/192, lr:0.000100, giou_loss:  17.59, conf_loss:  34.79, prob_loss:   8.55, total_loss:  60.93\n",
      "epoch: 4 step:   49/192, lr:0.000100, giou_loss:  18.62, conf_loss:  32.10, prob_loss:   4.60, total_loss:  55.32\n",
      "epoch: 4 step:   50/192, lr:0.000100, giou_loss:  10.20, conf_loss:  33.10, prob_loss:   2.68, total_loss:  45.97\n",
      "epoch: 4 step:   51/192, lr:0.000100, giou_loss:  28.40, conf_loss:  39.36, prob_loss:   5.87, total_loss:  73.62\n",
      "epoch: 4 step:   52/192, lr:0.000100, giou_loss:  15.28, conf_loss:  33.53, prob_loss:   3.73, total_loss:  52.54\n",
      "epoch: 4 step:   53/192, lr:0.000100, giou_loss:  18.44, conf_loss:  40.65, prob_loss:   6.96, total_loss:  66.06\n",
      "epoch: 4 step:   54/192, lr:0.000100, giou_loss:  17.95, conf_loss:  35.03, prob_loss:   4.54, total_loss:  57.51\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[23], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(EPOCHS):\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m image_data, target \u001b[38;5;129;01min\u001b[39;00m trainset:\n\u001b[1;32m---> 15\u001b[0m         results \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43myolo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m         cur_step \u001b[38;5;241m=\u001b[39m results[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m%\u001b[39m steps_per_epoch\n\u001b[0;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mepoch:\u001b[39m\u001b[38;5;132;01m{:2.0f}\u001b[39;00m\u001b[38;5;124m step:\u001b[39m\u001b[38;5;132;01m{:5.0f}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, lr:\u001b[39m\u001b[38;5;132;01m{:.6f}\u001b[39;00m\u001b[38;5;124m, giou_loss:\u001b[39m\u001b[38;5;132;01m{:7.2f}\u001b[39;00m\u001b[38;5;124m, conf_loss:\u001b[39m\u001b[38;5;132;01m{:7.2f}\u001b[39;00m\u001b[38;5;124m, prob_loss:\u001b[39m\u001b[38;5;132;01m{:7.2f}\u001b[39;00m\u001b[38;5;124m, total_loss:\u001b[39m\u001b[38;5;132;01m{:7.2f}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(epoch, cur_step, steps_per_epoch, results[\u001b[38;5;241m1\u001b[39m], results[\u001b[38;5;241m2\u001b[39m], results[\u001b[38;5;241m3\u001b[39m], results[\u001b[38;5;241m4\u001b[39m], results[\u001b[38;5;241m5\u001b[39m]))\n",
      "File \u001b[1;32m~\\ai-main\\ai-main\\Ch8_YOLOv3-MNIST\\train.py:82\u001b[0m, in \u001b[0;36mtrain_step\u001b[1;34m(model, image_data, target, lr_init, lr_end)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_step\u001b[39m(model, image_data, target, lr_init\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m, lr_end\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-6\u001b[39m):\n\u001b[0;32m     81\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mGradientTape() \u001b[38;5;28;01mas\u001b[39;00m tape:\n\u001b[1;32m---> 82\u001b[0m         pred_result \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     83\u001b[0m         giou_loss\u001b[38;5;241m=\u001b[39mconf_loss\u001b[38;5;241m=\u001b[39mprob_loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     85\u001b[0m         \u001b[38;5;66;03m# optimizing process\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\engine\\training.py:589\u001b[0m, in \u001b[0;36mModel.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(inputs, \u001b[38;5;241m*\u001b[39mcopied_args, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mcopied_kwargs)\n\u001b[0;32m    587\u001b[0m     layout_map_lib\u001b[38;5;241m.\u001b[39m_map_subclass_model_variable(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_layout_map)\n\u001b[1;32m--> 589\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\engine\\functional.py:515\u001b[0m, in \u001b[0;36mFunctional.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;129m@doc_controls\u001b[39m\u001b[38;5;241m.\u001b[39mdo_not_doc_inheritable\n\u001b[0;32m    497\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, mask\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    498\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calls the model on new inputs.\u001b[39;00m\n\u001b[0;32m    499\u001b[0m \n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m    In this case `call` just reapplies\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m \u001b[38;5;124;03m        a list of tensors if there are more than one outputs.\u001b[39;00m\n\u001b[0;32m    514\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 515\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_internal_graph\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\engine\\functional.py:672\u001b[0m, in \u001b[0;36mFunctional._run_internal_graph\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    669\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# Node is not computable, try skipping.\u001b[39;00m\n\u001b[0;32m    671\u001b[0m args, kwargs \u001b[38;5;241m=\u001b[39m node\u001b[38;5;241m.\u001b[39mmap_arguments(tensor_dict)\n\u001b[1;32m--> 672\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mnode\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    674\u001b[0m \u001b[38;5;66;03m# Update tensor_dict.\u001b[39;00m\n\u001b[0;32m    675\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x_id, y \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(\n\u001b[0;32m    676\u001b[0m     node\u001b[38;5;241m.\u001b[39mflat_output_ids, tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(outputs)\n\u001b[0;32m    677\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:1149\u001b[0m, in \u001b[0;36mLayer.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1144\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_cast_inputs(inputs, input_list)\n\u001b[0;32m   1146\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m autocast_variable\u001b[38;5;241m.\u001b[39menable_auto_cast_variables(\n\u001b[0;32m   1147\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compute_dtype_object\n\u001b[0;32m   1148\u001b[0m ):\n\u001b[1;32m-> 1149\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[43mcall_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_activity_regularizer:\n\u001b[0;32m   1152\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_activity_regularization(inputs, outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:96\u001b[0m, in \u001b[0;36minject_argument_info_in_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     94\u001b[0m bound_signature \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     97\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_keras_call_info_injected\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m     99\u001b[0m         \u001b[38;5;66;03m# Only inject info for the innermost failing call\u001b[39;00m\n",
      "File \u001b[1;32m~\\ai-main\\ai-main\\Ch8_YOLOv3-MNIST\\yolov3.py:23\u001b[0m, in \u001b[0;36mBatchNormalization.call\u001b[1;34m(self, x, training)\u001b[0m\n\u001b[0;32m     21\u001b[0m     training \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     22\u001b[0m training \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mlogical_and(training, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainable)\n\u001b[1;32m---> 23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:597\u001b[0m, in \u001b[0;36mBatchNormalizationBase.call\u001b[1;34m(self, inputs, training, mask)\u001b[0m\n\u001b[0;32m    594\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[0;32m    596\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfused:\n\u001b[1;32m--> 597\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fused_batch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    598\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining\u001b[49m\n\u001b[0;32m    599\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    600\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvirtual_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    601\u001b[0m         \u001b[38;5;66;03m# Currently never reaches here since fused_batch_norm does not\u001b[39;00m\n\u001b[0;32m    602\u001b[0m         \u001b[38;5;66;03m# support virtual batching\u001b[39;00m\n\u001b[0;32m    603\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m undo_virtual_batching(outputs)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:1047\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm\u001b[1;34m(self, inputs, mask, training)\u001b[0m\n\u001b[0;32m   1039\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1040\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_moving_average(\n\u001b[0;32m   1041\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoving_variance,\n\u001b[0;32m   1042\u001b[0m                 variance,\n\u001b[0;32m   1043\u001b[0m                 momentum,\n\u001b[0;32m   1044\u001b[0m                 input_batch_size,\n\u001b[0;32m   1045\u001b[0m             )\n\u001b[1;32m-> 1047\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_update\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmean_update\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1048\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_update(variance_update)\n\u001b[0;32m   1050\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\engine\\base_layer.py:1741\u001b[0m, in \u001b[0;36mLayer.add_update\u001b[1;34m(self, updates)\u001b[0m\n\u001b[0;32m   1739\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m update \u001b[38;5;129;01min\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(updates):\n\u001b[0;32m   1740\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(update):\n\u001b[1;32m-> 1741\u001b[0m         \u001b[43mupdate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:1018\u001b[0m, in \u001b[0;36mBatchNormalizationBase._fused_batch_norm.<locals>.mean_update\u001b[1;34m()\u001b[0m\n\u001b[0;32m   1016\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1017\u001b[0m         new_mean \u001b[38;5;241m=\u001b[39m mean\n\u001b[1;32m-> 1018\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_assign_new_value\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoving_mean\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnew_mean\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1019\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1020\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_assign_moving_average(\n\u001b[0;32m   1021\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmoving_mean, mean, momentum, input_batch_size\n\u001b[0;32m   1022\u001b[0m     )\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:891\u001b[0m, in \u001b[0;36mBatchNormalizationBase._assign_new_value\u001b[1;34m(self, variable, value)\u001b[0m\n\u001b[0;32m    889\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m backend\u001b[38;5;241m.\u001b[39mname_scope(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAssignNewValue\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m scope:\n\u001b[0;32m    890\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mexecuting_eagerly_outside_functions():\n\u001b[1;32m--> 891\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mvariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscope\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    892\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    893\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mcompat\u001b[38;5;241m.\u001b[39mv1\u001b[38;5;241m.\u001b[39mcolocate_with(variable):\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:1031\u001b[0m, in \u001b[0;36mBaseResourceVariable.assign\u001b[1;34m(self, value, use_locking, name, read_value)\u001b[0m\n\u001b[0;32m   1029\u001b[0m   validate_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_shape \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_shape\u001b[38;5;241m.\u001b[39mis_fully_defined()\n\u001b[0;32m   1030\u001b[0m   kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidate_shape\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m validate_shape\n\u001b[1;32m-> 1031\u001b[0m assign_op \u001b[38;5;241m=\u001b[39m \u001b[43mgen_resource_variable_ops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43massign_variable_op\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m read_value:\n\u001b[0;32m   1034\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lazy_read(assign_op)\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\envs\\tf2.14\\Lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py:151\u001b[0m, in \u001b[0;36massign_variable_op\u001b[1;34m(resource, value, validate_shape, name)\u001b[0m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tld\u001b[38;5;241m.\u001b[39mis_eager:\n\u001b[0;32m    150\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 151\u001b[0m     _result \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_FastPathExecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    152\u001b[0m \u001b[43m      \u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mAssignVariableOp\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresource\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalidate_shape\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    153\u001b[0m \u001b[43m      \u001b[49m\u001b[43mvalidate_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    154\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _result\n\u001b[0;32m    155\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m _core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "from config import *\n",
    "from bbox_iou import bbox_iou, bbox_giou\n",
    "from yolov3 import Create_YOLOv3\n",
    "from train import *\n",
    "\n",
    "\n",
    "yolo = Create_YOLOv3(num_class=NUM_CLASS, train_mode=True)\n",
    "\n",
    "best_val_loss = 99999\n",
    "save_directory = os.path.join(CHECKPOINTS_FOLDER, MODEL_NAME)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    for image_data, target in trainset:\n",
    "        results = train_step(yolo, image_data, target)\n",
    "        cur_step = results[0] % steps_per_epoch\n",
    "        print(\"epoch:{:2.0f} step:{:5.0f}/{}, lr:{:.6f}, giou_loss:{:7.2f}, conf_loss:{:7.2f}, prob_loss:{:7.2f}, total_loss:{:7.2f}\".format(epoch, cur_step, steps_per_epoch, results[1], results[2], results[3], results[4], results[5]))\n",
    " \n",
    "    if len(testset) == 0: \n",
    "        print(\"configure TEST options to validate model\")\n",
    "        yolo.save_weights(save_directory)\n",
    "        continue \n",
    "\n",
    "    count = 0\n",
    "    giou_val, conf_val, prob_val, total_val = 0, 0, 0, 0 \n",
    "\n",
    "    for image_data, target in testset:\n",
    "        results = validate_step(yolo, image_data, target)\n",
    "        count += 1\n",
    "        giou_val += results[0]\n",
    "        conf_val += results[1]\n",
    "        prob_val += results[2]\n",
    "        total_val += results[3]\n",
    "\n",
    "    # validation loss 저장 \n",
    "    with validate_writer.as_default():\n",
    "        tf.summary.scalar(\"validate_loss/total_val\", total_val / count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/giou_val\", giou_val / count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/conf_val\", conf_val / count, step=epoch)\n",
    "        tf.summary.scalar(\"validate_loss/prob_val\", prob_val / count, step=epoch)\n",
    "    validate_writer.flush()\n",
    "    # print(\"giou_val_loss:{:7.2f}, conf_val_loss:{:7.2f}, prob_val_loss:{:7.2f}, total_val_loss:{:7.2f}\\n\\n\".format( giou_val / count, conf_val / count, prob_val / count, total_val / count))\n",
    "\n",
    "    if SAVE_CHECKPOINT and not SAVE_BEST_ONLY:\n",
    "        save_directory = os.path.join(CHECKPOINTS_FOLDER,  MODEL_NAME + \"_epoch_{:03d}_val_loss_{:7.2f}\".format(epoch, total_val / count))\n",
    "\n",
    "    # print(best_val_loss, total_val / count)\n",
    "\n",
    "    if SAVE_BEST_ONLY:\n",
    "        if best_val_loss > total_val / count:\n",
    "            best_val_loss = total_val / count\n",
    "            yolo.save_weights(save_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39117a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo.save_weights(save_directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "424329d0",
   "metadata": {},
   "source": [
    "# 예측 후 후처리"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed9eb4df",
   "metadata": {},
   "source": [
    "## 박스 후처리(postprocess_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a16091",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def postprocess_boxes(pred_bbox, original_image, input_size, score_threshold):\n",
    "\n",
    "    valid_scale = [0, np.inf]\n",
    "    pred_bbox = np.array(pred_bbox)\n",
    "\n",
    "    pred_xywh = pred_bbox[:, 0:4]\n",
    "    pred_conf = pred_bbox[:, 4]\n",
    "    pred_prob = pred_bbox[:, 5:]\n",
    "\n",
    "    # 1. (x, y, w, h) --> (xmin, ymin, xmax, ymax) \n",
    "    pred_coor = np.concatenate( \n",
    "        [pred_xywh[:, :2] - pred_xywh[:, 2:] * 0.5,\n",
    "         pred_xywh[:, :2] + pred_xywh[:, 2:] * 0.5], axis=-1)\n",
    "\n",
    "    # 2. (xmin, ymin, xmax, ymax) -> (xmin_org, ymin_org, xmax_org, ymax_org) \n",
    "    org_h, org_w = original_image.shape[:2]\n",
    "    resize_ratio = min(input_size/org_w, input_size/org_h)\n",
    "\n",
    "    dw = (input_size - resize_ratio * org_w) / 2 \n",
    "    dh = (input_size - resize_ratio * org_h) / 2 \n",
    "\n",
    "    pred_coor[:, 0::2] = 1.0 * (pred_coor[:, 0::2] - dw) / resize_ratio\n",
    "    pred_coor[:, 1::2] = 1.0 * (pred_coor[:, 1::2] - dh) / resize_ratio\n",
    "\n",
    "    # 3. 범위를 벗어나는 박스를 자름 \n",
    "    pred_coor = np.concatenate(\n",
    "        [np.maximum(pred_coor[:, :2], [0, 0]),\n",
    "         np.minimum(pred_coor[:, 2:], [org_w-1, org_h-1])],\n",
    "        axis=-1)\n",
    "    invalid_mask = np.logical_or(\n",
    "        (pred_coor[:, 0] > pred_coor[:, 2]),\n",
    "        (pred_coor[:, 1] > pred_coor[:, 3]))\n",
    "    pred_coor[invalid_mask] = 0 \n",
    "\n",
    "    # 4. 유효하지 않은 상자 무시 \n",
    "    bboxes_scale = np.sqrt(\n",
    "        np.multiply.reduce(\n",
    "            pred_coor[:, 2:4] - pred_coor[:, 0:2], axis=-1))\n",
    "    scale_mask = np.logical_and(\n",
    "        (valid_scale[0] < bboxes_scale),\n",
    "        (bboxes_scale < valid_scale[1]))\n",
    "\n",
    "    # 5. 낮은 스코어의 상자 무시 \n",
    "    classes = np.argmax(pred_prob, axis=-1)\n",
    "    scores = pred_conf * pred_prob[np.arange(len(pred_coor)), classes]\n",
    "    score_mask = scores > score_threshold\n",
    "    mask = np.logical_and(scale_mask, score_mask)\n",
    "    coors, scores, classes = pred_coor[mask], scores[mask], classes[mask]\n",
    "\n",
    "    return np.concatenate([coors, scores[:, np.newaxis], \n",
    "                           classes[:, np.newaxis]], axis=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b08c81c7",
   "metadata": {},
   "source": [
    "## 상자들의 IoU 계산하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "225723b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def bboxes_iou(boxes1, boxes2):\n",
    "    boxes1 = np.array(boxes1)\n",
    "    boxes2 = np.array(boxes2)\n",
    "\n",
    "    boxes1_area = (boxes1[..., 2] - boxes1[..., 0]) * (boxes1[..., 3] - boxes1[..., 1])\n",
    "    boxes2_area = (boxes2[..., 2] - boxes2[..., 0]) * (boxes2[..., 3] - boxes2[..., 1])\n",
    "\n",
    "    left_up = np.maximum(boxes1[..., :2], boxes2[..., :2])\n",
    "    right_down = np.minimum(boxes1[..., 2:], boxes2[..., 2:])\n",
    "\n",
    "    inter_section = np.maximum(right_down - left_up, 0.0)\n",
    "    inter_area = inter_section[..., 0] * inter_section[..., 1]\n",
    "    union_area = boxes1_area + boxes2_area - inter_area\n",
    "\n",
    "    ious = np.maximum(1.0 * inter_area / union_area, np.finfo(np.float32).eps)\n",
    "\n",
    "    return ious"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13da1e72",
   "metadata": {},
   "source": [
    "## NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897aac8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nms(bboxes, iou_threshold, sigma=0.3, method='nms'):\n",
    "    classes_in_img = list(set(bboxes[:, 5]))\n",
    "    best_bboxes = []\n",
    "\n",
    "    for cls in classes_in_img:\n",
    "        cls_mask = (bboxes[:, 5] == cls)\n",
    "        cls_bboxes = bboxes[cls_mask]\n",
    "\n",
    "        # 1. 경계 상자의 개수가 0보다 큰지 확인  \n",
    "        while len(cls_bboxes) > 0:\n",
    "            # 2. 가장 높은 점수를 갖는 경계 상자를 선택 \n",
    "            max_ind = np.argmax(cls_bboxes[:, 4])\n",
    "            best_bbox = cls_bboxes[max_ind]\n",
    "            best_bboxes.append(best_bbox)\n",
    "            cls_bboxes = np.concatenate(\n",
    "                [cls_bboxes[: max_ind], \n",
    "                 cls_bboxes[max_ind + 1:]])\n",
    "  \n",
    "            # 3. 경계 상자의 모든 iou를 계산하고 iou 값이 임계값보다 높은 경계 상자를 제거 \n",
    "            iou = bboxes_iou(best_bbox[np.newaxis, :4],\n",
    "                             cls_bboxes[:, :4])\n",
    "            weight = np.ones((len(iou),), dtype=np.float32)\n",
    "\n",
    "            assert method in ['nms', 'soft-nms']\n",
    "\n",
    "            if method == 'nms':\n",
    "                iou_mask = iou > iou_threshold\n",
    "                weight[iou_mask] = 0.0 \n",
    "\n",
    "            if method == 'soft-nms':\n",
    "                weight = np.exp(-(1.0 * iou ** 2 / sigma))\n",
    "\n",
    "            cls_bboxes[:, 4] = cls_bboxes[:, 4] * weight\n",
    "            score_mask = cls_bboxes[:, 4] > 0. \n",
    "            cls_bboxes = cls_bboxes[score_mask]\n",
    "\n",
    "    return best_bboxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925645ca",
   "metadata": {},
   "source": [
    "## 사각형 그리기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b20e884",
   "metadata": {},
   "outputs": [],
   "source": [
    "import colorsys\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def draw_bbox(image, bboxes, class_names,\n",
    "              show_label=True, show_confidence=True,\n",
    "              Text_colors=(0,0,0), rectangle_colors='', \n",
    "              tracking=False):\n",
    "    image_h, image_w, _ = image.shape\n",
    "    num_class = len(class_names)\n",
    "\n",
    "    hsv_tuples = [(1.0 * x / num_classes, 1., 1.) for x in range(num_classes)]\n",
    "    colors = list(map(lambda x: colorsys.hsv_to_rgb(*x), hsv_tuples))\n",
    "    colors = list(map(lambda x: (int(x[0] * 255), int(x[1] * 255), int(x[2] * 255)), colors))\n",
    "\n",
    "    random.seed(0)\n",
    "    random.shuffle(colors)\n",
    "    random.seed(None)\n",
    "\n",
    "    for i, bbox in enumerate(bboxes):\n",
    "        coor = np.array(bbox[:4], dtype=np.int32)\n",
    "        score = bbox[4]\n",
    "        class_ind = int(bbox[5])\n",
    "        bbox_color = rectangle_colors if rectangle_colors != '' else colors[class_ind]\n",
    "        bbox_thick = int(0.6 * (image_h + image_w) / 1000)\n",
    "        if bbox_thick < 1: bbox_thick = 1 \n",
    "        fontScale = 0.75 * bbox_thick\n",
    "        x1, y1 = coor[0], coor[1]\n",
    "        x2, y2 = coor[2], coor[3]\n",
    "\n",
    "        # 경계상자 그리기 \n",
    "        cv2.rectangle(image, (x1, y1), (x2, y2), \n",
    "                      bbox_color, bbox_thick * 2)\n",
    "\n",
    "        if show_label:\n",
    "            score_str = \"\" \n",
    "            if show_confidence:\n",
    "                score_str = \" {:.2f}\".format(score)\n",
    "            if tracking: \n",
    "                score_str = \" \" + str(score)\n",
    "\n",
    "            try:\n",
    "                label = f\"{_class_names[class_ind]}{score_str}\"\n",
    "            except KeyError:\n",
    "                print(\"클래스 라벨이 잘못되었습니다.\")\n",
    "\n",
    "            # 텍스트 크기 \n",
    "            (text_width, text_height), baseline = cv2.getTextSize(\n",
    "                label, cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                fontScale, thickness=bbox_thick)\n",
    "            # 텍스트를 출력할 채워진 사각형 \n",
    "            cv2.rectangle(image, (x1, y1), \n",
    "                          (x1 + text_width,\n",
    "                           y1 - text_height - baseline),\n",
    "                          bbox_color, thickness=cv2.FILLED)\n",
    "            # 사각형 위에 텍스트 출력 \n",
    "            cv2.putText(image, label, (x1, y1 - 4), \n",
    "                        cv2.FONT_HERSHEY_COMPLEX_SMALL,\n",
    "                        fontScale, Text_colors, bbox_thick,\n",
    "                        lineType=cv2.LINE_AA)\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1db3bc7b",
   "metadata": {},
   "source": [
    "# 실시간 객체 탐지"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fb0f26a",
   "metadata": {},
   "source": [
    "## detect_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e766c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "\n",
    "from image_process import resize_to_square\n",
    "from data import read_class_names\n",
    "from post_process import *\n",
    "\n",
    "def detect_image(model, image_path, output_path,\n",
    "                 class_label_path, \n",
    "                 input_size=416, show=False,\n",
    "                 score_threshold=0.3, iou_threshold=0.45,\n",
    "                 rectangle_colors=''):\n",
    "    original_image = cv2.imread(image_path)\n",
    "    class_names = read_class_names(class_label_path)\n",
    "\n",
    "    image_data = resize_to_square(np.copy(original_image), target_size=input_size)\n",
    "    image_data = image_data[np.newaxis, ...].astype(np.float32)\n",
    "\n",
    "    pred_bbox = model.predict(image_data)\n",
    "\n",
    "    pred_bbox = [tf.reshape(x, (-1, tf.shape(x)[-1])) for x in pred_bbox]\n",
    "    pred_bbox = tf.concat(pred_bbox, axis=0)\n",
    "\n",
    "    bboxes = postprocess_boxes(pred_bbox, original_image,\n",
    "                               input_size, score_threshold)\n",
    "    bboxes = nms(bboxes, iou_threshold, method='nms')\n",
    "\n",
    "    image = draw_bbox(original_image, bboxes, class_names,\n",
    "                      rectangle_colors=rectangle_colors)\n",
    "\n",
    "    if output_path != '':\n",
    "        cv2.imwrite(output_path, image)\n",
    "    if show:\n",
    "        cv2.imshow(\"predicted image\", image)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.destroyAllWindows()\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84df8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from config import *\n",
    "from yolov3 import Create_YOLOv3\n",
    "\n",
    "yolo = Create_YOLOv3(num_class=NUM_CLASS)\n",
    "yolo.load_weights(os.path.join(CHECKPOINTS_FOLDER, MODEL_NAME))\n",
    "# yolo.load_weights(\"checkpoints/mnist_custom\")\n",
    "weight = yolo.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee631c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo.set_weights(weight)\n",
    "result_image = detect_image(model=yolo,  \n",
    "                            image_path=\"mnist_test_c.jpg\",\n",
    "                            output_path=\"mnist_test_out.jpg\", \n",
    "                            class_label_path=CLASS_LABEL_PATH, \n",
    "                            input_size=416, show=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70606f10",
   "metadata": {},
   "source": [
    "## Realtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "654aa3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from config import *\n",
    "from image_process import resize_to_square\n",
    "from data import read_class_names\n",
    "from post_process import *\n",
    "from yolov3 import Create_YOLOv3\n",
    "\n",
    "yolo = Create_YOLOv3(num_class=NUM_CLASS)\n",
    "yolo.load_weights(os.path.join(CHECKPOINTS_FOLDER, MODEL_NAME))\n",
    "# yolo.load_weights(\"checkpoints/mnist_custom\")\n",
    "weights = yolo.get_weights()\n",
    "class_names = read_class_names(CLASS_LABEL_PATH)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if cap.isOpened():\n",
    "    while True:\n",
    "        yolo.set_weights(weights)\n",
    "        ret, image = cap.read()\n",
    "        if not ret:\n",
    "            print(\"프레임을 받지 못했습니다.\")\n",
    "            break \n",
    "\n",
    "        # 밝기를 100만큼 더함 \n",
    "        dummy = np.full(image.shape, fill_value=100, \n",
    "                        dtype=np.uint8)\n",
    "        cv2.add(image, dummy, image)\n",
    "                \n",
    "        # 콘트라스트 강조함 \n",
    "        image = cv2.normalize(image, None, 0, 255,\n",
    "                              cv2.NORM_MINMAX)\n",
    "\n",
    "        # 이미지를 정사각형 모양으로 만듬 \n",
    "        image_data = resize_to_square(np.copy(image), 416)\n",
    "        image_data = image_data[np.newaxis,\n",
    "                                ...].astype(np.float32)\n",
    "\n",
    "        # 상자 예측 \n",
    "        pred_box = yolo.predict(image_data)\n",
    "        pred_box = [tf.reshape(x, (-1, tf.shape(x)[-1])) \n",
    "                    for x in pred_box]\n",
    "        pred_box = tf.concat(pred_box, axis=0)\n",
    "\n",
    "        # 상자 후처리 \n",
    "        bboxes = postprocess_boxes(pred_box, image, 416, 0.3)\n",
    "\n",
    "        # NMS에 의해 해당 영역에서 상자 하나만 남김 \n",
    "        bboxes = nms(bboxes, 0.45, method=\"nms\")\n",
    "\n",
    "        # 상자를 그림 \n",
    "        image = draw_bbox(image, bboxes, class_names)\n",
    "\n",
    "        cv2.imshow(\"Image\", image)\n",
    "        if cv2.waitKey(1) & 0xFF == 27:\n",
    "            break\n",
    "else:\n",
    "    print('연결된 카메라가 없습니다.')\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cf296f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# yolo.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6b9a41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2.14",
   "language": "python",
   "name": "tf2.14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
